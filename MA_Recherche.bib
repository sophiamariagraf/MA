@book{2015,
  title = {{{eGirls}}, {{eCitizens Putting Technology}}, {{Theory}} and {{Policy}} into {{Dialogue}} with {{Girls}}’ and {{Young Women}}’s {{Voices}}},
  date = {2015},
  publisher = {University of Ottawa Press},
  doi = {10.1353/book.40672},
  url = {https://muse.jhu.edu/book/40672},
  urldate = {2024-09-09},
  isbn = {978-0-7766-2259-0},
  langid = {english},
  keywords = {⏳},
  file = {/Users/sgraf/Zotero/storage/HECJ8CLN/2015 - eGirls, eCitizens Putting Technology, Theory and P.pdf}
}

@report{ajder2019,
  title = {The {{State}} of {{Deepfakes}}: {{Landscape}}, {{Threats}}, and {{Impact}}},
  author = {Ajder, Henry and Patrini, Giorgio and Cavalli, Francesco and Cullen, Laurence},
  date = {2019-09},
  institution = {Deeptrace},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/4Q9B5MZ3/Ajder et al._2019_The State of Deepfakes Landscape, Threats, and Impact.pdf}
}

@online{albert2024,
  title = {{{DSA}} Risk Assessment Reports: {{A}} Guide to the First Rollout and What’s next},
  author = {Albert, John},
  date = {2024-12-09},
  url = {https://dsa-observatory.eu/2024/12/09/dsa-risk-assessment-reports-are-in-a-guide-to-the-first-rollout-and-whats-next/},
  organization = {DSA Observatory},
  keywords = {✅}
}

@article{alilunas2024,
  title = {What We Must Be: {{AI}} and the Future of Porn Studies},
  shorttitle = {What We Must Be},
  author = {Alilunas, Peter},
  date = {2024-01-02},
  journaltitle = {Porn Studies},
  shortjournal = {Porn Studies},
  volume = {11},
  number = {1},
  pages = {99--112},
  issn = {2326-8743, 2326-8751},
  doi = {10.1080/23268743.2024.2312181},
  url = {https://www.tandfonline.com/doi/full/10.1080/23268743.2024.2312181},
  urldate = {2025-06-05},
  langid = {english}
}

@article{anciaux2025,
  title = {Imagining Markets and Crafting Value: The Emergence of an {{AI-generated}} Pornographic Content Ecosystem},
  shorttitle = {Imagining Markets and Crafting Value},
  author = {Anciaux, Arnaud and Gramaccia, Julie A.},
  date = {2025-05-15},
  journaltitle = {Porn Studies},
  shortjournal = {Porn Studies},
  pages = {1--16},
  issn = {2326-8743, 2326-8751},
  doi = {10.1080/23268743.2025.2492332},
  url = {https://www.tandfonline.com/doi/full/10.1080/23268743.2025.2492332},
  urldate = {2025-06-03},
  langid = {english}
}

@article{ash,
  title = {Nine Ways {{Facebook}} Can Make Itself a Better Forum for Free Speech and Democracy},
  author = {Ash, Timothy Garton and Gorwa, Robert and Metaxa, Danaë},
  langid = {english},
  file = {/Users/sgraf/Zotero/storage/AVL39KTF/Ash et al._Nine ways Facebook can make itself a better forum for free speech and democracy.pdf}
}

@article{atlam2025,
  title = {{{SLM-DFS}}: {{A}} Systematic Literature Map of Deepfake Spread on Social Media},
  shorttitle = {{{SLM-DFS}}},
  author = {Atlam, El-Sayed and Almaliki, Malik and Elmarhomy, Ghada and Almars, Abdulqader M. and Elsiddieg, Awatif M.A. and ElAgamy, Rasha},
  date = {2025-01},
  journaltitle = {Alexandria Engineering Journal},
  volume = {111},
  pages = {446--455},
  publisher = {Elsevier BV},
  issn = {1110-0168},
  doi = {10.1016/j.aej.2024.10.076},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1110016824012420},
  urldate = {2025-07-23},
  langid = {english},
  file = {/Users/sgraf/Zotero/storage/M65CUD5D/Atlam et al._2025_SLM-DFS A systematic literature map of deepfake spread on social media.pdf}
}

@book{atteveldt2022,
  title = {Computational Analysis of Communication: A Practical Introduction to the Analysis of Texts, Networks, and Images with Code Examples in {{Python}} and {{R}}},
  shorttitle = {Computational Analysis of Communication},
  author = {family=Atteveldt, given=Wouter, prefix=van, useprefix=false and Trilling, Damian and Arcíla Calderón, Carlos},
  date = {2022},
  publisher = {Wiley Blackwell},
  location = {Hoboken, USA Sussex, UK},
  url = {https://v2.cssbook.net},
  abstract = {"The use of computers is nothing new in the social sciences. In fact, one could argue that some disciplines within the social sciences have even be early adopters of computational approaches. Take the gathering and analyzing of large-scale survey data, dating back until the use of the Hollerith Machine in the 1890 US census. Long before every scholar had a personal computer on their desk, social scientists were using punch cards and mainframe computers to deal with such data. If we think of the analysis of communication more specifically, we see attempts to automate content analysis already in the 1960's [see, e.g. Scharkow, 2017]. Yet, something has profoundly changed in the last decades. The amount and kind of data we can collect as well as the computational power we have access to have increased dramatically. In particular, digital traces that we leave when communicating online, from access logs to comments we place, have required new approaches [e.g., Trilling, 2017]. At the same time, better computational facilities now allow us to ask questions we could not answer before"--},
  isbn = {978-1-119-68023-9},
  langid = {english},
  pagetotal = {314},
  keywords = {⏳},
  file = {/Users/sgraf/Zotero/storage/UYHB8AEA/Atteveldt et al._2022_Computational analysis of communication a practical introduction to the analysis of texts, networks.pdf}
}

@online{aylo2023,
  title = {Brands},
  author = {{Aylo}},
  date = {2023},
  url = {https://aylo.com/brands/},
  urldate = {2025-08-12},
  organization = {aylo.com},
  keywords = {✅}
}

@online{aylofreesitesltd,
  title = {Core values},
  author = {{Aylo Freesites Ltd}},
  url = {https://help.pornhub.com/hc/en-us/articles/4419871944723-Core-Values},
  urldate = {2025-08-12},
  langid = {1},
  organization = {help.pornhub.com},
  keywords = {✅}
}

@report{aylofreesitesltd2024,
  title = {{{EU DSA Transparency}} Report - {{August}} 2024},
  author = {{Aylo Freesites Ltd}},
  date = {2024-08-30},
  url = {https://help.pornhub.com/hc/en-us/articles/32596021061267-EU-DSA-Transparency-Report-August-2024},
  keywords = {✅}
}

@report{aylofreesitesltd2025,
  title = {Report on the Results of the Risk  Assessment for {{Pornhub}}.Com Pursuant  to {{Article}} 34 of the {{Digital Services Act}}},
  author = {{Aylo Freesites Ltd}},
  date = {2025-04},
  pages = {75},
  institution = {Aylo Freesites Limited},
  url = {https://ei.phncdn.com/static/misc/legal/Risk_Assessment_for_Pornhub_April_2025_1752958273.pdf},
  urldate = {2025-08-10},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/6Y5MB4XY/Risk_Assessment_for_Pornhub_April_2025_1752958273-2.pdf}
}

@article{aylofreesitesltd2025a,
  title = {Audit Implementation Report for {{Pornhub}}.Com Pursuant to {{Article}} 37 of the {{Digital Services Act}}},
  author = {{Aylo Freesites Ltd}},
  date = {2025-05},
  url = {https://ei.phncdn.com/static/misc/legal/Audit_Implementation_Report_for_Pornhub_May_2025_1752958259.pdf},
  langid = {english},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/2BC45FLJ/Ltd_Audit Implementation Report for Pornhub.com pursuant to Article 37 of the Digital Services Act.pdf}
}

@online{aylofreesitesltd2025c,
  title = {Premium Sign-Up},
  author = {{Aylo Freesites Ltd}},
  date = {2025},
  url = {https://pornhubpremium.com},
  organization = {pornhubpremium.com},
  keywords = {✅}
}

@online{aylofreesitesltd2025d,
  title = {Terms of {{Service}}},
  author = {{Aylo Freesites Ltd}},
  date = {2025-06-30},
  url = {https://www.pornhub.com/information/terms},
  urldate = {2025-08-06},
  organization = {pornhub.com},
  keywords = {✅}
}

@report{aylofreesitesltd2025e,
  title = {{{DSA Transparency}} Report – {{February}} 2025},
  author = {{Aylo Freesites Ltd}},
  year = {28 February 2025, updated 21 March 2025},
  url = {https://help.pornhub.com/hc/en-us/articles/38929180749587-DSA-Transparency-report-February-2025},
  keywords = {✅}
}

@article{barkouni2019,
  entrysubtype = {nonacademic},
  title = {Diese {{Frauen}} Posten {{Nacktfotos}} Und Begeben Sich in {{Lebensgefahr}}},
  author = {Barkouni, Tarek},
  date = {2019-10-14},
  journaltitle = {Vice.com},
  url = {https://www.vice.com/de/article/repressedgonewild-nacktfotos-reddit-aus-dem-iran/}
}

@inproceedings{batra2025,
  title = {{{SocialDF}}: {{Benchmark Dataset}} and {{Detection Model}} for {{Mitigating Harmful Deepfake Content}} on {{Social Media Platforms}}},
  shorttitle = {{{SocialDF}}},
  booktitle = {Proceedings of the 4th {{ACM International Workshop}} on {{Multimedia AI}} against {{Disinformation}}},
  author = {Batra, Arnesh and Khemani, Jashn and Gumber, Arush and Kumar, Anushk and Jain, Arhan and Gupta, Somil},
  date = {2025-06-30},
  pages = {81--89},
  publisher = {ACM},
  location = {Chicago USA},
  doi = {10.1145/3733567.3735573},
  url = {https://dl.acm.org/doi/10.1145/3733567.3735573},
  urldate = {2025-07-23},
  eventtitle = {{{MAD}}'25: 4th {{ACM International Workshop}} on {{Multimedia AI}} against {{Disinformation}}}
}

@article{birrer2024,
  title = {What We Know and Don’t Know about Deepfakes: {{An}} Investigation into the State of the Research and Regulatory Landscape},
  shorttitle = {What We Know and Don’t Know about Deepfakes},
  author = {Birrer, Alena and Just, Natascha},
  date = {2024-05-22},
  journaltitle = {New Media \& Society},
  shortjournal = {New Media \& Society},
  pages = {14614448241253138},
  issn = {1461-4448, 1461-7315},
  doi = {10.1177/14614448241253138},
  url = {https://journals.sagepub.com/doi/10.1177/14614448241253138},
  urldate = {2025-06-04},
  abstract = {The emergence of deepfakes has raised concerns among researchers, policymakers, and the public. However, many of these concerns stem from alarmism rather than well-founded evidence. This article provides an overview of what is currently known about deepfakes based on a systematic review of empirical research. It also examines and critically assesses regulatory responses globally through qualitative content analysis of policy and legal documents. The findings highlight gaps in our knowledge of deepfakes, making it difficult to assess the appropriateness and need for regulatory action. While deepfake technology may not introduce entirely new and unique regulatory problems at present, it can amplify existing problems such as the spread of non-consensual pornography and disinformation. Effective oversight and enforcement of existing rules, along with careful consideration of required adjustments will therefore be crucial. Altogether, this underscores the importance of more empirical research into the evolving challenges posed by deepfakes and calls for adaptive policy approaches.},
  langid = {english},
  keywords = {⏳},
  file = {/Users/sgraf/Zotero/storage/3I5CELYF/Birrer und Just_2024_What we know and don’t know about deepfakes An investigation into the state of the research and reg.pdf}
}

@incollection{brownsword2025,
  title = {Generative {{AI}} and the {{Rule}} of {{Law}}},
  booktitle = {The {{Oxford Handbook}} of the {{Foundations}} and {{Regulation}} of {{Generative AI}}},
  author = {Brownsword, Roger},
  editor = {Hacker, Philipp and Mittelstadt, Brent and Hammer, Sarah and Engel, Andreas},
  date = {2025-04-22},
  edition = {1},
  publisher = {Oxford University Press},
  doi = {10.1093/oxfordhb/9780198940272.013.0013},
  url = {https://academic.oup.com/edited-volume/59908/chapter/512459946},
  urldate = {2025-05-20},
  abstract = {Abstract             This chapter explores the application of the Rule of Law to generative AI. It is in the nature of a prolegomenon to debates about the particular rules and principles that should be adopted for the governance of this latest technology. The preliminary issues addressed relate to what the Rule of Law says about private governance, about exemptions for emergency or exceptional states, about how explicit and bespoke governance should be, about participatory and inclusive governance, about substantive constraints, and about universal values (and existential threats). Contrasting the Rule of Law with an ideal of ‘good governance’, the chapter suggests that the right question is not so much whether there are publicly declared rules about the lawful application of generative AI but whether the regulation of generative AI is in line with the ideals of good governance.},
  isbn = {978-0-19-894027-2 978-0-19-894030-2},
  langid = {english},
  keywords = {⏳},
  file = {/Users/sgraf/Zotero/storage/9AWP7GJH/Brownsword_2025_Generative AI and the Rule of Law.pdf}
}

@report{bundeskriminalamtbka2024,
  title = {Bundeslagebilder - {{Geschlechtsspezifisch}} Gegen {{Frauen}} Gerichtete {{Straftaten}} 2023},
  author = {{Bundeskriminalamt (BKA)}},
  date = {2024-11-19},
  institution = {Bundeskriminalamt (BKA)},
  file = {/Users/sgraf/Zotero/storage/8L564ZI4/Bundeskriminalamt (BKA)_2024_Bundeslagebilder - Geschlechtsspezifisch gegen Frauen gerichtete Straftaten 2023.pdf}
}

@book{burgess2019,
  title = {The {{SAGE}} Handbook of Social Media},
  editor = {Burgess, Jean and Marwick, Alice E. and Poell, Thomas},
  date = {2019},
  edition = {Paperback edition},
  publisher = {Sage reference},
  location = {Los Angeles London New Delhi Singapore Washington DC Melbourne},
  isbn = {978-1-4129-6229-2 978-1-5264-8687-5},
  langid = {english},
  pagetotal = {639},
  keywords = {⏳,❌},
  file = {/Users/sgraf/Zotero/storage/H7SRV65D/Burgess et al._2019_The SAGE handbook of social media.pdf}
}

@article{burgess2020,
  entrysubtype = {nonacademic},
  title = {Porn Sites Still Won’t Take down Nonconsensual Deepfakes},
  author = {Burgess, Matt},
  date = {2020-08-30},
  journaltitle = {netzpolitik.org},
  url = {https://www.wired.com/story/porn-sites-still-wont-take-down-non-consensual-deepfakes/},
  urldate = {2025-08-25},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/DUZ6SMNA/Burgess_2020_Porn sites still won’t take down nonconsensual deepfakes.pdf}
}

@article{butler2025,
  title = {Sex Worker Human Digital Twins and Intellectual Property: On Collaborative Futures for Sex Thinkers, Technologists, and Lawyers},
  shorttitle = {Sex Worker Human Digital Twins and Intellectual Property},
  author = {Butler, Yvette and Egwuatu, Chibundo and Canham, Matthew and Sawyer, Ben D.},
  date = {2025-04-23},
  journaltitle = {Porn Studies},
  shortjournal = {Porn Studies},
  pages = {1--16},
  issn = {2326-8743, 2326-8751},
  doi = {10.1080/23268743.2025.2466612},
  url = {https://www.tandfonline.com/doi/full/10.1080/23268743.2025.2466612},
  urldate = {2025-06-05},
  langid = {english}
}

@article{cagle2021,
  title = {The Ethics of Researching Unethical Images: {{A}} Story of Trying to Do Good Research without Doing Bad Things},
  shorttitle = {The Ethics of Researching Unethical Images},
  author = {Cagle, Lauren E.},
  date = {2021-09},
  journaltitle = {Computers and Composition},
  shortjournal = {Computers and Composition},
  volume = {61},
  pages = {102651},
  issn = {87554615},
  doi = {10.1016/j.compcom.2021.102651},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S8755461521000281},
  urldate = {2025-10-03},
  langid = {english},
  file = {/Users/sgraf/Zotero/storage/4JA64MXR/Cagle_2021_The ethics of researching unethical images A story of trying to do good research without doing bad.pdf}
}

@incollection{callon1989,
  title = {Society in the Making: The Study of Technology as a Tool for Sociological Analysis},
  booktitle = {The Social Construction of Technological Systems: New Directions in the Sociology and History of Technology},
  author = {Callon, M},
  editor = {Bijker, W and Huges, Thomas P and Pinch, T},
  date = {1989},
  pages = {83--103},
  publisher = {MIT Press},
  file = {/Users/sgraf/Zotero/storage/IM8BZEVL/Callon_1989_Society in the making the study of technology as a tool for sociological analysis.pdf}
}

@online{casas2025,
  title = {Academic {{Access}} to {{Social Media Data}} for the {{Study}} of {{Political Online Safety}}},
  author = {Casas, Andreu and Dagher, Georgia and O'Loughlin, Ben},
  date = {2025-01-16},
  doi = {10.31235/osf.io/7pcjd},
  url = {https://osf.io/7pcjd},
  urldate = {2025-03-10},
  abstract = {In this report we provide an overview of the kinds of data academics need in order to conduct independent research into political online safety matters on social media platforms, and the challenges they currently face. Additionally, we put forward ideas regarding novel governance structures that would enable high-quality independent research, while protecting users’ rights and data privacy, in the United Kingdom.},
  pubstate = {prepublished},
  keywords = {⏳,❌}
}

@article{celarier2021,
  entrysubtype = {nonacademic},
  title = {Bill {{Ackman}} Sent a Text to the {{CEO}} of {{Mastercard}}. {{What}} Happened next Is a Parable for {{ESG}}.},
  author = {Celarier, Michelle},
  date = {2021-06-16},
  journaltitle = {institutionalinvestor.com},
  url = {https://www.institutionalinvestor.com/article/2bswuu1nfc040ho7ghudc/culture/bill-ackman-sent-a-text-to-the-ceo-of-mastercard-what-happened-next-is-a-parable-for-esg}
}

@misc{centerfordemocracyandtechnology2025,
  title = {{{IBSA Principles}}: {{Principles}} for Combatting Image Based Sexual Abuse},
  author = {{Center for Democracy and Technology}},
  date = {2025},
  url = {https://ibsaprinciples.org/}
}

@report{certicoms.r.o.2025,
  title = {Independent {{Audit Report}} on {{XVideos}}.Com},
  author = {{Certicom s.r.o.}},
  date = {2025-04-21},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/HUIIWUP6/Certicom_2025_Independent Audit Report on XVideos.com.pdf}
}

@article{citron2011,
  title = {Intermediaries and Hate Speech: Fostering Digital Citizenship for Our Information Age},
  author = {Citron, Danielle Keats and Norton, Helen},
  date = {2011},
  journaltitle = {Boston University Law Review},
  volume = {91},
  number = {1435},
  url = {https://scholar.law.colorado.edu/faculty- articles/178},
  file = {/Users/sgraf/Zotero/storage/4RI6TYS9/Citron und Norton_2011_Intermediaries and hate speech fostering digital citizenship for our information age.pdf}
}

@article{citron2019,
  title = {Deep Fakes: A Looming Challenge for Privacy, Democracy, and National Security},
  author = {Citron, K. C. and Chesney, R},
  date = {2019},
  journaltitle = {California Law Review},
  volume = {107},
  number = {1753},
  url = {https://scholarship.law.bu.edu/faculty_scholarship/640}
}

@report{codingrights2017,
  title = {Online Gender-Based Violence: Diagnosis, Solutions and Challenges. {{Joint}} Contribution from {{Brazil}} to the {{UN}} Special Rapporteur on Violence against Women},
  author = {{Coding Rights} and {InternetLab}},
  date = {2017},
  location = {São Paulo},
  url = {http://www.internetlab.org.br/wp-content/uploads/2017/11/Relatorio_ ViolenciaGenero_ONU.pdf},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/5CWME3IR/Coding Rights und InternetLab_2017_Online Gender-Based Violence diagnosis, solutions and challenges. Joint contribution from Brazil to.pdf}
}

@article{cole2018,
  entrysubtype = {nonacademic},
  title = {Pornhub Is Banning {{AI-generated}} Fake Porn Videos, Says They’re Nonconsensual},
  author = {Cole, Samantha},
  date = {2018-02-06},
  journaltitle = {Vice.com},
  url = {https://www.vice.com/en/article/pornhub-bans-deepfakes/},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/3958I3LV/Cole_2018_Pornhub is banning AI-generated fake porn videos, says they’re nonconsensual.pdf}
}

@article{cole2020,
  entrysubtype = {nonacademic},
  title = {The Ugly Truth behind {{Pornhub}}’s ‘{{Year In Review}}’},
  author = {Cole, Samantha},
  date = {2020-02-18},
  journaltitle = {Vice.com},
  url = {https://www.vice.com/en/article/pornhub-year-in-review-deepfake/},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/MEPQYYIT/Cole_2020_The ugly truth behind Pornhub’s ‘Year In Review’.pdf}
}

@article{cole2020a,
  entrysubtype = {nonacademic},
  title = {‘{{War}} against Sex Workers:’ {{What Visa}} and {{Mastercard}} Dropping {{Pornhub}} Means to Performers},
  author = {Cole, Samantha},
  date = {2020-12-11},
  journaltitle = {Vice.com},
  url = {https://www.vice.com/en/article/sex-workers-what-visa-and-mastercard-dropping-pornhub-means-to-performers/}
}

@article{cole2020b,
  entrysubtype = {nonacademic},
  title = {Pornhub Just Purged All Unverified Content from the Platform},
  author = {Cole, Samantha},
  date = {2020-12-14},
  journaltitle = {Vice.com},
  url = {https://www.vice.com/en/article/pornhub-suspended-all-unverified-videos-content/},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/3KE4726A/Cole_2020_Pornhub just purged all unverified content from the platform.pdf}
}

@article{cole2025,
  entrysubtype = {nonacademic},
  title = {Pornhub Will Pay \$5 {{Million}} over Allegations of Hosting Child Sexual Abuse Material},
  author = {Cole, Samantha},
  date = {2025-09-03},
  journaltitle = {404 Media},
  url = {https://www.404media.co/pornhub-ftc-utah-settlement-lawsuit/},
  keywords = {⏳},
  file = {/Users/sgraf/Zotero/storage/SFFIRWKY/Cole_2025_Pornhub will pay $5 Million over allegations of hosting child sexual abuse material.pdf}
}

@video{compton2023,
  type = {Dokumentation},
  entrysubtype = {film},
  title = {Alptraum {{Deepfake-Pornos}}},
  editor = {Compton, Sophie and Reuben, Hamlyn},
  editortype = {director},
  namea = {{arte/ ZDF}},
  nameatype = {collaborator},
  date = {2023},
  url = {https://www.arte.tv/de/videos/119514-000-A/alptraum-deepfake-pornos/},
  urldate = {2024-11-15},
  abstract = {Eine junge Frau findet heraus, dass von ihr auf Pornoseiten Deepfakes kursieren. Mittels einer KI wurde ihr Gesicht auf Pornovideos kopiert – mit Klarnamen und Adresse. Die junge Frau macht sich auf die Suche nach dem Urheber dieser Videos, sie trifft dabei auf andere junge Frauen, die dasselbe erlebt haben, und erfährt, wie leicht es ist, mit KI solche Fakes zu produzieren. Die 23-jährige Studentin Taylor Klein stößt eines Tages im Internet auf gefakte Pornovideos von sich selbst. Jemand hat mittels KI ihr Gesicht auf Pornovideos kopiert. Die Dokumentation beschreibt die schmerzhafte und emotionale Suche der jungen Frau nach dem Urheber dieser gefakten Videos, die jemand auf einschlägigen Pornoseiten hochgeladen hat. Die Videos sind zwar gefälscht, aber ihr Gesicht, ihr Name, ihre Adresse wurden vom Verursacher angegeben und sind es nicht. Taylor trifft andere junge Frauen, die ebenfalls Opfer von Deepfakes wurden. Die Zahl der im Netz kursierenden Deepfake-Pornos wächst rasant. Frauen sind in 99 Prozent der Fälle die Opfer. Ob das Video echt ist oder ein Fake, lässt sich im Nachhinein kaum erkennen, so lebensecht wirken die KI-generierten Videos. Der psychische, emotionale und soziale Schaden für die betroffenen Frauen ist immens. Die Dokumentation zeigt eindrücklich, wie leicht es ist, diese Deepfakes herzustellen – inzwischen ist die KI so weit ausgereift, dass ein einziges hochaufgelöstes Foto ausreicht, um ein Video von 60 Sekunden herzustellen. Der Film zeigt auch, wie hilflos die Rechtsprechung derzeit noch ist, wenn es um die Bestrafung eines solchen Missbrauchs geht und dass den jungen Frauen oftmals nur der Rückzug aus der digitalen Welt übrigbleibt.},
  keywords = {⏳}
}

@book{corbin2008,
  title = {Basics of Qualitative Research: Techniques and Procedures for Developing Grounded Theory},
  shorttitle = {Basics of {{Qualitative Research}} (3rd Ed.)},
  author = {Corbin, Juliet and Strauss, Anselm},
  date = {2008},
  edition = {3},
  publisher = {SAGE Publications, Inc.},
  doi = {10.4135/9781452230153},
  url = {https://methods.sagepub.com/book/basics-of-qualitative-research},
  urldate = {2025-10-19},
  isbn = {978-1-4129-0644-9 978-1-4522-3015-3}
}

@article{datta2025,
  entrysubtype = {nonacademic},
  title = {Porn Platforms Report {{EU}} User Collapse, May Dodge {{DSA}} Scrutiny},
  author = {Datta, Anupriya},
  date = {2025-02-18},
  journaltitle = {euractiv.com},
  url = {https://www.euractiv.com/section/tech/news/porn-platforms-report-a-major-drop-in-eu-users-to-evade-dsa-responsibility/?_ga=2.226876890.69505057.1740046886-1334932735.1740046886},
  urldate = {2025-03-21},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/ZEVC5I34/Datta_2025_Porn platforms report EU user collapse, may dodge DSA scrutiny.pdf}
}

@article{deckker2025,
  title = {Artificial {{Intelligence}} and Pornography: {{A}} Comprehensive Research Review},
  shorttitle = {Artificial {{Intelligence}} and Pornography},
  author = {Deckker, Dinesh and Sumanasekara, Subhashini},
  date = {2025-05-30},
  journaltitle = {World Journal of Advanced Research and Reviews},
  shortjournal = {World J. Adv. Res. Rev.},
  volume = {26},
  number = {2},
  pages = {618--637},
  issn = {25819615},
  doi = {10.30574/wjarr.2025.26.2.1739},
  url = {https://journalwjarr.com/node/1533},
  urldate = {2025-10-16},
  abstract = {This comprehensive review examines the intersection of artificial intelligence (AI) and pornography, analyzing how AI-driven technologies such as deepfakes, recommendation systems, and content moderation tools are reshaping the adult entertainment industry. While AI introduces efficiencies in content creation and personalization, it also generates significant ethical, psychological, legal, and societal challenges. The proliferation of non-consensual deepfake pornography raises urgent concerns about consent, privacy, and image-based sexual abuse. AI's role in influencing user behaviour, reinforcing unrealistic sexual norms, and altering perceptions of intimacy is explored through psychological and media effects theories. Additionally, the paper highlights gaps in global regulation, inconsistencies in legal enforcement, and the urgent need for longitudinal and intervention studies to assess the real-world impacts of AI-enhanced pornography. Future directions emphasise the development of ethical frameworks, robust technological safeguards, and interdisciplinary research to guide responsible innovation and protect human dignity in digital environments.},
  file = {/Users/sgraf/Zotero/storage/TGDTCPBL/Dinesh Deckker und Subhashini Sumanasekara_2025_Artificial Intelligence and pornography A comprehensive research review.pdf}
}

@article{denardis2015,
  title = {Internet Governance by Social Media Platforms},
  author = {DeNardis, L. and Hackl, A.M.},
  date = {2015-10},
  journaltitle = {Telecommunications Policy},
  shortjournal = {Telecommunications Policy},
  volume = {39},
  number = {9},
  pages = {761--770},
  issn = {03085961},
  doi = {10.1016/j.telpol.2015.04.003},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0308596115000592},
  urldate = {2025-03-05},
  langid = {english},
  keywords = {⏳,❌}
}

@book{denzin1970,
  title = {The Research Act: A Theoretical Introduction to Sociological Methods},
  author = {Denzin, Norman K.},
  date = {1970},
  publisher = {Aldine Pub. Co},
  location = {Chicago},
  isbn = {978-0-202-30121-1},
  langid = {english},
  annotation = {OCLC: 75943}
}

@article{denzin2012,
  title = {Triangulation 2.0},
  author = {Denzin, Norman K.},
  date = {2012-04},
  journaltitle = {Journal of Mixed Methods Research},
  shortjournal = {Journal of Mixed Methods Research},
  volume = {6},
  number = {2},
  pages = {80--88},
  issn = {1558-6898, 1558-6901},
  doi = {10.1177/1558689812437186},
  url = {https://journals.sagepub.com/doi/10.1177/1558689812437186},
  urldate = {2025-09-15},
  abstract = {A third way of conceptualizing mixed methods research is proposed, one based on critical interpretive methodologies.},
  langid = {english},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/P23HGP5Q/Denzin_2012_Triangulation 2.0.pdf}
}

@incollection{denzin2015,
  title = {Triangulation},
  booktitle = {The {{Blackwell Encyclopedia}} of {{Sociology}}},
  author = {Denzin, Norman K.},
  editor = {Ritzer, George},
  date = {2015-10-26},
  edition = {1},
  publisher = {Wiley},
  doi = {10.1002/9781405165518.wbeost050.pub2},
  url = {https://onlinelibrary.wiley.com/doi/10.1002/9781405165518.wbeost050.pub2},
  urldate = {2025-09-29},
  abstract = {Triangulation refers to the application and combination of several research methodologies in the study of the same phenomenon. The concept of triangulation, understood as in the action of drawing a triangle, may be traced back to the Greeks and the origins of modern geometry. Introduced in the social sciences in the 1950s (Campbell and Fiske, 1959), then heavily criticized in the 1980s (see Silverman, 1985; Lincoln and Guba, 1985; Guba and Lincoln, 1989) and in the 1990s (Flick, 2004, 2007), triangulation is a postpositivist methodological strategy. It has recently returned to favor, as a new generation of scholars is drawn to a mixed, or multimethod, approach to social inquiry (Teddlie and Tashakkori, 2003; Creswell, 2011). When the term was introduced in the social sciences, the method designated by it functioned as a bridge between quantitative and qualitative epistemologies. It was seen as a way of helping qualitative researchers become more rigorous, perhaps by allowing them to address a methodological inferiority associated with “a kind of stepchild complex” (Kamberelis and Dimitriadis, 2004: 2). Advocates of mixed‐methods research argue that it allows them to answer questions that other methodologies, taken singly, cannot. Further, it provides “better inferences based on a greater diversity of divergent views” (Teddlie and Tashakkori, 2003: 14–15).},
  isbn = {978-1-4051-2433-1 978-1-4051-6551-8},
  langid = {english},
  file = {/Users/sgraf/Zotero/storage/Z8HKYQYI/Denzin_2015_Triangulation.pdf}
}

@report{deutscherjuristinnenbunde.v.2023,
  type = {Policy Paper},
  title = {Bekämpfung Bildbasierter Sexualisierter {{Gewalt}}},
  author = {{Deutscher Juristinnenbund e.V.}},
  date = {2023-06-07},
  url = {https://www.djb.de/fileadmin/user_upload/presse/stellungnahmen/st23-17_Bildbasierte_Gewalt.pdf},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/P2FJVPFQ/Deutscher Juristinnenbund e.V. - 2023 - Bekämpfung bildbasierter sexualisierter Gewalt.pdf}
}

@inproceedings{ding2025,
  title = {The {{Malicious Technical Ecosystem}}: {{Exposing Limitations}} in {{Technical Governance}} of {{AI-Generated Non-Consensual Intimate Images}} of {{Adults}}},
  shorttitle = {The {{Malicious Technical Ecosystem}}},
  author = {Ding, Michelle L. and Suresh, Harini},
  date = {2025},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.2504.17663},
  url = {https://arxiv.org/abs/2504.17663},
  urldate = {2025-07-08},
  abstract = {In this paper, we adopt a survivor-centered approach to locate and dissect the role of sociotechnical AI governance in preventing AI-Generated Non-Consensual Intimate Images (AIG-NCII) of adults, colloquially known as "deep fake pornography." We identify a "malicious technical ecosystem" or "MTE," comprising of open-source face-swapping models and nearly 200 "nudifying" software programs that allow non-technical users to create AIG-NCII within minutes. Then, using the National Institute of Standards and Technology (NIST) AI 100-4 report as a reflection of current synthetic content governance methods, we show how the current landscape of practices fails to effectively regulate the MTE for adult AIG-NCII, as well as flawed assumptions explaining these gaps.},
  version = {1},
  keywords = {✅,Artificial Intelligence (cs.AI),Computers and Society (cs.CY),FOS: Computer and information sciences,Human-Computer Interaction (cs.HC),Machine Learning (cs.LG)},
  file = {/Users/sgraf/Zotero/storage/4NKQA238/Ding und Suresh_2025_The Malicious Technical Ecosystem Exposing Limitations in Technical Governance of AI-Generated Non-.pdf}
}

@online{dolhansky2020,
  title = {The {{DeepFake Detection Challenge}} ({{DFDC}}) Dataset},
  author = {Dolhansky, Brian and Bitton, Joanna and Pflaum, Ben and Lu, Jikuo and Howes, Russ and Wang, Menglin and Ferrer, Cristian Canton},
  date = {2020},
  doi = {10.48550/arXiv.2006.07397},
  url = {https://arxiv.org/abs/2006.07397},
  urldate = {2025-10-17},
  abstract = {Deepfakes are a recent off-the-shelf manipulation technique that allows anyone to swap two identities in a single video. In addition to Deepfakes, a variety of GAN-based face swapping methods have also been published with accompanying code. To counter this emerging threat, we have constructed an extremely large face swap video dataset to enable the training of detection models, and organized the accompanying DeepFake Detection Challenge (DFDC) Kaggle competition. Importantly, all recorded subjects agreed to participate in and have their likenesses modified during the construction of the face-swapped dataset. The DFDC dataset is by far the largest currently and publicly available face swap video dataset, with over 100,000 total clips sourced from 3,426 paid actors, produced with several Deepfake, GAN-based, and non-learned methods. In addition to describing the methods used to construct the dataset, we provide a detailed analysis of the top submissions from the Kaggle contest. We show although Deepfake detection is extremely difficult and still an unsolved problem, a Deepfake detection model trained only on the DFDC can generalize to real "in-the-wild" Deepfake videos, and such a model can be a valuable analysis tool when analyzing potentially Deepfaked videos. Training, validation and testing corpuses can be downloaded from https://ai.facebook.com/datasets/dfdc.},
  pubstate = {prepublished},
  version = {4},
  keywords = {Computer Vision and Pattern Recognition (cs.CV),FOS: Computer and information sciences,Machine Learning (cs.LG)}
}

@report{dsacivilsocietycoordinationgroup2025,
  title = {Civil {{Society Responds}} to {{DSA Risk Assessment Reports}}: {{An Initial Feedback Brief}}},
  author = {{DSA Civil Society Coordination Group}},
  date = {2025-03-17},
  institution = {Center for Democracy \& Technology},
  url = {https://cdt.org/insights/dsa-civil-society-coordination-group-publishes-an-initial-analysis-of-the-major-online-platforms-risks-analysis-reports/},
  keywords = {⏳},
  file = {/Users/sgraf/Zotero/storage/K3ZCFMTF/Center for Democracy & Technology_2025_Civil Society Responds to DSA Risk Assessment Reports An Initial Feedback Brief.pdf}
}

@article{dvoskin2024,
  title = {Speaking Back to Sexual Privacy Invasions},
  author = {Dvoskin, Brenda},
  date = {2024},
  journaltitle = {Washington Law Review},
  volume = {99},
  number = {1},
  pages = {59--106},
  url = {https://digitalcommons.law.uw.edu/cgi/viewcontent.cgi?article=5301&context=wlr},
  keywords = {⏳},
  file = {/Users/sgraf/Zotero/storage/ISYQQAW3/Dvoskin_2024_Speaking Back to Sexual Privacy Invasions.pdf}
}

@book{ellingson2009,
  title = {Engaging Crystallization in Qualitative Research},
  author = {Ellingson, Laura},
  date = {2009},
  publisher = {SAGE Publications, Inc.},
  location = {2455 Teller Road,~Thousand Oaks~California~91320~United States of America},
  doi = {10.4135/9781412991476},
  url = {https://methods.sagepub.com/book/engaging-crystallization-in-qualitative-research},
  urldate = {2025-10-18},
  isbn = {978-1-4129-5907-0 978-1-4129-9147-6}
}

@report{europeancommission,
  title = {Digital {{Services Terms}} and {{Conditions Database}} –~{{User}} Guide},
  author = {{European Commission}},
  keywords = {⏳},
  file = {/Users/sgraf/Zotero/storage/43URZ4XE/European Commission_Digital Services Terms and Conditions Database – User guide.pdf}
}

@dataset{europeancommission-dgconnect2023,
  title = {Digital {{Services Act Transparency Database}}},
  author = {{European Commission-DG CONNECT}},
  date = {2023},
  publisher = {{Directorate-General for Communications Networks, Content and Technology}},
  doi = {10.2906/134353607485211},
  url = {http://data.europa.eu/88u/dataset/dsa-transparency-database},
  urldate = {2025-09-20},
  abstract = {The Digital Services Act (DSA) Transparency Database collects the content moderation decisions that providers of online platforms take on the content generated by their users in almost real-time. In particular, it records a standardised set of information about each content moderation decision, the so-called Statement of Reasons, which includes the action taken, the reasons behind the action as well as its legal or contractual basis among other information.  To enhance transparency and facilitate scrutiny over content moderation decisions, providers of online platforms need to submit these statements of reasons in a machine-readable format to the DSA Transparency Database, allowing to track online content moderation. Its website also offers various tools for accessing, analysing, and downloading the information that online platforms need to make available when they take content moderation decisions, contributing to the monitoring of the dissemination of illegal and harmful content online.},
  langid = {english},
  keywords = {"en":"digital single market","en":"Internet",✅,content-moderation,dsa,illegal-content,internet,online-plartforms,open-data}
}

@dataset{europeancommission-dgconnect2023a,
  title = {Digital {{Services Act Transparency Database}}},
  author = {{European Commission-DG CONNECT}},
  date = {2023},
  publisher = {{Directorate-General for Communications Networks, Content and Technology}},
  doi = {10.2906/134353607485211},
  url = {http://data.europa.eu/88u/dataset/dsa-transparency-database},
  urldate = {2025-09-21},
  abstract = {The Digital Services Act (DSA) Transparency Database collects the content moderation decisions that providers of online platforms take on the content generated by their users in almost real-time. In particular, it records a standardised set of information about each content moderation decision, the so-called Statement of Reasons, which includes the action taken, the reasons behind the action as well as its legal or contractual basis among other information.  To enhance transparency and facilitate scrutiny over content moderation decisions, providers of online platforms need to submit these statements of reasons in a machine-readable format to the DSA Transparency Database, allowing to track online content moderation. Its website also offers various tools for accessing, analysing, and downloading the information that online platforms need to make available when they take content moderation decisions, contributing to the monitoring of the dissemination of illegal and harmful content online.},
  langid = {english},
  keywords = {"en":"digital single market","en":"Internet",content-moderation,dsa,illegal-content,internet,online-plartforms,open-data}
}

@report{europeancommission2023a,
  type = {Press release},
  title = {Commission Designates Second Set of {{Very Large Online Platforms}} under the {{Digital Services Act}}},
  author = {{European Commission}},
  date = {2023-12-20},
  location = {Brussels},
  url = {https://ec.europa.eu/commission/presscorner/api/files/document/print/en/ip_23_6763/IP_23_6763_EN.pdf},
  file = {/Users/sgraf/Zotero/storage/VSZ5I6YJ/European Commission_2023_Commission designates second set of Very Large Online Platforms under the Digital Services Act.pdf}
}

@online{europeancommission2023b,
  title = {Commission Launches New Database to Track Digital Services Terms and Conditions},
  author = {{European Commission}},
  date = {2023-12-01},
  url = {https://digital-strategy.ec.europa.eu/en/news/commission-launches-new-database-track-digital-services-terms-and-conditions},
  organization = {Shaping Europe’s digital future},
  keywords = {✅}
}

@report{europeancommission2024b,
  type = {Press release},
  title = {Commission Designates Adult Content Platform {{XNXX}} as {{Very Large Online Platform}} under the {{Digital Services Act}}},
  author = {{European Commission}},
  date = {2024-07-10},
  location = {Brussels},
  url = {https://ec.europa.eu/commission/presscorner/api/files/document/print/en/ip_24_3723/IP_24_3723_EN.pdf},
  file = {/Users/sgraf/Zotero/storage/Q3VW8TX6/European Commission_2024_Commission designates adult content platform XNXX as Very Large Online Platform under the Digital Se.pdf}
}

@legislation{europeancommission2024c,
  title = {{{COMMISSION IMPLEMENTING REGULATION}} ({{EU}}) 2024/2835 of 4 {{November}} 2024 Laying down Templates Concerning the Transparency Reporting Obligations of Providers of Intermediary Services and of Providers of Online Platforms under {{Regulation}} ({{EU}}) 2022/2065 of the {{European Parliament}} and of the {{Council}}},
  author = {{European Commission}},
  date = {2024-11-04},
  number = {2024/2835},
  file = {/Users/sgraf/Zotero/storage/CYB4VSMD/European Commission_COMMISSION IMPLEMENTING REGULATION (EU) 20242835 of 4 November 2024 laying down templates concernin.pdf}
}

@online{europeancommission2025d,
  title = {How the {{Digital Services Act}} Enhances Transparency Online},
  author = {{European Commission}},
  date = {2025-08-07},
  url = {https://digital-strategy.ec.europa.eu/en/policies/dsa-brings-transparency},
  organization = {Shaping Europe’s digital future},
  keywords = {✅}
}

@legislation{europeancommissionb,
  title = {{{REGULATION}} ({{EU}}) 2024/1689 {{OF THE EUROPEAN PARLIAMENT AND OF THE COUNCIL}}  of 13 {{June}} 2024  Laying down Harmonised Rules on Artificial Intelligence and Amending {{Regulations}} ({{EC}}) {{No}} 300/2008, ({{EU}}) {{No}} 167/2013, ({{EU}}) {{No}} 168/2013, ({{EU}}) 2018/858, ({{EU}}) 2018/1139 and ({{EU}}) 2019/2144 and {{Directives}} 2014/90/{{EU}}, ({{EU}}) 2016/797 and ({{EU}}) 2020/1828 ({{Artificial Intelligence Act}})},
  author = {{European Commission}},
  file = {/Users/sgraf/Zotero/storage/FJUT8NJR/OJ%3AL_202401689%3AEN%3ATXT.pdf}
}

@legislation{europeancommissionc,
  title = {{{REGULATION}} ({{EU}}) 2022/2065 {{OF THE EUROPEAN PARLIAMENT AND OF THE COUNCIL}}  of 19 {{October}} 2022  on a {{Single Market For Digital Services}} and Amending {{Directive}} 2000/31/{{EC}} ({{Digital Services Act}})},
  author = {{European Commission}},
  url = {http://data.europa.eu/eli/reg/2022/2065/oj},
  file = {/Users/sgraf/Zotero/storage/86AHYCMS/Regulation (EU) 20222065 of the European Parliame.pdf;/Users/sgraf/Zotero/storage/TI4ISGAX/CELEX%3A32022R2065%3ADE%3ATXT-2.pdf}
}

@online{europeancommissiond,
  title = {Digital {{Services Terms}} and {{Conditions Database}}},
  author = {{European Commission}},
  url = {https://platform-contracts.digital-strategy.ec.europa.eu},
  urldate = {2025-09-16},
  keywords = {✅}
}

@online{europeancommissione,
  title = {Overview Documentation},
  author = {{European Commission}},
  url = {https://transparency.dsa.ec.europa.eu/page/documentation},
  urldate = {2025-09-21},
  organization = {DSA Transparency Database},
  keywords = {✅}
}

@online{europeancommissionf,
  title = {{{API}} and Schema},
  author = {{European Commission}},
  url = {https://transparency.dsa.ec.europa.eu/page/api-documentation#statement-attributes},
  urldate = {2025-09-21},
  organization = {DSA Transparency Database},
  keywords = {✅}
}

@online{europeancommissiong,
  title = {Explore Data Overview},
  author = {{European Commission}},
  url = {https://transparency.dsa.ec.europa.eu/explore-data/overview},
  urldate = {2025-09-21},
  organization = {DSA Transparency Database}
}

@article{falduti2023,
  title = {Mapping the {{Interdisciplinary Research}} on {{Non-consensual Pornography}}: {{Technical}} and {{Quantitative Perspectives}}},
  shorttitle = {Mapping the {{Interdisciplinary Research}} on {{Non-consensual Pornography}}},
  author = {Falduti, Mattia and Tessaris, Sergio},
  date = {2023-09-30},
  journaltitle = {Digital Threats: Research and Practice},
  shortjournal = {Digital Threats},
  volume = {4},
  number = {3},
  pages = {1--22},
  issn = {2692-1626, 2576-5337},
  doi = {10.1145/3608483},
  url = {https://dl.acm.org/doi/10.1145/3608483},
  urldate = {2025-06-03},
  abstract = {The phenomenon of the non-consensual distribution of intimate or sexually explicit digital images of adults, a.k.a. non-consensual pornography (NCP) or revenge pornography, is under the spotlight for the toll it is taking on society. Law enforcement statistics confirm a dramatic global rise in abuses. For this reason, the research community is investigating different strategies to fight and mitigate the abuses and their effects. Since the phenomenon involves different aspects of personal and social interaction among users of social media and content sharing platforms, in the literature it is addressed under different academic disciplines. However, while most of the literature reviews focus on non-consensual pornography either from a social science or psychological perspective, to the best of our knowledge a systematic review of the research on the technical aspects of the problem is still missing. In this work, we present a Systematic Mapping Study (SMS) of the literature, looking at this interdisciplinary phenomenon through a technical lens. Therefore, we focus on the cyber side of the crime of non-consensual pornography with the aim of describing the state-of-the-art and the future lines of research from a technical and quantitative perspective.},
  langid = {english},
  keywords = {⏳},
  file = {/Users/sgraf/Zotero/storage/QTXNWAB6/Falduti und Tessaris_2023_Mapping the Interdisciplinary Research on Non-consensual Pornography Technical and Quantitative Per.pdf}
}

@article{farid2021,
  title = {An Overview of Perceptual Hashing},
  author = {Farid, Hany},
  date = {2021-10-28},
  journaltitle = {Journal of Online Trust and Safety},
  shortjournal = {jots},
  volume = {1},
  number = {1},
  issn = {2770-3142},
  doi = {10.54501/jots.v1i1.24},
  url = {https://tsjournal.org/index.php/jots/article/view/24},
  urldate = {2025-10-17},
  abstract = {It is said that what happens on the internet stays on the internet, forever. In some cases this may be considered a feature. Reports of human rights violations and corporate corruption, for example, should remain part of the public record. In other cases, however, digital immortality may be considered less desirable. Most would agree that terror-related content, child sexual abuse material, non-consensual intimate imagery, and dangerous disinformation, to name a few, should not be so easily found online. Neither human moderation nor artificial intelligence is currently able to contend with the spread of harmful content. Perceptual hashing has emerged as a powerful technology to limit the redistribution of multimedia content (including audio, images, and video). We review how this technology works, its advantages and disadvantages, and how it has been deployed on small- to large-scale platforms.},
  file = {/Users/sgraf/Zotero/storage/ZZMEWPTA/Farid_2021_An Overview of Perceptual Hashing.pdf}
}

@online{ferrer2020,
  title = {Deepfake {{Detection Challenge}} Results: An Open Initiative to Advance {{AI}}},
  author = {Ferrer, C. C. and Dolhansky, Brian and Pflaum, Ben and Bitton, J and Pan, J and Lu},
  date = {2020-06-12},
  url = {https://ai.meta.com/blog/deepfake-detection-challenge-results-an-open-initiative-to-advance-ai/},
  organization = {Meta AI}
}

@article{fisher2024,
  title = {Moderating {{Synthetic Content}}: The {{Challenge}} of {{Generative AI}}},
  shorttitle = {Moderating {{Synthetic Content}}},
  author = {Fisher, Sarah A. and Howard, Jeffrey W. and Kira, Beatriz},
  date = {2024-12},
  journaltitle = {Philosophy \& Technology},
  shortjournal = {Philos. Technol.},
  volume = {37},
  number = {4},
  pages = {133},
  issn = {2210-5433, 2210-5441},
  doi = {10.1007/s13347-024-00818-9},
  url = {https://link.springer.com/10.1007/s13347-024-00818-9},
  urldate = {2025-06-03},
  abstract = {Abstract             Artificially generated content threatens to seriously disrupt the public sphere. Generative AI massively facilitates the production of convincing portrayals of fabricated events. We have already begun to witness the spread of synthetic misinformation, political propaganda, and non-consensual intimate deepfakes. Malicious uses of the new technologies can only be expected to proliferate over time. In the face of this threat, social media platforms must surely act. But how? While it is tempting to think they need new sui generis policies targeting synthetic content, we argue that the challenge posed by generative AI should be met through the enforcement of general platform rules. We demonstrate that the threat posed to individuals and society by AI-generated content is no different in kind from that of ordinary harmful content—a threat which is already well recognised. Generative AI massively increases the problem but, ultimately, it requires the same approach. Therefore, platforms do best to double down on improving and enforcing their existing rules, regardless of whether the content they are dealing with was produced by humans or machines.},
  langid = {english},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/NMSHSR2X/Fisher et al._2024_Moderating Synthetic Content the Challenge of Generative AI.pdf}
}

@book{flick2007,
  title = {Designing Qualitative Research},
  author = {Flick, Uwe},
  date = {2007},
  series = {The {{Sage}} Qualitative Research Kit / Ed. by {{Uwe Flick}}},
  edition = {Repr},
  number = {1},
  publisher = {SAGE},
  location = {Los Angeles},
  isbn = {978-0-7619-4976-3},
  langid = {english},
  pagetotal = {130},
  file = {/Users/sgraf/Zotero/storage/M7GBBN5D/Flick_2010_Designing qualitative research.pdf}
}

@inbook{flynn2019,
  title = {Image-{{Based Sexual Abuse}}},
  booktitle = {Oxford {{Research Encyclopedia}} of {{Criminology}} and {{Criminal Justice}}},
  author = {Flynn, Asher},
  date = {2019-03-26},
  publisher = {Oxford University Press},
  doi = {10.1093/acrefore/9780190264079.013.534},
  url = {https://oxfordre.com/criminology/view/10.1093/acrefore/9780190264079.001.0001/acrefore-9780190264079-e-534},
  urldate = {2024-09-19},
  abstract = {Image-based sexual abuse (IBSA) is a form of technology-facilitated sexual violence. The term describes a pattern of behaviors involving the nonconsensual creation, distribution, and/or threats to distribute, nude or sexual images. Also known as “revenge pornography” or “nonconsensual pornography,” IBSA affects a significant proportion of the population. A study conducted by Powell, Scott, Flynn, and McCook of IBSA across Australia, the United Kingdom, and New Zealand found that one in six individuals aged between 16 and 64 years have experienced at least one form of IBSA victimization, and one in six individuals have engaged in at least one form of IBSA perpetration.             Perpetrators of IBSA can include intimate partners, family members, friends, acquaintances, and persons unknown to the victim, with diverse motivations, including sexual gratification, retribution, coercive control, social notoriety, monetary gain, and voyeurism. The images themselves may be self-created by the victim as a “selfie” or produced consensually in the context of a relationship. Alternatively, images may be digitally altered, taken surreptitiously in public or private settings, or created coercively, or they may have been taken of a sexual assault or rape. While IBSA is not itself new, technology has created a conducive and large-scale platform for such abuse to occur.},
  bookauthor = {Flynn, Asher},
  isbn = {978-0-19-026407-9},
  langid = {english},
  keywords = {⏳}
}

@article{flynn2022,
  title = {Deepfakes and {{Digitally Altered Imagery Abuse}}: {{A Cross-Country Exploration}} of an {{Emerging}} Form of {{Image-Based Sexual Abuse}}},
  shorttitle = {Deepfakes and {{Digitally Altered Imagery Abuse}}},
  author = {Flynn, Asher and Powell, Anastasia and Scott, Adrian J and Cama, Elena},
  date = {2022-10-13},
  journaltitle = {The British Journal of Criminology},
  volume = {62},
  number = {6},
  pages = {1341--1358},
  issn = {0007-0955, 1464-3529},
  doi = {10.1093/bjc/azab111},
  url = {https://academic.oup.com/bjc/article/62/6/1341/6448791},
  urldate = {2025-06-16},
  abstract = {Abstract             Deepfake and digitally altered nude and sexual imagery is a serious and harmful emerging form of image-based sexual abuse (IBSA). This article reports on a multi-methods and cross-country study of IBSA across the United Kingdom, New Zealand and Australia, with a specific focus on the creation, distribution and threat to distribute deepfake and digitally altered imagery. Our findings suggest this abuse involves poly-victimization and poly-perpetration, and is disproportionately experienced and engaged in by those with mobility and/or communication assistance needs, members of the LGB+ community, males, young people and racial minorities (perpetration only). In this article, we discuss the pervasiveness and harms of deepfake and digitally altered imagery abuse, as well as challenges in legal responses, policing and prevention.},
  langid = {english},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/NDERYADD/Flynn et al._2022_Deepfakes and Digitally Altered Imagery Abuse A Cross-Country Exploration of an Emerging form of Im.pdf}
}

@online{förster2025,
  title = {A Multi-Level Strategy for Deepfake Content Moderation under {{EU}} Regulation},
  author = {Förster, Max-Paul and Deck, Luca and Weidlich, Raimund and Kühl, Niklas},
  date = {2025},
  doi = {10.48550/ARXIV.2507.08879},
  url = {https://arxiv.org/abs/2507.08879},
  urldate = {2025-07-23},
  abstract = {The growing availability and use of deepfake technologies increases risks for democratic societies, e.g., for political communication on online platforms. The EU has responded with transparency obligations for providers and deployers of Artificial Intelligence (AI) systems and online platforms. This includes marking deepfakes during generation and labeling deepfakes when they are shared. However, the lack of industry and enforcement standards poses an ongoing challenge. Through a multivocal literature review, we summarize methods for marking, detecting, and labeling deepfakes and assess their effectiveness under EU regulation. Our results indicate that individual methods fail to meet regulatory and practical requirements. Therefore, we propose a multi-level strategy combining the strengths of existing methods. To account for the masses of content on online platforms, our multi-level strategy provides scalability and practicality via a simple scoring mechanism. At the same time, it is agnostic to types of deepfake technology and allows for context-specific risk weighting.},
  pubstate = {prepublished},
  version = {1},
  keywords = {✅,Artificial Intelligence (cs.AI),Computers and Society (cs.CY),FOS: Computer and information sciences},
  file = {/Users/sgraf/Zotero/storage/52BG8K2D/Förster et al._2025_A Multi-Level Strategy for Deepfake Content Moderation under EU Regulation.pdf}
}

@article{franco2024,
  title = {“{{Controlling}} the Keys to the {{Golden City}}”: {{The}} Payment Ecosystem and the Regulation of Adult Webcamming and Subscription-Based Fan Platforms},
  shorttitle = {“{{Controlling}} the Keys to the {{Golden City}}”},
  author = {Franco, Rébecca S},
  date = {2024-12-11},
  journaltitle = {New Media \& Society},
  shortjournal = {New Media \& Society},
  pages = {14614448241303465},
  issn = {1461-4448, 1461-7315},
  doi = {10.1177/14614448241303465},
  url = {https://journals.sagepub.com/doi/10.1177/14614448241303465},
  urldate = {2025-06-04},
  abstract = {This article examines the role of payment intermediaries in regulating the platformized adult industry and demonstrates how the adult industry responds to their power and the rules they set. Based on 16 expert interviews, fieldwork at 3 industry conferences, and document analysis of rules, content guidelines, terms, and conditions, the author teases out the intricate interplay between credit card networks, payment processors, and adult platforms. Visa and Mastercard’s rules, enforced by payment processors and implemented by platforms, create a selective, private ordering of permissible content that surpasses legal requirements. This process is impelled by the brand safety and commercial interests of global corporations, without accountability to the industry or consideration for sex workers’ needs. The article calls for the need to hold payment intermediaries as de facto regulators of online sexual commerce and key actors in platform governance accountable toward the industry and workers they impact.},
  langid = {english}
}

@report{franzke2020,
  title = {Internet {{Research}}: {{Ethical Guidelines}} 3.0},
  author = {family=franzke, given=aline, prefix=shakti, useprefix=false and Bechmann, Anja and Zimmer, Michael and Ess, Charles},
  date = {2020},
  url = {https://aoir.org/reports/ethics3.pdf},
  file = {/Users/sgraf/Zotero/storage/3V3FBXQZ/tpm_v22_n1.pdf}
}

@article{frosio2018,
  title = {Why Keep a Dog and Bark Yourself? {{From}} Intermediary Liability to Responsibility},
  shorttitle = {Why Keep a Dog and Bark Yourself?},
  author = {Frosio, Giancarlo F},
  date = {2018-03-01},
  journaltitle = {International Journal of Law and Information Technology},
  volume = {26},
  number = {1},
  pages = {1--33},
  issn = {0967-0769, 1464-3693},
  doi = {10.1093/ijlit/eax021},
  url = {https://academic.oup.com/ijlit/article/26/1/1/4745804},
  urldate = {2025-04-07},
  langid = {english},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/245K7FNL/Frosio_2018_Why keep a dog and bark yourself From intermediary liability to responsibility.pdf}
}

@article{frosio2023,
  title = {Taking Fundamental Rights Seriously in the {{Digital Services Act}}'s Platform Liability Regime},
  author = {Frosio, Giancarlo and Geiger, Christophe},
  date = {2023-01},
  journaltitle = {European Law Journal},
  shortjournal = {European Law Journal},
  volume = {29},
  number = {1--2},
  pages = {31--77},
  issn = {1351-5993, 1468-0386},
  doi = {10.1111/eulj.12475},
  url = {https://onlinelibrary.wiley.com/doi/10.1111/eulj.12475},
  urldate = {2024-09-09},
  abstract = {Abstract             This article highlights how the EU fundamental rights framework should inform the liability regime of platforms foreseen in secondary EU law, in particular with regard to the reform of the E‐commerce directive by the Digital Services Act. In order to identify all possible tensions between the liability regime of platforms on the one hand, and fundamental rights on the other hand, and in order to contribute to a well‐balanced and proportionate European legal instrument, this article addresses these potential conflicts from the standpoint of users (those who share content and those who access it), platforms, regulators and other stakeholders involved. Section 2 delves into the intricate landscape of online intermediary liability, interrogating how the E‐Commerce Directive and the emerging Digital Services Act grapple with the delicate equilibrium between shielding intermediaries and upholding the competing rights of other stakeholders. The article then navigates in Section 3 the fraught terrain of fundamental rights as articulated by the European Court of Human Rights (ECtHR) and the Court of Justice of the European Union (CJEU) under the aegis of the European Convention on Human Rights and the EU Charter. This section poses an urgent inquiry: can the DSA's foundational principles reconcile these legal frameworks in a manner that fuels democracy rather than stifles it through inadvertent censorship? Section 4 then delves into the intricate relationship between fundamental rights and the DSA reform. This section conducts a comprehensive analysis of the key provisions of the DSA, emphasising how they underscore the importance of fundamental rights. In addition to mapping out the strengths of the framework the section also identifies existing limitations within the DSA and suggests potential pathways for further refinement and improvement. This article concludes by outlining key avenues for achieving a balanced and fundamental rights‐compliant regulatory framework for platform liability within the EU.},
  langid = {english},
  keywords = {⏳,unread},
  file = {/Users/sgraf/Zotero/storage/D2V558KY/Frosio und Geiger - 2023 - Taking fundamental rights seriously in the Digital.pdf}
}

@report{fticonsulting2025,
  type = {Audit report},
  title = {Independant Audit {{Article}} 37 of {{Regulation}} ({{EU}}) 2022/2065 ({{Digital Services Act}})},
  author = {{FTI Consulting}},
  date = {2025-04},
  pages = {286},
  url = {https://ei.phncdn.com/static/misc/legal/Audit_Report_for_Pornhub_April_2025_1753199885.pdf},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/S8J58UHH/Audit_Report_for_Pornhub_April_2025_1753199885.pdf}
}

@inproceedings{gamage2022,
  title = {Are {{Deepfakes Concerning}}? {{Analyzing Conversations}} of {{Deepfakes}} on {{Reddit}} and {{Exploring Societal Implications}}},
  shorttitle = {Are {{Deepfakes Concerning}}?},
  booktitle = {{{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Gamage, Dilrukshi and Ghasiya, Piyush and Bonagiri, Vamshi and Whiting, Mark E. and Sasahara, Kazutoshi},
  date = {2022-04-27},
  pages = {1--19},
  publisher = {ACM},
  location = {New Orleans LA USA},
  doi = {10.1145/3491102.3517446},
  url = {https://dl.acm.org/doi/10.1145/3491102.3517446},
  urldate = {2025-07-07},
  eventtitle = {{{CHI}} '22: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-4503-9157-3},
  langid = {english},
  keywords = {⏳},
  file = {/Users/sgraf/Zotero/storage/YQ8ILIB9/Gamage et al._2022_Are Deepfakes Concerning Analyzing Conversations of Deepfakes on Reddit and Exploring Societal Impl.pdf}
}

@article{garcia-navarro2024,
  entrysubtype = {nonacademic},
  title = {The {{Interview Childhood Stardom Is Rough}}. {{Jenna Ortega Is Still Recovering}}.},
  author = {Garcia-Navarro, Lulu},
  date = {2024-08-24},
  journaltitle = {The New York Times},
  url = {https://www.nytimes.com/2024/08/24/magazine/jenna-ortega-interview.html}
}

@book{ggplot22016,
  title = {Ggplot2: {{Elegant}} Graphics for Data Analysis},
  author = {Wickham, Hadley},
  date = {2016},
  publisher = {Springer-Verlag New York},
  url = {https://ggplot2.tidyverse.org},
  isbn = {978-3-319-24277-4}
}

@article{gillespie,
  title = {Reduction / {{Borderline}} Content / {{Shadowbanning}}},
  author = {Gillespie, Tarleton},
  langid = {english},
  keywords = {⏳},
  file = {/Users/sgraf/Zotero/storage/8YDPQJ4T/Gillespie_Reduction  Borderline content  Shadowbanning.pdf}
}

@book{gillespie2018a,
  title = {Custodians of the {{Internet}}: Platforms, Content Moderation, and the Hidden Decisions That Shape Social Media},
  shorttitle = {Custodians of the {{Internet}}},
  author = {Gillespie, Tarleton},
  date = {2018},
  publisher = {Yale University Press},
  location = {New Haven [Connecticut]},
  abstract = {"Most users want their Twitter feed, Facebook page, and YouTube comments to be free of harassment and porn. Whether faced with 'fake news' or livestreamed violence, 'content moderators'--who censor or promote user-posted content--have never been more important. This is especially true when the tools that social media platforms use to curb trolling, ban hate speech, and censor pornography can also silence the speech you need to hear. [The author] provides an overview of current social media practices and explains the underlying rationales for how, when, and why these policies are enforced. In doing so, [the author] highlights that content moderation receives too little public scrutiny even as it is shapes social norms and creates consequences for public discourse, cultural production, and the fabric of society. Based on interviews with content moderators, creators, and consumers, this ... book is ... for anyone who's ever clicked 'like' or 'retweet.'"},
  isbn = {978-0-300-17313-0 978-0-300-26143-1},
  langid = {english},
  keywords = {⏳},
  file = {/Users/sgraf/Zotero/storage/XUYMRA34/Gillespie_2018_Custodians of the Internet platforms, content moderation, and the hidden decisions that shape socia.pdf}
}

@article{gillespie2020,
  title = {Content Moderation, {{AI}}, and the Question of Scale},
  author = {Gillespie, Tarleton},
  date = {2020-07},
  journaltitle = {Big Data \& Society},
  shortjournal = {Big Data \& Society},
  volume = {7},
  number = {2},
  pages = {2053951720943234},
  issn = {2053-9517, 2053-9517},
  doi = {10.1177/2053951720943234},
  url = {https://journals.sagepub.com/doi/10.1177/2053951720943234},
  urldate = {2025-06-04},
  abstract = {AI seems like the perfect response to the growing challenges of content moderation on social media platforms: the immense scale of the data, the relentlessness of the violations, and the need for human judgments without wanting humans to have to make them. The push toward automated content moderation is often justified as a necessary response to the scale: the enormity of social media platforms like Facebook and YouTube stands as the reason why AI approaches are desirable, even inevitable. But even if we could effectively automate content moderation, it is not clear that we should.},
  langid = {english},
  keywords = {⏳},
  file = {/Users/sgraf/Zotero/storage/2TUKSY2D/Gillespie_2020_Content moderation, AI, and the question of scale.pdf}
}

@article{gillespie2020a,
  title = {Expanding the Debate about Content Moderation: {{Scholarly}} Research Agendas for the Coming Policy Debates},
  shorttitle = {Expanding the Debate about Content Moderation},
  author = {Gillespie, Tarleton and Aufderheide, Patricia and Carmi, Elinor and Gerrard, Ysabel and Gorwa, Robert and Matamoros-Fernández, Ariadna and Roberts, Sarah T. and Sinnreich, Aram and Myers West, Sarah},
  date = {2020-10-21},
  journaltitle = {Internet Policy Review},
  volume = {9},
  number = {4},
  publisher = {{Internet Policy Review, Alexander von Humboldt Institute for Internet and Society}},
  issn = {2197-6775},
  doi = {10.14763/2020.4.1512},
  url = {https://policyreview.info/articles/analysis/expanding-debate-about-content-moderation-scholarly-research-agendas-coming-policy},
  urldate = {2025-07-18},
  langid = {english},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/LT2WTPUG/Gillespie et al._2020_Expanding the debate about content moderation Scholarly research agendas for the coming policy deba.pdf}
}

@article{gillespie2022,
  title = {Do {{Not Recommend}}? {{Reduction}} as a {{Form}} of {{Content Moderation}}},
  shorttitle = {Do {{Not Recommend}}?},
  author = {Gillespie, Tarleton},
  date = {2022-07},
  journaltitle = {Social Media + Society},
  volume = {8},
  number = {3},
  publisher = {SAGE Publications},
  issn = {2056-3051, 2056-3051},
  doi = {10.1177/20563051221117552},
  url = {https://journals.sagepub.com/doi/10.1177/20563051221117552},
  urldate = {2025-07-21},
  abstract = {Public debate about content moderation has overwhelmingly focused on removal: social media platforms deleting content and suspending users, or opting not to do so. However, removal is not the only available remedy. Reducing the visibility of problematic content is becoming a commonplace element of platform governance. Platforms use machine learning classifiers to identify content they judge misleading enough, risky enough, or offensive enough that, while it does not warrant removal according to the site guidelines, warrants demoting them in algorithmic rankings and recommendations. In this essay, I document this shift and explain how reduction works. I then raise questions about what it means to use recommendation as a means of content moderation.},
  langid = {english},
  keywords = {⏳},
  file = {/Users/sgraf/Zotero/storage/9NP64EPA/Gillespie_2022_Do Not Recommend Reduction as a Form of Content Moderation.pdf}
}

@article{goldman2021,
  title = {Content {{Moderation Remedies}}},
  author = {Goldman, Eric},
  date = {2021},
  journaltitle = {SSRN Electronic Journal},
  shortjournal = {SSRN Journal},
  publisher = {Elsevier BV},
  issn = {1556-5068},
  doi = {10.2139/ssrn.3810580},
  url = {https://www.ssrn.com/abstract=3810580},
  urldate = {2025-07-20},
  langid = {english},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/EZ7IIJUI/Goldman_2021_Content Moderation Remedies.pdf}
}

@article{gongane2022,
  title = {Detection and Moderation of Detrimental Content on Social Media Platforms: Current Status and Future Directions},
  shorttitle = {Detection and Moderation of Detrimental Content on Social Media Platforms},
  author = {Gongane, Vaishali U. and Munot, Mousami V. and Anuse, Alwin D.},
  date = {2022-12},
  journaltitle = {Social Network Analysis and Mining},
  shortjournal = {Soc. Netw. Anal. Min.},
  volume = {12},
  number = {1},
  publisher = {{Springer Science and Business Media LLC}},
  issn = {1869-5450, 1869-5469},
  doi = {10.1007/s13278-022-00951-3},
  url = {https://link.springer.com/10.1007/s13278-022-00951-3},
  urldate = {2025-07-23},
  langid = {english},
  keywords = {⏳},
  file = {/Users/sgraf/Zotero/storage/67DNETBJ/Gongane et al._2022_Detection and moderation of detrimental content on social media platforms current status and future.pdf}
}

@online{goodfellow2014,
  title = {Generative {{Adversarial Networks}}},
  author = {Goodfellow, Ian J. and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  date = {2014},
  doi = {10.48550/ARXIV.1406.2661},
  url = {https://arxiv.org/abs/1406.2661},
  urldate = {2025-07-23},
  abstract = {We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to 1/2 everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples.},
  pubstate = {prepublished},
  version = {1},
  keywords = {⏳,✅,FOS: Computer and information sciences,Machine Learning (cs.LG),Machine Learning (stat.ML)},
  file = {/Users/sgraf/Zotero/storage/HTTQ2TXD/Goodfellow et al._2014_Generative Adversarial Networks.pdf}
}

@online{google2025,
  title = {{{YouTube Community Guidelines}} Enforcement},
  author = {{Google}},
  date = {2025},
  url = {https://transparencyreport.google.com/youtube-policy/removals?hl=en},
  organization = {Transparency report}
}

@report{google2025a,
  title = {{{EU Digital Services Act}} ({{EU DSA}}) Biannual {{VLOSE}}/{{VLOP}} Transparency Report},
  author = {{Google}},
  date = {2025-08-28},
  url = {https://storage.googleapis.com/transparencyreport/report-downloads/pdf-report-27_2025-1-1_2025-6-30_en_v1.pdf},
  file = {/Users/sgraf/Zotero/storage/6RTAQR5F/Google_2025_EU Digital Services Act (EU DSA) biannual VLOSEVLOP transparency report.pdf}
}

@article{gorwa2019,
  title = {What Is Platform Governance?},
  author = {Gorwa, Robert},
  date = {2019-05-12},
  journaltitle = {Information, Communication \& Society},
  shortjournal = {Information, Communication \& Society},
  volume = {22},
  number = {6},
  pages = {854--871},
  issn = {1369-118X, 1468-4462},
  doi = {10.1080/1369118X.2019.1573914},
  url = {https://www.tandfonline.com/doi/full/10.1080/1369118X.2019.1573914},
  urldate = {2024-11-24},
  langid = {english},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/3GTVIXSM/Gorwa - 2019 - What is platform governance.pdf}
}

@article{gorwa2020,
  title = {Algorithmic Content Moderation: {{Technical}} and Political Challenges in the Automation of Platform Governance},
  shorttitle = {Algorithmic Content Moderation},
  author = {Gorwa, Robert and Binns, Reuben and Katzenbach, Christian},
  date = {2020-01},
  journaltitle = {Big Data \& Society},
  shortjournal = {Big Data \& Society},
  volume = {7},
  number = {1},
  issn = {2053-9517, 2053-9517},
  doi = {10.1177/2053951719897945},
  url = {http://journals.sagepub.com/doi/10.1177/2053951719897945},
  urldate = {2025-03-14},
  langid = {english},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/EBI7HBG3/Gorwa et al._2020_Algorithmic content moderation Technical and political challenges in the automation of platform gov.pdf}
}

@book{gorwa2024a,
  title = {The Politics of Platform Regulation: {{How}} Governments Shape Online Content Moderation},
  shorttitle = {The {{Politics}} of {{Platform Regulation}}},
  author = {Gorwa, Robert},
  date = {2024},
  series = {Oxford {{Studies}} in {{Digital Politics}}},
  publisher = {Oxford University Press},
  location = {New York},
  abstract = {As digital platforms have become more integral to not just how we live, but also to how we do politics, the rules governing online expression, behavior, and interaction created by large multinational technology firms—popularly termed ‘content moderation,’ ‘platform governance,’ or ‘trust and safety’—have increasingly become the target of government regulatory efforts. This book provides a conceptual and empirical analysis of the important and emerging tech policy terrain of ‘platform regulation.’ How, why, and where exactly is it happening? Why now? And how do we best understand the vast array of strategies being deployed across jurisdictions to tackle this issue? The book outlines three strategies commonly pursued by government actors seeking to combat issues relating to the proliferation of hate speech, disinformation, child abuse imagery, and other forms of harmful content on user-generated content platforms: convincing, collaborating, and contesting. It then outlines a theoretical model for explaining the adoption of these different strategies in different political contexts and regulatory episodes. This model is explored through detailed case study chapters—driven by a combination of stakeholder interviews and new policymaking documents obtained via freedom of information requests—looking at policy development in Germany, Australia and New Zealand, and the United States},
  isbn = {978-0-19-769288-2 978-0-19-769285-1 978-0-19-769286-8},
  langid = {english},
  pagetotal = {1},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/SGQ4CMCT/Gorwa - 2024 - The Politics of Platform Regulation How Governmen.pdf}
}

@article{gorwa2024b,
  title = {Moderating Model Marketplaces: Platform Governance Puzzles for {{AI}} Intermediaries},
  shorttitle = {Moderating Model Marketplaces},
  author = {Gorwa, Robert and Veale, Michael},
  date = {2024-07-02},
  journaltitle = {Law, Innovation and Technology},
  volume = {16},
  number = {2},
  pages = {341--391},
  publisher = {Informa UK Limited},
  issn = {1757-9961, 1757-997X},
  doi = {10.1080/17579961.2024.2388914},
  url = {https://www.tandfonline.com/doi/full/10.1080/17579961.2024.2388914},
  urldate = {2025-05-22},
  langid = {english},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/9SV3IVIB/Gorwa und Veale_2024_Moderating model marketplaces platform governance puzzles for AI intermediaries.pdf}
}

@report{gorwa2024c,
  title = {Real {{Time Threats Analysis}} of {{Trust}} and {{Safety Practices}} for {{Child Sexual Exploitation}} and {{Abuse}} ({{CSEA}}) {{Prevention}} on {{Livestreaming Platforms}}},
  author = {Gorwa, Robert and Thakur, Dhanaraj},
  date = {2024-11},
  institution = {Center for Democracy \& Technology},
  url = {https://cdt.org/wp-content/uploads/2024/11/CDT-Research-Real-Time-Threats-hqp-final.pdf},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/JZH6UWVA/CDT-Research-Real-Time-Threats-hqp-final.pdf}
}

@article{gosztonyi2025,
  title = {The {{European}} Regulation of Porn Platforms before and after the {{Digital Services Act}}},
  author = {Gosztonyi, Gergely and Ruszkai, Szonja and Lendvai, Gergely Ferenc},
  date = {2025-04-04},
  journaltitle = {Porn Studies},
  shortjournal = {Porn Studies},
  pages = {1--16},
  issn = {2326-8743, 2326-8751},
  doi = {10.1080/23268743.2025.2476962},
  url = {https://www.tandfonline.com/doi/full/10.1080/23268743.2025.2476962},
  urldate = {2025-04-11},
  langid = {english},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/4KS2DISD/Gosztonyi et al._2025_The European regulation of porn platforms before and after the Digital Services Act.pdf}
}

@software{grieser2024,
  title = {Quadro – {{Qualitative Data Analysis Realized}} in {{Obsidian}}},
  author = {Grieser, Christopher},
  date = {2024-02-06},
  url = {https://github.com/chrisgrieser/quadro},
  abstract = {Obsidian Plugin for Qualitative Data Analysis (QDA). An open alternative to    `MAXQDA` and `atlas.ti`, using Markdown to store data and research codes.},
  version = {0.10.0}
}

@online{griffin2025b,
  title = {A {{Stakeholder Mapping}} and {{Research AgendaThe Politics}} of {{Risk}} in the {{Digital Services Act}}},
  author = {Griffin, Rachel},
  date = {2025},
  eprinttype = {Weizenbaum Institute},
  issn = {2748-5625},
  doi = {10.34669/WI.WJDS/5.2.6},
  url = {https://ojs.weizenbaum-institut.de/index.php/wjds/article/view/5_2_6},
  urldate = {2025-06-19},
  abstract = {The EU’s 2022 Digital Services Act requires large online platforms to regularly assess and mitigate ‘systemic risks’ to various public-interest goals, including fundamental rights, civic discourse, public health and security. Drawing on social constructionist understandings of risk, this article theorizes systemic risk management under the DSA as an arena for political power and contestation, since translating its broadly-defined abstract principles into actionable risk management procedures will entail making many contestable political decisions about how online platforms should be governed. This raises the question: who will exercise power in these decision-making processes? Providing some first answers to this question, this article makes three key contributions. First, it maps the key stakeholder groups involved, and the legal and institutional mechanisms through which they can participate in DSA systemic risk management. Second, it critically analyzes the power dynamics and unequal resources that will structure stakeholder participation. Third, this stakeholder mapping provides a foundation for future research on the politics of DSA systemic risks. The article concludes with reflections on directions for future research on the political agendas, priorities and strategies that shape platform governance.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {⏳,FOS: Law,FOS: Political science,FOS: Social sciences},
  file = {/Users/sgraf/Zotero/storage/TEM5F2CG/Griffin_2025_A Stakeholder Mapping and Research AgendaThe Politics of Risk in the Digital Services Act.pdf}
}

@article{griffin2025c,
  title = {Governing Platforms through Corporate Risk Management: The Politics of Systemic Risk in the {{Digital Services Act}}},
  shorttitle = {Governing Platforms through Corporate Risk Management},
  author = {Griffin, Rachel},
  date = {2025-06},
  journaltitle = {European Law Open},
  shortjournal = {European Law Open},
  volume = {4},
  number = {2},
  pages = {223--253},
  issn = {2752-6135},
  doi = {10.1017/elo.2025.17},
  url = {https://www.cambridge.org/core/product/identifier/S2752613525000177/type/journal_article},
  urldate = {2025-09-22},
  abstract = {Abstract             The EU’s 2022 Digital Services Act (DSA) requires large online platforms to assess and mitigate risks to various vaguely-defined and contestable values, including fundamental rights; public health and security; civic discourse; and people’s mental and physical wellbeing. The scope of these provisions is thus incredibly broad and they have unsurprisingly attracted significant academic interest. So far, most scholarship has taken a broadly functionalist approach: it accepts the basic premise that certain social impacts of platforms constitute risks which must be managed, and evaluates the DSA’s capacity to achieve this ‘effectively’.                            In contrast, this article aims to step back and critically reflect on the underlying conceptual and institutional framework of systemic risk management, based on an explicitly social constructionist understanding of risk as a technology of governance shaped by competing political agendas. Drawing on critical literature on risk regulation from various disciplines and regulatory fields, it identifies two key themes. First,               discursively               framing political problems as risks tends to exclude issues less amenable to the ‘risk’ framing; to privilege technocratic expertise; and to depoliticise distributive and ideological conflicts. Second, the DSA’s               institutional               approach to risk regulation delegates primary responsibility for identifying and managing risks to regulated companies, creating well-documented risks of capture. Overall, both themes point to similar conclusions: the systemic risk framework will be highly favourable to the interests of the powerful multinational corporations it seeks to regulate.                          In conclusion, however, the article notes that platform regulation may pose distinctive challenges that are not well illuminated by scholarship on risk regulation in other fields – notably because of the widely-recognised possibilities for political abuse of more prescriptive regulation of online media. It suggests some avenues for further research into risk politics in the specific context of online media platforms, in particular drawing on scholarship on risk management in critical security studies.},
  langid = {english},
  keywords = {⏳}
}

@article{grimmelmann2005,
  title = {Regulation by Software},
  author = {Grimmelmann, James},
  date = {2005},
  journaltitle = {Yale Law Journal},
  volume = {114},
  number = {1719},
  url = {https://ssrn.com/abstract=2358693},
  file = {/Users/sgraf/Zotero/storage/45DWTM7Z/Grimmelmann_2005_Regulation by software.pdf}
}

@article{grimmelmann2015,
  title = {The Virtues of Moderation},
  author = {Grimmelmann, James},
  date = {2015},
  journaltitle = {Yale Journal of Law \& Technology},
  volume = {17},
  number = {42},
  eprint = {20.500.13051/7798},
  eprinttype = {hdl},
  url = {http://hdl.handle.net/20.500.13051/7798},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/B8TXWMQM/Grimmelmann_2015_The Virtues of Moderation.pdf}
}

@incollection{grison2024,
  title = {Playing {{Hide}} and {{Seek}} with {{Algorithms}} in the“{{Gay TikTok}}”: {{From Shadowbanning}} to {{Platform Affordances}}},
  booktitle = {Online {{Virality}}: {{Spread}} and {{Influence}}},
  author = {Grison, Thilbaut},
  editor = {Schafer, Valérie and Pailler, Fred},
  date = {2024},
  pages = {S. 249 -- 268},
  keywords = {⏳},
  file = {/Users/sgraf/Zotero/storage/EDPGV7LA/Grison_2024_Playing Hide and Seek with Algorithms in the“Gay TikTok” From Shadowbanning to Platform Affordances.pdf}
}

@incollection{hacker2025,
  title = {Generative {{Discrimination}}: {{What Happens When Generative AI Exhibits Bias}}, and {{What Can Be Done About It}}},
  shorttitle = {Generative {{Discrimination}}},
  booktitle = {The {{Oxford Handbook}} of the {{Foundations}} and {{Regulation}} of {{Generative AI}}},
  author = {Hacker, Philipp and Mittelstadt, Brent and Wachter, Sandra and Zuiderveen Borgesius, Frederik},
  editor = {Hacker, Philipp and Mittelstadt, Brent and Hammer, Sarah and Engel, Andreas},
  date = {2025-04-22},
  edition = {1},
  publisher = {Oxford University Press},
  doi = {10.1093/oxfordhb/9780198940272.013.0016},
  url = {https://academic.oup.com/edited-volume/59908/chapter/512461244},
  urldate = {2025-05-20},
  abstract = {Abstract             As generative Artificial Intelligence (genAI) is increasingly used across sectors, its potential for societal benefit is paired with risks of discrimination. This chapter explores how genAI challenges non-discrimination law, identifying two primary types of discriminatory outputs: (i) demeaning and abusive content; and (ii) subtler biases from inadequate representation of protected groups. The latter includes genAI output that, while not discriminatory in a single instance, has discriminatory effects over time. For example, a genAI system may predominantly display white men when asked for examples of people in important jobs. The chapter examines the resources of existing EU law in addressing such cases and demonstrates how traditional legal categories, such as direct and indirect discrimination and harassment, are sometimes inadequate for genAI. The final part also offers suggestions on updating EU laws and mitigating biases pre-emptively in training and input data.},
  isbn = {978-0-19-894027-2 978-0-19-894030-2},
  langid = {english},
  keywords = {⏳},
  file = {/Users/sgraf/Zotero/storage/K4X9JJHH/Hacker et al._2025_Generative Discrimination What Happens When Generative AI Exhibits Bias, and What Can Be Done About.pdf}
}

@online{han2024,
  title = {Characterizing the {{MrDeepFakes Sexual Deepfake Marketplace}}},
  author = {Han, Catherine and Li, Anne and Kumar, Deepak and Durumeric, Zakir},
  date = {2024},
  doi = {10.48550/ARXIV.2410.11100},
  url = {https://arxiv.org/abs/2410.11100},
  urldate = {2025-04-05},
  abstract = {The prevalence of sexual deepfake material has exploded over the past several years. Attackers create and utilize deepfakes for many reasons: to seek sexual gratification, to harass and humiliate targets, or to exert power over an intimate partner. In part enabling this growth, several markets have emerged to support the buying and selling of sexual deepfake material. In this paper, we systematically characterize the most prominent and mainstream marketplace, MrDeepFakes. We analyze the marketplace economics, the targets of created media, and user discussions of how to create deepfakes, which we use to understand the current state-of-the-art in deepfake creation. Our work uncovers little enforcement of posted rules (e.g., limiting targeting to well-established celebrities), previously undocumented attacker motivations, and unexplored attacker tactics for acquiring resources to create sexual deepfakes.},
  pubstate = {prepublished},
  keywords = {✅,Computers and Society (cs.CY),Cryptography and Security (cs.CR),FOS: Computer and information sciences,Human-Computer Interaction (cs.HC),Social and Information Networks (cs.SI)},
  file = {/Users/sgraf/Zotero/storage/5N4LY9WS/Han et al._2024_Characterizing the MrDeepFakes Sexual Deepfake Marketplace.pdf}
}

@online{hao2023,
  title = {Safety and Fairness for Content Moderation in Generative Models},
  author = {Hao, Susan and Kumar, Piyush and Laszlo, Sarah and Poddar, Shivani and Radharapu, Bhaktipriya and Shelby, Renee},
  date = {2023},
  doi = {10.48550/ARXIV.2306.06135},
  url = {https://arxiv.org/abs/2306.06135},
  urldate = {2025-10-17},
  abstract = {With significant advances in generative AI, new technologies are rapidly being deployed with generative components. Generative models are typically trained on large datasets, resulting in model behaviors that can mimic the worst of the content in the training data. Responsible deployment of generative technologies requires content moderation strategies, such as safety input and output filters. Here, we provide a theoretical framework for conceptualizing responsible content moderation of text-to-image generative technologies, including a demonstration of how to empirically measure the constructs we enumerate. We define and distinguish the concepts of safety, fairness, and metric equity, and enumerate example harms that can come in each domain. We then provide a demonstration of how the defined harms can be quantified. We conclude with a summary of how the style of harms quantification we demonstrate enables data-driven content moderation decisions.},
  pubstate = {prepublished},
  version = {1},
  keywords = {Artificial Intelligence (cs.AI),FOS: Computer and information sciences,Machine Learning (cs.LG)}
}

@article{harper2021,
  title = {Delineating Non-Consensual Sexual Image Offending: {{Towards}} an Empirical Approach},
  shorttitle = {Delineating Non-Consensual Sexual Image Offending},
  author = {Harper, Craig A. and Fido, Dean and Petronzi, Dominic},
  date = {2021-05},
  journaltitle = {Aggression and Violent Behavior},
  shortjournal = {Aggression and Violent Behavior},
  volume = {58},
  pages = {101547},
  issn = {13591789},
  doi = {10.1016/j.avb.2021.101547},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S135917892100001X},
  urldate = {2025-06-03},
  langid = {english},
  keywords = {⏳},
  file = {/Users/sgraf/Zotero/storage/WMF32MRL/Harper et al._2021_Delineating non-consensual sexual image offending Towards an empirical approach.pdf}
}

@inproceedings{hawkins2025,
  title = {Deepfakes on {{Demand}}: The Rise of Accessible Non-Consensual Deepfake Image Generators},
  shorttitle = {Deepfakes on {{Demand}}},
  author = {Hawkins, Will and Russell, Chris and Mittelstadt, Brent},
  date = {2025},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.2505.03859},
  url = {https://arxiv.org/abs/2505.03859},
  urldate = {2025-05-20},
  abstract = {Advances in multimodal machine learning have made text-to-image (T2I) models increasingly accessible and popular. However, T2I models introduce risks such as the generation of non-consensual depictions of identifiable individuals, otherwise known as deepfakes. This paper presents an empirical study exploring the accessibility of deepfake model variants online. Through a metadata analysis of thousands of publicly downloadable model variants on two popular repositories, Hugging Face and Civitai, we demonstrate a huge rise in easily accessible deepfake models. Almost 35,000 examples of publicly downloadable deepfake model variants are identified, primarily hosted on Civitai. These deepfake models have been downloaded almost 15 million times since November 2022, with the models targeting a range of individuals from global celebrities to Instagram users with under 10,000 followers. Both Stable Diffusion and Flux models are used for the creation of deepfake models, with 96\% of these targeting women and many signalling intent to generate non-consensual intimate imagery (NCII). Deepfake model variants are often created via the parameter-efficient fine-tuning technique known as low rank adaptation (LoRA), requiring as few as 20 images, 24GB VRAM, and 15 minutes of time, making this process widely accessible via consumer-grade computers. Despite these models violating the Terms of Service of hosting platforms, and regulation seeking to prevent dissemination, these results emphasise the pressing need for greater action to be taken against the creation of deepfakes and NCII.},
  version = {1},
  keywords = {✅,68T01,Artificial Intelligence (cs.AI),Computer Vision and Pattern Recognition (cs.CV),Computers and Society (cs.CY),FOS: Computer and information sciences},
  file = {/Users/sgraf/Zotero/storage/EL7FX9MK/Hawkins et al._2025_Deepfakes on Demand the rise of accessible non-consensual deepfake image generators.pdf}
}

@inproceedings{henderson2023,
  title = {Self-{{Destructing Models}}: {{Increasing}} the {{Costs}} of {{Harmful Dual Uses}} of {{Foundation Models}}},
  shorttitle = {Self-{{Destructing Models}}},
  booktitle = {Proceedings of the 2023 {{AAAI}}/{{ACM Conference}} on {{AI}}, {{Ethics}}, and {{Society}}},
  author = {Henderson, Peter and Mitchell, Eric and Manning, Christopher and Jurafsky, Dan and Finn, Chelsea},
  date = {2023-08-08},
  pages = {287--296},
  publisher = {ACM},
  location = {Montréal QC Canada},
  doi = {10.1145/3600211.3604690},
  url = {https://dl.acm.org/doi/10.1145/3600211.3604690},
  urldate = {2025-08-03},
  eventtitle = {{{AIES}} '23: {{AAAI}}/{{ACM Conference}} on {{AI}}, {{Ethics}}, and {{Society}}},
  isbn = {979-8-4007-0231-0},
  langid = {english},
  file = {/Users/sgraf/Zotero/storage/WJM5T2MV/Henderson et al._2023_Self-Destructing Models Increasing the Costs of Harmful Dual Uses of Foundation Models.pdf}
}

@article{henry2018,
  title = {Policing Image-Based Sexual Abuse: Stakeholder Perspectives},
  shorttitle = {Policing Image-Based Sexual Abuse},
  author = {Henry, Nicola and Flynn, Asher and Powell, Anastasia},
  date = {2018-11-02},
  journaltitle = {Police Practice and Research},
  shortjournal = {Police Practice and Research},
  volume = {19},
  number = {6},
  pages = {565--581},
  issn = {1561-4263, 1477-271X},
  doi = {10.1080/15614263.2018.1507892},
  url = {https://www.tandfonline.com/doi/full/10.1080/15614263.2018.1507892},
  urldate = {2024-09-19},
  langid = {english},
  keywords = {⏳,❌},
  file = {/Users/sgraf/Zotero/storage/28XS22L2/Henry et al. - 2018 - Policing image-based sexual abuse stakeholder perspectives.pdf}
}

@article{henry2018a,
  title = {Technology-{{Facilitated Sexual Violence}}: {{A Literature Review}} of {{Empirical Research}}},
  shorttitle = {Technology-{{Facilitated Sexual Violence}}},
  author = {Henry, Nicola and Powell, Anastasia},
  date = {2018-04},
  journaltitle = {Trauma, Violence, \& Abuse},
  shortjournal = {Trauma, Violence, \& Abuse},
  volume = {19},
  number = {2},
  pages = {195--208},
  issn = {1524-8380, 1552-8324},
  doi = {10.1177/1524838016650189},
  url = {https://journals.sagepub.com/doi/10.1177/1524838016650189},
  urldate = {2025-06-12},
  abstract = {Technology-facilitated sexual violence (TFSV) refers to a range of behaviors where digital technologies are used to facilitate both virtual and face-to-face sexually based harms. Such behaviors include online sexual harassment, gender- and sexuality-based harassment, cyberstalking, image-based sexual exploitation, and the use of a carriage service to coerce a victim into an unwanted sexual act. This article reviews the current state of knowledge on these different dimensions, drawing on existing empirical studies. While there is a growing body of research into technology-facilitated harms perpetrated against children and adolescents, there is a dearth of qualitative and quantitative research on TFSV against adults. Moreover, few of the existing studies provide reliable data on the nature, scope, and impacts of TFSV. Preliminary studies, however, indicate that some harms, much like sexual violence more broadly, may be predominantly gender-, sexuality-, and age-based, with young women being overrepresented as victims in some categories. This review collects the empirical evidence to date regarding the prevalence and gender-based nature of TFSV against adults and discusses the implications for policy and programs, as well as suggestions for future research.},
  langid = {english},
  keywords = {⏳},
  file = {/Users/sgraf/Zotero/storage/5SD7V9C7/Henry und Powell_2018_Technology-Facilitated Sexual Violence A Literature Review of Empirical Research.pdf}
}

@article{hoboken2023,
  title = {Putting the {{DSA}} into {{Practice}}: {{Enforcement}}, {{Access}} to {{Justice}}, and {{Global Implications}}},
  shorttitle = {Putting the {{DSA}} into {{Practice}}},
  author = {Hoboken, Joris and Buri, Ilaria and Quintais, João and Fahy, Ronan and Appelman, Naomi and Straub, Marlene},
  with = {{Fachinformationsdienst Für Internationale Und Interdisziplinäre Rechtsforschung}},
  date = {2023},
  publisher = {Verfassungsbooks},
  doi = {10.17176/20230208-093135-0},
  url = {https://intr2dok.vifa-recht.de/receive/mir_mods_00015033},
  urldate = {2025-03-07},
  abstract = {Die Veröffentlichung des Gesetzes über digitale Dienste im Amtsblatt markiert das Ende eines jahrelangen Entwurfs- und Verhandlungsprozesses und schlägt ein neues Kapitel auf: das seiner Durchsetzung, des praktikablen Zugangs zur Justiz und des Potenzials, weltweite Präzedenzfälle zu schaffen. Das Gesetz wurde als Europas neue „digitale Verfassung“ bezeichnet, die den Vorrang der demokratischen Regelsetzung vor den privaten transnationalen Ordnungsmechanismen von Big Tech bekräftigt. Damit will die Europäische Union einmal mehr einen globalen Standard für die Regulierung des digitalen Umfelds setzen. Doch wird das Gesetz über digitale Dienste die Erwartungen erfüllen können, und unter welchen Bedingungen? Martin Husovec Will the Digital Services Act Work?: On Money and Effort Folkert Wilman Between Preservation and Clarification: The Evolution of the DSA's Liability Rules in Light of the CJEU's Case Law Sebastian Becker and Jan Penfrat The DSA Fails to Reign in the Most Harmful Digital Platform Businesses – But It Is Still Useful Alexandra Geese Why the DSA Could Save Us From the Rise of Authoritarian Regimes Ilaria Buri A Regulator Caught Between Conflicting Policy Objectives: Reflections on the European Commission ́s Role as DSA Enforcer Julian Jaursch Platform Oversight: Here is what a Strong Digital Services Coordinator Should Look Like Alessandro Mantelero Fundamental Rights Impact Assessment in the DSA Asha Allen An Intersectional Lens on Online Gender-Based Violence and the Digital Services Act Catalina Goanta Now What: Exploring the DSA's Enforcement Futures in Relation to Social Media Platforms and Native Advertising Pietro Ortolani If You Build it, They Will Come: The DSA “Procedure Before Substance” Approach Aleksandra Kuczerawy Remedying Overremoval Tomiwa Ilori Contextualisation over Replication: The Possible Impacts of the Digital Services Act on Content Regulation in African Countries Nayanatara Ranganathan Regulating Influence, Timidly Nicolo Zingales The DSA as a Paradigm Shift for Online Intermediaries' Due Diligence: Hail To Meta-Regulation Daphne Keller The European Union's New Digital Services Act and the Rest of the World},
  langid = {english},
  keywords = {⏳,340},
  file = {/Users/sgraf/Zotero/storage/6SWWR3VX/Hoboken et al._2023_Putting the DSA into Practice Enforcement, Access to Justice, and Global Implications.pdf}
}

@online{holznagel2025,
  title = {{{DSA}} - {{Risk Assessment}} \& {{Mitigation}}: 3 {{Thoughts}} on the First {{Reportings}}},
  author = {Holznagel, Daniel},
  date = {2025-06-25},
  url = {https://www.otto-schmidt.de/blog/it-recht-blog/dsa-risk-assessment-mitigation-3-thoughts-on-the-first-reportings-ITBLOG0007909.html},
  organization = {IT-Recht},
  keywords = {✅}
}

@online{holznagel2025a,
  type = {Analysis},
  title = {Shortcomings of the First {{DSA Audits}} — and How to Do Better},
  author = {Holznagel, Daniel},
  date = {2025-06-11},
  url = {https://dsa-observatory.eu/2025/06/11/shortcomings-of-the-first-dsa-audits-and-how-to-do-better/},
  urldate = {2025-09-18},
  organization = {DSA Observatory},
  keywords = {✅}
}

@report{homesecurityheroes2023,
  title = {2023 {{State}} of {{Deepfakes}}: {{Realities}}, {{Threats}}, and {{Impact}}},
  author = {{Home Security Heroes}},
  date = {2023},
  url = {https://www.securityhero.io/state-of-deepfakes/},
  file = {/Users/sgraf/Zotero/storage/W23FESU5/state-of-deepfake-infographic-2023.pdf}
}

@article{hoppenstedt2025,
  entrysubtype = {nonacademic},
  title = {The {{Growing Problem}} of {{Fake Porn Images}}},
  author = {Hoppenstedt, Max and Höfner, Roman and Buschek, Christo and Böhm, Markus},
  date = {2025-01-03},
  journaltitle = {spiegel.de},
  url = {https://www.spiegel.de/international/zeitgeist/artificial-intelligence-and-deepfakes-the-growing-problem-of-fake-porn-images-a-82fd8d6c-f4e3-4237-9066-978cbed496cf},
  urldate = {2025-05-05},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/K668MBL5/Hoppenstedt et al._2025_The Growing Problem of Fake Porn Images.pdf}
}

@article{huber2024,
  title = {Non-Consensual Intimate Image Distribution: {{Nature}}, Removal, and Implications for the {{Online Safety Act}}},
  shorttitle = {Non-Consensual Intimate Image Distribution},
  author = {Huber, Antoinette Raffaela and Ward, Zara},
  date = {2024-07-21},
  journaltitle = {European Journal of Criminology},
  shortjournal = {European Journal of Criminology},
  issn = {1477-3708, 1741-2609},
  doi = {10.1177/14773708241255821},
  url = {https://journals.sagepub.com/doi/10.1177/14773708241255821},
  urldate = {2024-09-09},
  abstract = {Research was conducted in partnership with the Revenge Porn Helpline (RPH) to examine the location and removal of non-consensual intimate image (NCII) abuse. By examining reports to the helpline, data were collected to uncover where intimate images were being non-consensually distributed, how they were proportionally distributed across platforms, and avenues for image removal. The data confirm that social media plays a key role in NCII distribution and provides further insight into where images are being distributed outside of social media platforms. Data on image removal indicate that knowledge of how to navigate different types of platforms is important for image removal success, making contributions from organisations such as the RPH vital, and highlighting the need to make reporting processes more accessible. The findings also indicate significant gaps within the Online Safety Act which will need to be addressed if the Act is to effectively protect victim-survivors. In particular, the need to move beyond focusing on services with the largest user numbers and broadening the scope to include smaller high-risk and problematic platforms.},
  langid = {english},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/855HFEAL/Huber und Ward - 2024 - Non-consensual intimate image distribution Nature.pdf}
}

@article{husovec2023,
  title = {Rising above Liability: The {{Digital Services Act}} as a Blueprint for the Second Generation of Global Internet Rules},
  shorttitle = {Rising {{Above Liability}}},
  author = {Husovec, Martin},
  date = {2023},
  publisher = {Berkeley Technology Journal},
  doi = {10.15779/Z38M902431},
  url = {https://lawcat.berkeley.edu/record/1287997},
  urldate = {2025-03-29},
  keywords = {⏳},
  file = {/Users/sgraf/Zotero/storage/ERCXRAPU/Husovec, Martin;_2023_Rising Above Liability The Digital Services Act as a Blueprint for the Second Generation Of Global.pdf}
}

@book{husovec2024b,
  title = {Principles of the Digital Services Act},
  author = {Husovec, Martin},
  date = {2024},
  publisher = {Oxford University Press},
  location = {Oxford},
  doi = {10.1093/law-ocl/9780192882455.001.0001},
  abstract = {"Numerous questions were at the heart of parliamentary discussions over the provisions of the Digital Services Act (DSA), the EU's new regulatory framework for digital services in Europe. How should liberal democracies prevent illegal and harmful activities online and protect fundamental rights? How should digital service providers assess the impact of their technology on others? And how should technology companies moderate user-generated content? "Principles of the Digital Services Act" analyses the DSA's key provisions, dissecting its mechanisms and components, to understand the new law's likely impact on digital services in Europe and beyond."--},
  isbn = {978-0-19-288245-5 978-0-19-197678-0},
  langid = {english},
  pagetotal = {1},
  keywords = {⏳},
  file = {/Users/sgraf/Zotero/storage/IFG4E9IY/Husovec_2024_Principles of the digital services act.pdf;/Users/sgraf/Zotero/storage/WLN7QHHF/Husovec_Scans.pdf}
}

@report{internetmatters.org2024,
  title = {The New Face of Digital Abuse: {{Children}}'s Experiences of Nude Deepfakes},
  author = {{internetmatters.org}},
  date = {2024-10},
  url = {https://www.internetmatters.org/hub/research/children-experiences-nude-deepfakes-research/},
  urldate = {2025-07-02},
  keywords = {⏳},
  file = {/Users/sgraf/Zotero/storage/BUKJGSUH/internetmatters.org_2024_The new face of digital abuse Children's experiences of nude deepfakes.pdf}
}

@article{jacobs2024,
  title = {{{DIY}} Pornography and the Deepfake Coup},
  author = {Jacobs, Katrien},
  date = {2024-01-02},
  journaltitle = {Porn Studies},
  shortjournal = {Porn Studies},
  volume = {11},
  number = {1},
  pages = {91--98},
  issn = {2326-8743, 2326-8751},
  doi = {10.1080/23268743.2023.2297691},
  url = {https://www.tandfonline.com/doi/full/10.1080/23268743.2023.2297691},
  urldate = {2025-06-05},
  langid = {english}
}

@article{jacobs2024a,
  title = {{{DIY}} Pornography and the Deepfake Coup},
  author = {Jacobs, Katrien},
  date = {2024-01-02},
  journaltitle = {Porn Studies},
  shortjournal = {Porn Studies},
  volume = {11},
  number = {1},
  pages = {91--98},
  issn = {2326-8743, 2326-8751},
  doi = {10.1080/23268743.2023.2297691},
  url = {https://www.tandfonline.com/doi/full/10.1080/23268743.2023.2297691},
  urldate = {2025-07-04},
  langid = {english},
  keywords = {⏳}
}

@article{jacobsen2024,
  title = {Deepfakes and the Promise of Algorithmic Detectability},
  author = {Jacobsen, Benjamin N},
  date = {2024-04-02},
  journaltitle = {European Journal of Cultural Studies},
  shortjournal = {European Journal of Cultural Studies},
  pages = {13675494241240028},
  issn = {1367-5494, 1460-3551},
  doi = {10.1177/13675494241240028},
  url = {https://journals.sagepub.com/doi/10.1177/13675494241240028},
  urldate = {2025-06-04},
  abstract = {Deepfakes, as a sociocultural and technical phenomenon, have engendered two distinct yet intimately interwoven set of responses: on one hand, they have created widespread anxieties concerning the potential and harmful impact of deepfakes. On the other hand, they have also given rise to a new regime of detection: tools, models, and methods that are developed and used to detect whether something is a deepfake or not. However, the ways in which machine learning algorithms are being framed as the solution to the problem of deepfake detection have not received sufficient critical attention. Drawing on the 2019 Deepfake Detection Challenge organised by Meta as well as finding resonances in the work of Eyal Weizman, this article seeks to problematise and unsettle what I call the promise of algorithmic detectability. That is, the claim that machine learning algorithms render the issue of deepfake detection knowable, tractable, and resolvable. Examining the themes of training data, thresholds, and certainty, I emphasise the inherent difficulties, intractabilities and contingencies of deepfake detection models. Ultimately, I argue that the promise of algorithmic detectability falls short and that the ethico-politics of deepfakes cannot be reduced solely to a framework of detection algorithms.},
  langid = {english},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/BQ3DTLCQ/Jacobsen_2024_Deepfakes and the promise of algorithmic detectability.pdf}
}

@article{jaroucheh2020,
  title = {{{TRUSTD}}: Combat Fake Content Using Blockchain and Collective Signature Technologies},
  shorttitle = {{{TRUSTD}}},
  author = {Jaroucheh, Zakwan and Alissa, Mohamad and Buchanan, William J},
  date = {2020},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.2008.13632},
  url = {https://arxiv.org/abs/2008.13632},
  urldate = {2025-10-17},
  abstract = {The growing trend of sharing news/contents, through social media platforms and the World Wide Web has been seen to impact our perception of the truth, altering our views about politics, economics, relationships, needs and wants. This is because of the growing spread of misinformation and disinformation intentionally or unintentionally by individuals and organizations. This trend has grave political, social, ethical, and privacy implications for society due to 1) the rapid developments in the field of Machine Learning (ML) and Deep Learning (DL) algorithms in creating realistic-looking yet fake digital content (such as text, images, and videos), 2) the ability to customize the content feeds and to create a polarized so-called "filter-bubbles" leveraging the availability of the big-data. Therefore, there is an ethical need to combat the flow of fake content. This paper attempts to resolve some of the aspects of this combat by presenting a high-level overview of TRUSTD, a blockchain and collective signature-based ecosystem to help content creators in getting their content backed by the community, and to help users judge on the credibility and correctness of these contents.},
  version = {1},
  keywords = {Cryptography and Security (cs.CR),FOS: Computer and information sciences}
}

@article{jaursch2024a,
  title = {The {{Digital Services Act}} Is in Effect – Now What?},
  author = {Jaursch, Julian},
  date = {2024},
  langid = {english},
  file = {/Users/sgraf/Zotero/storage/M5Z2USFB/Jaursch_2024_The Digital Services Act is in effect – now what.pdf}
}

@article{jiang2022,
  title = {A Trade-off-Centered Framework of Content Moderation},
  author = {Jiang, Jialun Aaron and Nie, Peipei and Brubaker, Jed R. and Fiesler, Casey},
  date = {2022},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.2206.03450},
  url = {https://arxiv.org/abs/2206.03450},
  urldate = {2025-10-17},
  abstract = {Content moderation research typically prioritizes representing and addressing challenges for one group of stakeholders or communities in one type of context. While taking a focused approach is reasonable or even favorable for empirical case studies, it does not address how content moderation works in multiple contexts. Through a systematic literature review of 86 content moderation papers that document empirical studies, we seek to uncover patterns and tensions within past content moderation research. We find that content moderation can be characterized as a series of trade-offs around moderation actions, styles, philosophies, and values. We discuss how facilitating cooperation and preventing abuse, two key elements in Grimmelmann's definition of moderation, are inherently dialectical in practice. We close by showing how researchers, designers, and moderators can use our framework of trade-offs in their own work, and arguing that trade-offs should be of central importance in investigating and designing content moderation.},
  version = {1},
  keywords = {Computers and Society (cs.CY),FOS: Computer and information sciences,Human-Computer Interaction (cs.HC),J.4; K.4.2}
}

@article{jones2024,
  entrysubtype = {nonacademic},
  title = {Spain Sentences 15 Schoolchildren over {{AI-generated}} Naked Images},
  author = {Jones, Sam},
  date = {2024-07-09},
  journaltitle = {theguardian.com},
  url = {https://www.theguardian.com/world/article/2024/jul/09/spain-sentences-15-school-children-over-ai-generated-naked-images},
  urldate = {2025-03-22}
}

@online{jóźwiak2024,
  title = {The Wait Is (Almost) over! {{First}} Risk Assessment and Audit Reports – What Will Be Published, When, and the Way Forward},
  author = {Jóźwiak, Magdalena},
  date = {2024-11-22},
  url = {https://dsa-observatory.eu/2024/11/22/the-wait-is-almost-over-first-risk-assessment-and-audit-reports-what-will-be-published-when-and-the-way-forward/},
  organization = {DSA Observatory},
  keywords = {✅}
}

@report{jugendschutz.net2024,
  title = {Bericht {{Jugendschutz}} Im {{Internet}} 2023 - {{Risiken}} Und {{Handlungsbedarf}}},
  author = {{Jugendschutz.net}},
  date = {2024-07},
  url = {https://www.jugendschutz.net/fileadmin/daten/publikationen/jahresberichte/jahresbericht_2023.pdf},
  urldate = {2024-08-29},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/6ZE6Z4Z5/Jugendschutz.net - 2024 - Bericht Jugendschutz im Internet 2023 - Risiken un.pdf}
}

@book{jünger2023,
  title = {Computational Methods für die Sozial- und Geisteswissenschaften},
  author = {Jünger, Jakob and Gärtner, Chantal},
  date = {2023},
  publisher = {Springer Fachmedien Wiesbaden},
  location = {Wiesbaden},
  doi = {10.1007/978-3-658-37747-2},
  url = {https://link.springer.com/10.1007/978-3-658-37747-2},
  urldate = {2025-04-11},
  isbn = {978-3-658-37746-5 978-3-658-37747-2},
  langid = {ngerman},
  keywords = {⏳},
  file = {/Users/sgraf/Zotero/storage/6EZCB8ZA/Jünger und Gärtner_2023_Computational Methods für die Sozial- und Geisteswissenschaften.pdf;/Users/sgraf/Zotero/storage/B4MXMFP7/Jünger und Gärtner_2023_Computational Methods für die Sozial- und Geisteswissenschaften.pdf}
}

@online{karaboga2024,
  title = {Deepfakes und manipulierte Realitäten - Technologiefolgenabschätzung und Handlungsempfehlungen für die Schweiz},
  author = {Karaboga, Murat and Frei, Nula and Puppis, Manuel and Vogler, Daniel and Raemy, Patric and Ebbers, Frank and Runge, Greta and Rauchfleisch, Adrian and family=Seta, given=Gabriela, prefix=de, useprefix=true and Gurr, Gwendolin and Friedewald, Michael and Rovelli, Sophia},
  date = {2024-06-18},
  eprinttype = {vdf},
  doi = {10.5281/ZENODO.11643644},
  url = {https://zenodo.org/doi/10.5281/zenodo.11643644},
  urldate = {2025-07-29},
  abstract = {A deepfake is an audio or (moving) image content synthesised or manipulated with the aid of artificial intelligence technologies, which appears to be authentic and in which a person says or does something that he or she has never said or done. Since 2017, when synthetic and manipulated media content was firstreferred to as “deepfake”, the term has become firmly entrenched in political and media debate. Several years after its introduction, we can now draw some mixed conclusions: some political deepfakes and deepfake-based fraud cases, for example nuisance or scam calls, appear to confirm certain concerns. On the other hand, avariety of useful applications have been created that are based on synthetic and manipulated media content. Neither the widely feared large-scale use of deepfakes in disinformation campaigns nor a major information apocalypse have materialised to date. The purpose of this study is to assess the opportunities and risks associated with deepfakes for Switzerland.},
  langid = {ngerman},
  pubstate = {prepublished},
  keywords = {⏳},
  file = {/Users/sgraf/Zotero/storage/BGI7JA29/Karaboga et al._2024_Deepfakes und manipulierte Realitäten - Technologiefolgenabschätzung und Handlungsempfehlungen für d.pdf}
}

@article{karagianni2024,
  title = {A Feminist Legal Analysis of Non-Consensual Sexualized Deepfakes: Contextualizing Its Impact as {{AI-generated}} Image-Based Violence under {{EU}} Law},
  shorttitle = {A Feminist Legal Analysis of Non-Consensual Sexualized Deepfakes},
  author = {Karagianni, Anastasia and Doh, Miriam},
  date = {2024-11-14},
  journaltitle = {Porn Studies},
  shortjournal = {Porn Studies},
  pages = {1--18},
  issn = {2326-8743, 2326-8751},
  doi = {10.1080/23268743.2024.2408277},
  url = {https://www.tandfonline.com/doi/full/10.1080/23268743.2024.2408277},
  urldate = {2025-06-03},
  langid = {english},
  keywords = {⏳},
  file = {/Users/sgraf/Zotero/storage/7CRGA978/Karagianni und Doh_2024_A feminist legal analysis of non-consensual sexualized deepfakes contextualizing its impact as AI-g.pdf}
}

@article{karasavva2022,
  title = {Personality, {{Attitudinal}}, and {{Demographic Predictors}} of {{Non-consensual Dissemination}} of {{Intimate Images}}},
  author = {Karasavva, V. and Forth, A.},
  date = {2022-11},
  journaltitle = {Journal of Interpersonal Violence},
  shortjournal = {J Interpers Violence},
  volume = {37},
  number = {21--22},
  pages = {NP19265-NP19289},
  issn = {0886-2605, 1552-6518},
  doi = {10.1177/08862605211043586},
  url = {https://journals.sagepub.com/doi/10.1177/08862605211043586},
  urldate = {2025-06-04},
  abstract = {Non-consensual intimate image dissemination (NCII), or else better known as “revenge pornography” is a form of technology-facilitated sexual violence that can have devastating effects on the victim. This is one of the first studies examining how demographic characteristics (gender, sexual orientation), personality traits (Dark Tetrad), and attitudes (aggrieved entitlement, sexual entitlement, sexual image abuse myth acceptance) predict NCII perpetration and victimization. In a sample of 810 undergraduate students (72.7\% female and 23.3\% male), 13.7\% of the participants had at some point in their life, distributed nude, or sexual pictures of someone else without consent and 28.5\% had experienced such victimization. NCII perpetration was predictive of NCII victimization and vice versa. Using binomial logistic regression, we found that women, members of the LGBQ+ community, those scoring higher in sadism, and participants with a history of NCII perpetration were more likely to report that someone had distributed their nude or sexual image without consent. Further, we found that those scoring higher in narcissism and sadism, along with those with a history of NCII victimization were more likely to report they had distributed the nude or sexual image of someone else without consent. Finally, the findings suggest that the relationship between victims and perpetrators is quite a bit more varied than the term “revenge pornography” implies.},
  langid = {english},
  file = {/Users/sgraf/Zotero/storage/RBYUSRSN/Karasavva und Forth_2022_Personality, Attitudinal, and Demographic Predictors of Non-consensual Dissemination of Intimate Ima.pdf}
}

@article{karasavva2023,
  title = {From Myth to Reality: Sexual Image Abuse Myth Acceptance, the {{Dark Tetrad}}, and Non-Consensual Intimate Image Dissemination Proclivity},
  shorttitle = {From Myth to Reality},
  author = {Karasavva, Vasileia and Swanek, Jessie and Smodis, Audrey and Forth, Adelle},
  date = {2023-01-02},
  journaltitle = {Journal of Sexual Aggression},
  shortjournal = {Journal of Sexual Aggression},
  volume = {29},
  number = {1},
  pages = {51--67},
  issn = {1355-2600, 1742-6545},
  doi = {10.1080/13552600.2022.2032430},
  url = {https://www.tandfonline.com/doi/full/10.1080/13552600.2022.2032430},
  urldate = {2025-06-03},
  langid = {english},
  keywords = {⏳},
  file = {/Users/sgraf/Zotero/storage/BWCV5XID/Karasavva et al._2023_From myth to reality sexual image abuse myth acceptance, the Dark Tetrad, and non-consensual intima.pdf}
}

@book{katzenbach2018,
  title = {Die Regeln digitaler Kommunikation},
  author = {Katzenbach, Christian},
  date = {2018},
  publisher = {Springer Fachmedien Wiesbaden},
  location = {Wiesbaden},
  doi = {10.1007/978-3-658-19337-9},
  url = {http://link.springer.com/10.1007/978-3-658-19337-9},
  urldate = {2025-03-14},
  isbn = {978-3-658-19336-2 978-3-658-19337-9},
  langid = {ngerman},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/8E6TYHQE/Katzenbach_2018_Die Regeln digitaler Kommunikation.pdf}
}

@report{kaye2018,
  type = {Report of the UN Special Rapporteur on the promotion and protection of the Right to Freedom of Opinion and Expression.},
  title = {A Human Rights Approach to Platform Content Regulation},
  author = {Kaye, David},
  date = {2018},
  number = {A/HRC/38/35},
  url = {https://docs.un.org/en/A/HRC/38/35}
}

@article{keller2018,
  entrysubtype = {nonacademic},
  title = {Don’t Force {{Google}} to Export Other Countries’ Laws},
  author = {Keller, Daphne},
  date = {2018-09-10},
  journaltitle = {New York Times},
  url = {https://www.nytimes.com/2018/09/10/opinion/google-right-forgotten.html}
}

@book{kelly1988,
  title = {Surviving Sexual Violence},
  author = {Kelly, Liz},
  date = {1988},
  publisher = {Polity Press},
  location = {Cambridge Oxford},
  abstract = {Women's awareness of the threat and reality of sexual violence is now perhaps more than ever publicly acknowledged. Yet this fact continues to be almost wholly ignored. This new study, based on in-depth interviews with 60 women, is the first to cover the experience of a range of forms of sexual violence over women's lifetimes. Drawing on feminist theory, developing a critique of male research and quoting extensively from the women interviewed, it developes feminist thought in several key areas: the similarities and differences between forms of sexual violence; the ways women define their experiences; and the strategies women use in resisting, coping with and surviving sexual violence. The author stresses the importance for all women of recognizing the incidents of sexual violence in their lives and seeing themselves and other women as survivors rather than victims. In highlighting the ways in which the media, the criminal justice system and even the 'helping' profess ions contribute to the trivialization of sexual violence, she demonstrates the necessity of women organizing collectively to end this suffering},
  langid = {english},
  pagetotal = {273}
}

@article{kharvi2024,
  title = {Understanding the {{Impact}} of {{AI-Generated Deepfakes}} on {{Public Opinion}}, {{Political Discourse}}, and {{Personal Security}} in {{Social Media}}},
  author = {Kharvi, Prakash L.},
  date = {2024-07},
  journaltitle = {IEEE Security \& Privacy},
  shortjournal = {IEEE Secur. Privacy},
  volume = {22},
  number = {4},
  pages = {115--122},
  publisher = {{Institute of Electrical and Electronics Engineers (IEEE)}},
  issn = {1540-7993, 1558-4046},
  doi = {10.1109/msec.2024.3405963},
  url = {https://ieeexplore.ieee.org/document/10552098/},
  urldate = {2025-07-23}
}

@incollection{kikerpill2021,
  title = {Dealing with {{Deepfakes}}: {{Reddit}}, {{Online Content Moderation}}, and {{Situational Crime Prevention}}},
  shorttitle = {Dealing with {{Deepfakes}}},
  booktitle = {Studies in {{Media}} and {{Communications}}},
  author = {Kikerpill, Kristjan and Siibak, Andra and Valli, Suido},
  editor = {Wiest, Julie B.},
  date = {2021-03-25},
  pages = {25--45},
  publisher = {Emerald Publishing Limited},
  doi = {10.1108/S2050-206020210000020008},
  url = {https://www.emerald.com/insight/content/doi/10.1108/S2050-206020210000020008/full/html},
  urldate = {2025-06-03},
  isbn = {978-1-83909-112-4 978-1-83909-111-7},
  keywords = {❌}
}

@article{kira2024,
  title = {When Non-Consensual Intimate Deepfakes Go Viral: {{The}} Insufficiency of the {{UK Online Safety Act}}},
  shorttitle = {When Non-Consensual Intimate Deepfakes Go Viral},
  author = {Kira, Beatriz},
  date = {2024-09},
  journaltitle = {Computer Law \& Security Review},
  shortjournal = {Computer Law \& Security Review},
  volume = {54},
  pages = {106024},
  issn = {02673649},
  doi = {10.1016/j.clsr.2024.106024},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0267364924000906},
  urldate = {2024-09-09},
  abstract = {Advancements in artificial intelligence (AI) have drastically simplified the creation of synthetic media. While concerns often focus on potential misinformation harms, ‘non-consensual intimate deepfakes’ (NCID) – a form of image-based sexual abuse – pose a current, severe, and growing threat, disproportionately impacting women and girls. This article examines the measures implemented with the recently adopted Online Safety Act 2023 (OSA) and argues that the new criminal offences and the ‘systems and processes’ approach the law adopts are insufficient to counter NCID in the UK. This is because the OSA relies on platform policies that often lack consistency regarding synthetic media and on platforms’ content removal mechanisms which offer limited redress to victimsurvivors after the harm has already occurred. The article argues that stronger prevention mechanisms are necessary and proposes that the law should mandate all AI-powered deepfake creation tools to ban the generation of intimate synthetic content and require the implementation of comprehensive and enforceable content moderation systems.},
  langid = {english},
  keywords = {⏳,✅},
  file = {/Users/sgraf/Zotero/storage/L7249PTT/Kira - 2024 - When non-consensual intimate deepfakes go viral T.pdf}
}

@report{kleemann2023,
  title = {Deepfakes - wenn wir unseren Augen und Ohren nicht mehr trauen können: Medienmanipulationen im Konflikt: Herausforderungen und Bewältigungsstrategien},
  shorttitle = {Deepfakes - wenn wir unseren Augen und Ohren nicht mehr trauen können},
  author = {Kleemann, Aldo},
  date = {2023},
  journaltitle = {SWP-Aktuell 43/2023},
  number = {43},
  institution = {{Stiftung Wissenschaft und Politik, German Institute for International and Security Affairs}},
  doi = {10.18449/2023A43},
  url = {https://www.swp-berlin.org/10.18449/2023A43/},
  urldate = {2025-10-17},
  langid = {ngerman},
  version = {1}
}

@article{klonick2017,
  title = {The New Governors: The People, Rules, and Processes Governing Online Speech},
  author = {Klonick, Kate},
  date = {2017},
  journaltitle = {Harvard Law Review},
  volume = {131},
  number = {1598},
  url = {https://ssrn.com/abstract=2937985}
}

@article{köver2022,
  entrysubtype = {nonacademic},
  title = {World's Largest Porn Site: {{How XVideos}} Does Very Little against Sexualized Violence},
  author = {Köver, Chris and Meineck, Sebastian},
  date = {2022-03-11},
  journaltitle = {netzpolitik.org},
  url = {https://netzpolitik.org/2022/how-xvideos-does-very-little-against-sexualized-violence/},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/KQN2VG23/Köver und Meineck_2022_Weltgrößte Pornoseite  So wenig tut XVideos gegen sexualisierte Gewalt.pdf}
}

@article{kozlovski2025,
  entrysubtype = {nonacademic},
  title = {Deepfakes and {{Beyond}}: {{Mapping}} the {{Ethics}} and {{Risks}} of {{Digital Duplicates}}},
  author = {Kozlovski, Atay},
  date = {2025-05-13},
  journaltitle = {Tech Policy Press},
  url = {https://www.techpolicy.press/deepfakes-and-beyond-mapping-the-ethics-and-risks-of-digital-duplicates/},
  keywords = {⏳},
  file = {/Users/sgraf/Zotero/storage/I6IF5IA6/Kozlovski_2025_Deepfakes and Beyond Mapping the Ethics and Risks of Digital Duplicates.pdf}
}

@book{kraut2012,
  title = {Building Successful Online Communities: Evidence-Based Social Design},
  shorttitle = {Building {{Successful Online Communities}}},
  author = {Kraut, Robert E. and Resnick, Paul},
  date = {2012-03-23},
  publisher = {The MIT Press},
  doi = {10.7551/mitpress/8472.001.0001},
  url = {https://direct.mit.edu/books/book/2912/Building-Successful-Online-CommunitiesEvidence},
  urldate = {2025-10-17},
  abstract = {How insights from the social sciences, including social psychology and economics, can improve the design of online communities.             Online communities are among the most popular destinations on the Internet, but not all online communities are equally successful. For every flourishing Facebook, there is a moribund Friendster—not to mention the scores of smaller social networking sites that never attracted enough members to be viable. This book offers lessons from theory and empirical research in the social sciences that can help improve the design of online communities.             The authors draw on the literature in psychology, economics, and other social sciences, as well as their own research, translating general findings into useful design claims. They explain, for example, how to encourage information contributions based on the theory of public goods, and how to build members' commitment based on theories of interpersonal bond formation. For each design claim, they offer supporting evidence from theory, experiments, or observational studies.},
  isbn = {978-0-262-29831-5},
  langid = {english}
}

@article{kristof2020,
  entrysubtype = {nonacademic},
  title = {The Children of {{Pornhub}}: {{Why Does Canada Allow This}}. {{Company}} to {{Profit Off Videos}} of {{Exploitation}} and {{Assault}}?},
  author = {Kristof, Nicholas},
  date = {2020},
  journaltitle = {New York Times},
  url = {https://www.nytimes.com/2020/12/04/opinion/sunday/pornhub-rape-trafficking.html}
}

@article{łabuz2023,
  title = {Regulating {{Deep Fakes}} in the {{Artificial Intelligence Act}}},
  author = {Łabuz, Mateusz},
  date = {2023-10-27},
  journaltitle = {Applied Cybersecurity \& Internet Governance},
  shortjournal = {Applied Cybersecurity \& Internet Governance},
  volume = {2},
  number = {1},
  pages = {1--42},
  issn = {2956-3119, 2956-4395},
  doi = {10.60097/ACIG/162856},
  url = {https://www.acigjournal.com/Regulating-Deep-Fakes-in-the-Artificial-Intelligence-Act,184302,0,2.html},
  urldate = {2025-05-20},
  abstract = {The Artificial Intelligence Act (AI Act) may be a milestone of regulating artificial intelligence by the European Union. Regulatory framework proposed by the European Commission has the potential to serve as a benchmark worldwide and strengthen the position of the EU as one of the main players of the technology market. One of the components of the regulation are the provisions on deep fakes, which include the definition, classification as a “specific risk” AI system and transparency obligations. Deep fakes rightly arouse controversy and are assessed as a complex phenomenon, the negative use of which significantly increases the risk of political manipulation, and at the same time contributes to disinformation, undermining trust in information or in the media. The AI Act may strengthen the protection of citizens against some of the negative consequences of misusing deep fakes, although the impact of the regulatory framework in its current form will be limited due to the specificity of creating and disseminating deep fakes. The effectiveness of the provisions will depend not only on the enforcement capabilities, but also on the precision of phrasing provisions to prevent misinterpretation and deliberate abuse of exceptions. At the same time, the AI Act will not cover a significant part of deep fakes, which, due to the malicious intentions of their creators, will not be subject to the protection in the form of transparency obligations. This study allows for the analysis of provisions relating to deep fakes in the AI Act and proposing improvements that will take into account the specificity of this phenomenon to a greater extent.},
  keywords = {⏳},
  file = {/Users/sgraf/Zotero/storage/IRB3SD64/Łabuz_2023_Regulating Deep Fakes in the Artificial Intelligence Act.pdf}
}

@article{łabuz2025,
  title = {A {{Teleological Interpretation}} of the {{Definition}} of {{DeepFakes}} in the {{EU Artificial Intelligence Act}}—{{A Purpose}}‐{{Based Approach}} to {{Potential Problems With}} the {{Word}} “{{Existing}}”},
  author = {Łabuz, Mateusz},
  date = {2025-03},
  journaltitle = {Policy \& Internet},
  shortjournal = {Policy \&amp; Internet},
  volume = {17},
  number = {1},
  pages = {e435},
  issn = {1944-2866, 1944-2866},
  doi = {10.1002/poi3.435},
  url = {https://onlinelibrary.wiley.com/doi/10.1002/poi3.435},
  urldate = {2025-05-20},
  abstract = {ABSTRACT             The EU Artificial Intelligence Act is the world's first attempt to holistically regulate artificial intelligence. It presents an extensive, multi‐faceted definition of deepfakes, and introduces specific safeguards against their misuses. These guardrails have the potential to become a global role model. The AI Act uses concepts that leave room for interpretation, which is important given the constant development of technology and the need for adjustments. However, some solutions raise the problem of vagueness, which in turn may result in a narrower interpretation of a linguistic nature, and reduce the scope of legally permissible countermeasures. The aim of this study is to critically evaluate the definition of deepfakes contained in the AI Act in relation to the word “existing” used. A narrow interpretation could potentially exclude some synthetic media from the scope of transparency obligations due to the non‐classification of these media as deepfakes. Therefore, a teleological interpretation of the provisions is proposed, reinforced with elements of systemicity, so that the safeguards built by the AI Act also include deepfakes that do not depict any identifiable pre‐existing persons, objects, places, entities or events to better reflect goals of the regulation, and complement the value‐based system of the AI Act.           ,              摘要:             欧盟《人工智能法案》是世界上用于全面监管人工智能的首次尝试。该法案对深度伪造技术进行了广泛、多方面的定义, 并引入了防止其滥用的具体保障措施。这些措施有可能成为全球榜样。《人工智能法案》使用的概念留有解释空间, 鉴于技术的不断发展和调整的需要, 这一点很重要。然而, 一些解决方案提出了模糊性的问题, 这反过来可能导致对语言性质的更狭隘的解释, 并缩小法律允许的对策范围。本研究旨在批判性地评价《人工智能法案》中与“现有”一词相关的深度伪造技术的定义。狭义解释可能会将某些合成媒体排除在透明度义务范围之外, 因为这些媒体不被归类为深度伪造。因此, 建议对这些条款进行目的论解释, 并辅以系统性要素, 以便《人工智能法案》建立的保障措施也包括那些“不描绘任何可识别的预先存在的人、物体、地点、实体或事件”的深度伪造, 以期更好地反映监管目标, 并补充《人工智能法案》的价值体系。           ,              Resumen:             La Ley de Inteligencia Artificial de la UE es el primer intento del mundo de regular de manera holística la inteligencia artificial. Presenta una definición extensa y multifacética de deep fakes e introduce salvaguardas específicas contra su uso indebido. Estas barandillas tienen el potencial de convertirse en un modelo global a seguir. La Ley de IA utiliza conceptos que dejan espacio para la interpretación, lo cual es importante dado el constante desarrollo de la tecnología y la necesidad de ajustes. Sin embargo, algunas soluciones plantean el problema de la vaguedad, que a su vez puede dar lugar a una interpretación más estrecha de naturaleza lingüística y reducir el alcance de las contramedidas legalmente permisibles. El objetivo de este estudio es evaluar críticamente la definición de deep fakes contenida en la Ley de IA en relación con la palabra “existente” utilizada. Una interpretación estricta podría excluir algunos medios sintéticos del ámbito de aplicación de las obligaciones de transparencia debido a la no clasificación de estos medios como deep fakes. Por lo tanto, se propone una interpretación teleológica de las disposiciones, reforzada con elementos de sistematicidad, de modo que las salvaguardas construidas por la Ley de IA también incluyan deep fakes que no retraten ninguna persona, objeto, lugar, entidad o evento preexistente identificable para reflejar mejor los objetivos de la regulación y complementar el sistema basado en valores de la Ley de IA.},
  langid = {english},
  keywords = {⏳},
  file = {/Users/sgraf/Zotero/storage/HLMVAEYX/Łabuz_2025_A Teleological Interpretation of the Definition of DeepFakes in the EU Artificial Intelligence Act—A.pdf}
}

@article{lakshané2024,
  title = {Non-Consensual Intimate Imagery: An Overview},
  shorttitle = {Non-Consensual Intimate Imagery},
  author = {Lakshané, Rohini},
  date = {2024-03-25},
  publisher = {Take Back The Tech},
  doi = {10.5281/ZENODO.10980144},
  url = {https://zenodo.org/doi/10.5281/zenodo.10980144},
  urldate = {2025-07-21},
  abstract = {Take Back the Tech! is proud to present this overview paper regarding non-consensual intimate imagery (NCII) by Rohini Lakshané. It unpacks definitions, the impact on survivors/victims, how morality and victim-blaming is often interwoven in responses, the difficulty of action, types of legislation (and limits) to address it, and, importantly, resources for take-down and coping with NCII. As noted in the introduction, NCII refers to intimate photos or videos that are captured, published or distributed without the explicit consent of the person(s) depicted in those images. The meaning and connotations of what constitutes an intimate or sexually explicit image changes vastly with social and cultural norms and contexts in different parts of the world. In this document, we define intimate images as sexually explicit, nude or partially nude photos or videos. They are a violation of privacy and of consent, and are a type of technology-facilitated gender-based violence (TFGBV). When perpetrated by intimate partners, NCII are also a form of intimate partner violence (IPV) or domestic violence. NCII impinge on the victim’s right to privacy, sexual consent, their freedom of (sexual) expression, and right to live free from violence. The majority of the victims of NCII are known to be women or gender-diverse persons. However, NCII victims may belong to any gender or sexual orientation. Symptomatic of the surveillance economy, which threatens the freedom of expression and speech of women, gender-diverse and LGBTQIA+ persons, NCII is often accompanied by personal and identifying details and captured or commodified in order to extort, threaten or inflict harm. First published at: https://www.takebackthetech.net/blog/non-consensual-intimate-imagery-overview ~ Deleted versions of this document This is a list of the previous (deleted) DOIs of this document. They were retracted on account of errors in formatting, layout, errors etc of this document. While no published version of this document has ever contained any factual errors, the ones listed here have been retracted. Hence, please do not refer to them and delete any copies you may have of these documents.~~ https://zenodo.org/doi/10.5281/zenodo.11655780 https://zenodo.org/records/12698227 https://zenodo.org/records/11656105 https://zenodo.org/records/10911462 https://zenodo.org/records/10893868 https://zenodo.org/records/10893867 https://zenodo.org/uploads/12277588},
  langid = {english},
  keywords = {⏳,GBV,Gender studies,gender-based violence,IBSA,image-based abuse,image-based sexual abuse,NCII,non-consensual intimate images,OGBV,Sexual violence,TFGBV,VAW},
  file = {/Users/sgraf/Zotero/storage/PT2ENE9C/Lakshané_2024_Non-consensual intimate imagery an overview.pdf}
}

@report{landesanstaltfürmediennrw2024,
  title = {Erfahrung von {{Kindern}} Und {{Jugendlichen}} Mit {{Sexting}} Und {{Pornos}} –~{{Zentrale Ergebnisse}} Der {{Befragung}}},
  author = {{Landesanstalt für Medien NRW}},
  date = {2024-09},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/F9TGXMPA/Landesanstalt für Medien NRW - 2024 - Erfahrung von Kindern und Jugendlichen mit Sexting.pdf}
}

@article{lapointe2025,
  title = {The {{Present}} and {{Future}} of {{Adult Entertainment}}: {{A Content Analysis}} of {{AI-Generated Pornography Websites}}},
  shorttitle = {The {{Present}} and {{Future}} of {{Adult Entertainment}}},
  author = {Lapointe, Valerie A. and Dubé, Simon and Rukhlyadyev, Sophia and Kessai, Tinhinane and Lafortune, David},
  date = {2025-03-03},
  journaltitle = {Archives of Sexual Behavior},
  shortjournal = {Arch Sex Behav},
  issn = {0004-0002, 1573-2800},
  doi = {10.1007/s10508-025-03099-1},
  url = {https://link.springer.com/10.1007/s10508-025-03099-1},
  urldate = {2025-06-03},
  langid = {english},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/K252F6BQ/Lapointe et al._2025_The Present and Future of Adult Entertainment A Content Analysis of AI-Generated Pornography Websit.pdf}
}

@inproceedings{laranjeiradasilva2022,
  title = {Seeing without Looking: Analysis Pipeline for Child Sexual Abuse Datasets},
  shorttitle = {Seeing without {{Looking}}},
  booktitle = {2022 {{ACM Conference}} on {{Fairness Accountability}} and {{Transparency}}},
  author = {Laranjeira da Silva, Camila and Macedo, Joao and Avila, Sandra and Dos Santos, Jefersson},
  date = {2022-06-21},
  pages = {2189--2205},
  publisher = {ACM},
  location = {Seoul Republic of Korea},
  doi = {10.1145/3531146.3534636},
  url = {https://dl.acm.org/doi/10.1145/3531146.3534636},
  urldate = {2025-10-17},
  eventtitle = {{{FAccT}} '22: 2022 {{ACM Conference}} on {{Fairness}}, {{Accountability}}, and {{Transparency}}},
  isbn = {978-1-4503-9352-2},
  langid = {english}
}

@article{latour1991,
  title = {Technology Is Society Made Durable},
  author = {Latour, Bruno},
  editor = {Law, J.},
  date = {1991},
  journaltitle = {A sociology of monsters essays on power, technology and domination: Sociological Review},
  shortjournal = {The Sociological Review},
  volume = {38},
  pages = {103--131},
  issn = {0038-0261, 1467-954X},
  doi = {10.1111/j.1467-954X.1990.tb03350.x},
  url = {https://journals.sagepub.com/doi/10.1111/j.1467-954X.1990.tb03350.x},
  urldate = {2025-10-13},
  abstract = {Is it possible to devise a set of concepts that could replace the technology/society divide? This set of new concepts - association and substitution - might help to rephrase some of the traditional questions of social order and especially that of the durability of domination of power. However, instead of using different tools to analyse power and weakness, it is argued that power and domination are simply different values of variables that should be studied in their whole range. By reconstructing networks it is argued that a full description of power and domination may be obtained.},
  issue = {1\_suppl},
  langid = {english},
  file = {/Users/sgraf/Zotero/storage/JMNBMEB2/46-TECHNOLOGY-DURABLE-GBpdf-2.pdf}
}

@article{leerssen2024,
  title = {Outside the Black Box: {{From}} Algorithmic Transparency to Platform Observability in the {{Digital Services Act}}},
  shorttitle = {Outside the {{Black Box}}},
  author = {Leerssen, Paddy},
  date = {2024},
  journaltitle = {Weizenbaum Journal of the Digital Society},
  volume = {4},
  number = {2},
  publisher = {Weizenbaum Institute},
  issn = {2748-5625},
  doi = {10.34669/WI.WJDS/4.2.3},
  url = {https://ojs.weizenbaum-institut.de/index.php/wjds/article/view/4_2_3},
  urldate = {2024-10-17},
  abstract = {Algorithmic transparency is high on the agenda for social media regulation. However, recent work in Science and Technology Studies questions whether this endeavor of “opening the black box” is feasible or even meaningful due to the sociotechnical contingency of platform behavior. To address these shortcomings, Bernhard Rieder and Jeannette Hoffman have proposed a move from algorithmic transparency to platform observability: a pragmatic and sociotechnical perspective aimed at securing structural, real-time access to the means of platform knowledge production. This paper applies the concept of observability to recent legislative developments in the EU’s new Digital Services Act. Reviewing that legislation’s transparency rules demonstrates how familiar algorithmic principles rules are starting to be complemented by innovative new observability policies and how these reflect revised understandings of transparency’s possible subjects, functions, and formats. This review also surfaces normative tensions in observability policy. In terms of substance, observability demands access to content but struggles to discern public from private discourses in semi-public social media channels. In terms of function, observability aims to act as a companion to regulation, but tensions arise between a broad concept of knowledge production and a narrow concept of regulatory compliance monitoring. In terms of format, observability’s drive for infrastructural and real-time access entails new API governance tradeoffs between, for example, scope and scalability. Along these lines, observability paves the way for a more constructive debate around platform data access laws and the dead ends of algorithmic transparency.},
  langid = {english},
  keywords = {✅,read},
  file = {/Users/sgraf/Zotero/storage/4P6MHDDB/Leerssen - 2024 - Outside the Black Box From Algorithmic Transparen.pdf}
}

@article{light2018a,
  title = {The Walkthrough Method: {{An}} Approach to the Study of Apps},
  shorttitle = {The Walkthrough Method},
  author = {Light, Ben and Burgess, Jean and Duguay, Stefanie},
  date = {2018-03},
  journaltitle = {New Media \& Society},
  volume = {20},
  number = {3},
  pages = {881--900},
  publisher = {SAGE Publications},
  issn = {1461-4448, 1461-7315},
  doi = {10.1177/1461444816675438},
  url = {https://journals.sagepub.com/doi/10.1177/1461444816675438},
  urldate = {2025-05-23},
  abstract = {Software applications (apps) are now prevalent in the digital media environment. They are the site of significant sociocultural and economic transformations across many domains, from health and relationships to entertainment and everyday finance. As relatively closed technical systems, apps pose new methodological challenges for sociocultural digital media research. This article describes a method, grounded in a combination of science and technology studies with cultural studies, through which researchers can perform a critical analysis of a given app. The method involves establishing an app’s environment of expected use by identifying and describing its vision, operating model and modes of governance. It then deploys a walkthrough technique to systematically and forensically step through the various stages of app registration and entry, everyday use and discontinuation of use. The walkthrough method establishes a foundational corpus of data upon which can be built a more detailed analysis of an app’s intended purpose, embedded cultural meanings and implied ideal users and uses. The walkthrough also serves as a foundation for further user-centred research that can identify how users resist these arrangements and appropriate app technology for their own purposes.},
  langid = {english},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/BC8B6KXW/Light et al._2018_The walkthrough method An approach to the study of apps.pdf}
}

@article{lord2020,
  title = {Pornhub: {{Opening}} the {{Floodgates}}?},
  shorttitle = {Pornhub},
  author = {Lord, Phil},
  date = {2020},
  journaltitle = {SSRN Electronic Journal},
  shortjournal = {SSRN Journal},
  issn = {1556-5068},
  doi = {10.2139/ssrn.3751640},
  url = {https://www.ssrn.com/abstract=3751640},
  urldate = {2025-08-17},
  langid = {english},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/4HYY6JTD/Lord_2020_Pornhub Opening the Floodgates.pdf}
}

@online{lyu2020,
  title = {{{DeepFake}} Detection: Current Challenges and next Steps},
  shorttitle = {{{DeepFake Detection}}},
  author = {Lyu, Siwei},
  date = {2020},
  doi = {10.48550/ARXIV.2003.09234},
  url = {https://arxiv.org/abs/2003.09234},
  urldate = {2025-10-17},
  abstract = {High quality fake videos and audios generated by AI-algorithms (the deep fakes) have started to challenge the status of videos and audios as definitive evidence of events. In this paper, we highlight a few of these challenges and discuss the research opportunities in this direction.},
  pubstate = {prepublished},
  version = {1},
  keywords = {Computer Vision and Pattern Recognition (cs.CV),FOS: Computer and information sciences}
}

@inproceedings{macdonald2023,
  title = {The Algorithmic Moderation of Sexual Expression: {{Pornhub}}, Payment Processors and {{CSAM}}},
  shorttitle = {{{THE ALGORITHMIC MODERATION OF SEXUAL EXPRESSION}}},
  booktitle = {{{AoIR Selected Papers}} of {{Internet Research}}},
  author = {MacDonald, Maggie},
  date = {2023-12-31},
  doi = {10.5210/spir.v2023i0.13453},
  url = {https://spir.aoir.org/ojs/index.php/spir/article/view/13453},
  urldate = {2025-06-03},
  abstract = {Pornography platforms are increasingly required by payment processor business partners to mitigate harm in their content management systems through algorithmic moderation. Demands that adult merchants incorporate these tools are not proportional to instances of harmful content, but a response to the widespread conflation of pornography with harm and risk online. This paper explores co-governance by payment processors calling for algorithmic tools through the case of Pornhub, asking: what standards are required by financial firms, how are these enforced on platforms, and what effects does this arrangement have on porn content? I open with key context regarding the deplatforming of sex, antiporn campaigning and constructions of harm through 'reputational risk’. Following this, I detail financial firms infrastructural influence in platform co-governance. Next, a close reading of adult merchant terms identifies specific clauses calling for algorithmic moderation. Concluding this issue mapping, I provide a taxonomy of moderation tools in place on Pornhub. I close with an issue discussion to consider AI's positioning as a regulatory solution, CSAM data ethics, moderator labour, and the many technical problems obscured by promises of safety through automated content management systems. The resulting review of algorithmic measures enforced by financial firms offers a detailed case of the opaque governance conditions imperilling sexual expression across porn platforms.},
  keywords = {⏳},
  file = {/Users/sgraf/Zotero/storage/CNPTQLCI/MacDonald_2023_THE ALGORITHMIC MODERATION OF SEXUAL EXPRESSION PORNHUB, PAYMENT PROCESSORS AND CSAM.pdf}
}

@article{mackenzie2024,
  entrysubtype = {nonacademic},
  title = {Inside the Deepfake Porn Crisis Engulfing {{Korean}} Schools},
  author = {Mackenzie, Jean and Choi, Leehyun},
  date = {2024-09-03},
  journaltitle = {bbc.com},
  url = {https://www.bbc.com/news/articles/cpdlpj9zn9go},
  urldate = {2025-03-22},
  keywords = {❌}
}

@article{mackenzie2024a,
  entrysubtype = {nonacademic},
  title = {South {{Korea}} Faces Deepfake Porn 'Emergency'},
  author = {Mackenzie, Jean and Marsh, Nick},
  date = {2024-08-28},
  journaltitle = {bbc.com},
  url = {https://www.bbc.com/news/articles/cg4yerrg451o},
  urldate = {2025-03-22},
  file = {/Users/sgraf/Zotero/storage/XXM24NLA/Mackenzie und Marsh_South Korea faces deepfake porn 'emergency'.pdf}
}

@incollection{macqueen2008,
  title = {Teambased Codebook Development: Structure, Process, and Agreement},
  booktitle = {Handbook for Team-Based Qualitative Research},
  author = {MacQueen, Kathleen M. and McLellan-Lemal, E. and Bartholow, K. and Milstein, B.},
  editor = {Guest, Greg and MacQueen, Kathleen M.},
  date = {2008},
  pages = {119--135},
  publisher = {Altamira Press},
  location = {Lanham New York Toronto Plymouth, UK},
  isbn = {978-0-7591-0911-7 978-0-7591-0910-0},
  langid = {english}
}

@article{maddocks2018,
  title = {From {{Non-consensual Pornography}} to {{Image-based Sexual Abuse}}: {{Charting}} the {{Course}} of a {{Problem}} with {{Many Names}}},
  shorttitle = {From {{Non-consensual Pornography}} to {{Image-based Sexual Abuse}}},
  author = {Maddocks, Sophie},
  date = {2018-07-03},
  journaltitle = {Australian Feminist Studies},
  shortjournal = {Australian Feminist Studies},
  volume = {33},
  number = {97},
  pages = {345--361},
  issn = {0816-4649, 1465-3303},
  doi = {10.1080/08164649.2018.1542592},
  url = {https://www.tandfonline.com/doi/full/10.1080/08164649.2018.1542592},
  urldate = {2025-06-10},
  langid = {english},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/SNKAZB8G/Maddocks_2018_From Non-consensual Pornography to Image-based Sexual Abuse Charting the Course of a Problem with M.pdf}
}

@article{maddocks2020,
  title = {‘{{A Deepfake Porn Plot Intended}} to {{Silence Me}}’: Exploring Continuities between Pornographic and ‘Political’ Deep Fakes},
  shorttitle = {‘{{A Deepfake Porn Plot Intended}} to {{Silence Me}}’},
  author = {Maddocks, Sophie},
  date = {2020-10},
  journaltitle = {Porn Studies},
  shortjournal = {Porn Studies},
  volume = {7},
  number = {4},
  pages = {415--423},
  issn = {2326-8743, 2326-8751},
  doi = {10.1080/23268743.2020.1757499},
  url = {https://www.tandfonline.com/doi/full/10.1080/23268743.2020.1757499},
  urldate = {2025-06-03},
  langid = {english},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/3G3KVR7G/Maddocks_2020_‘A Deepfake Porn Plot Intended to Silence Me’ exploring continuities between pornographic and ‘poli.pdf}
}

@online{madio2025,
  title = {Asymmetric {{Content Moderation}} in {{Search Markets}}: {{The Case}} of {{Adult Websites}}},
  shorttitle = {Asymmetric {{Content Moderation}} in {{Search Markets}}},
  author = {Madio, Leonardo and Mitchell, Matthew F. and Quinn, Martin and Reggiani, Carlo},
  date = {2025},
  eprinttype = {SSRN},
  doi = {10.2139/ssrn.5106235},
  url = {https://www.ssrn.com/abstract=5106235},
  urldate = {2025-06-04},
  pubstate = {prepublished}
}

@article{maiberg2025,
  entrysubtype = {nonacademic},
  title = {Mr. {{Deepfakes}}, the {{Biggest Deepfake Porn Site}} on the {{Internet}}, {{Says It}}’s {{Shutting Down}} for {{Good}}},
  author = {Maiberg, Emanuel and Cole, Samantha},
  date = {2025-05-04},
  journaltitle = {404 Media},
  url = {https://www.404media.co/mr-deepfakes-the-biggest-deepfake-porn-site-on-the-internet-says-its-shutting-down-for-good/},
  keywords = {✅,❌}
}

@article{maiberg2025a,
  entrysubtype = {nonacademic},
  title = {How {{OnlyFans}} Piracy Is Ruining the Internet for Everyone},
  author = {Maiberg, Emanuel},
  date = {2025-09-01},
  journaltitle = {404 Media},
  url = {https://www.404media.co/how-onlyfans-piracy-is-ruining-the-internet-for-everyone/},
  keywords = {⏳,❌}
}

@article{mania2020,
  title = {The {{Legal Implications}} and {{Remedies Concerning Revenge Porn}} and {{Fake Porn}}: {{A Common Law Perspective}}},
  shorttitle = {The {{Legal Implications}} and {{Remedies Concerning Revenge Porn}} and {{Fake Porn}}},
  author = {Mania, Karolina},
  date = {2020-12},
  journaltitle = {Sexuality \& Culture},
  shortjournal = {Sexuality \& Culture},
  volume = {24},
  number = {6},
  pages = {2079--2097},
  issn = {1095-5143, 1936-4822},
  doi = {10.1007/s12119-020-09738-0},
  url = {https://link.springer.com/10.1007/s12119-020-09738-0},
  urldate = {2024-09-09},
  abstract = {Abstract             Based on US and British regulations in force, this article offers an overview of legislation of two Common Law countries in the area of modern forms of law infringements focusing on the notions of revenge porn and fake porn. The first part contains definitions and descriptions of the terms ‘revenge porn’ and ‘fake porn’, pointing out to the context of the relationship between the dynamic technological development and use of artificial intelligence on the one hand and the regulatory framework failing to meet the current needs on the other. Further, examination is conducted of US and British legislation in force divided into civil and criminal law, indicating legislative gaps as well as the inefficiency of the existing legal solutions and presenting a range of proposals of legislative changes. The considerations have been supplemented with the results of the author’s assessment of sociological and statistical research available in source literature carried thus far in the field in question. The following section is dedicated to a comparative assessment of American and British legal solutions based on selected, critical issues. The final parts of the article serve to postulate systemic changes in legislation and is a proposal to introduce out-of-court dispute settlement methods in legal disputes pertaining to the matters discussed herein, and to~frame future research directions.},
  langid = {english},
  keywords = {✅,legal},
  file = {/Users/sgraf/Zotero/storage/KQHCHGX7/Mania - 2020 - The Legal Implications and Remedies Concerning Rev.pdf}
}

@article{mania2024,
  title = {Legal {{Protection}} of {{Revenge}} and {{Deepfake Porn Victims}} in the {{European Union}}: {{Findings From}} a {{Comparative Legal Study}}},
  shorttitle = {Legal {{Protection}} of {{Revenge}} and {{Deepfake Porn Victims}} in the {{European Union}}},
  author = {Mania, Karolina},
  date = {2024-01},
  journaltitle = {Trauma, Violence, \& Abuse},
  shortjournal = {Trauma, Violence, \& Abuse},
  volume = {25},
  number = {1},
  pages = {117--129},
  issn = {1524-8380, 1552-8324},
  doi = {10.1177/15248380221143772},
  url = {https://journals.sagepub.com/doi/10.1177/15248380221143772},
  urldate = {2025-08-03},
  abstract = {The use of images of persons in a pornographic context (without the prior consent of the person concerned) on the internet is an increasingly widespread infringement. Unlawful activities carried out with the use of generated images and artificial intelligence are a variant of this phenomenon. “Revenge porn” and “deepfake porn” illustrate the inadequacy of legal systems vis a vis the fast-changing reality. Using the comparative law method, a comparison was made between the current laws of nine EU Member States to create a map of protection for victims of revenge porn. As the results showed, in three of the studied countries there is a separate incrimination of revenge porn; however, the conceptual scope of its definition is significantly different and it is these differences that determine the legal way for the victims to assert their rights. This article is a comparison of the current legal regulations of selected European Union countries and the means of legal protection used by the victims. The text presents the differences occurring in the legal systems adopted in the countries subject to analysis, as well as an assessment of possible solutions at the legal and technological level to face the existing problem.},
  langid = {english},
  keywords = {⏳}
}

@article{maris2020,
  title = {Tracking Sex: {{The}} Implications of Widespread Sexual Data Leakage and Tracking on Porn Websites},
  shorttitle = {Tracking Sex},
  author = {Maris, Elena and Libert, Timothy and Henrichsen, Jennifer R},
  date = {2020-11},
  journaltitle = {New Media \& Society},
  shortjournal = {New Media \& Society},
  volume = {22},
  number = {11},
  pages = {2018--2038},
  issn = {1461-4448, 1461-7315},
  doi = {10.1177/1461444820924632},
  url = {https://journals.sagepub.com/doi/10.1177/1461444820924632},
  urldate = {2025-06-04},
  abstract = {This article explores tracking and privacy risks on pornography websites. Our analysis of 22,484 pornography websites indicated that 93\% leak user data to a third-party. Tracking on these sites is highly concentrated by a handful of major companies, which we identify. We successfully extracted privacy policies for 3856 sites, 17\% of the total. The policies were written such that one might need a 2-year college education to understand them. Our content analysis of the sample’s domains indicated 44.97\% of them expose or suggest a specific gender/sexual identity or interest likely to be linked to the user. We identify three core implications of the quantitative results: (1) the unique/elevated risks of porn data leakage versus other types of data, (2) the particular risks/impact for “vulnerable” populations, and (3) the complications of providing consent for porn site users and the need for affirmative consent in these online sexual interactions.},
  langid = {english},
  file = {/Users/sgraf/Zotero/storage/Z8ZEQ33S/Maris et al._2020_Tracking sex The implications of widespread sexual data leakage and tracking on porn websites.pdf}
}

@article{mast2024a,
  title = {Forschungsdatenzugang und Technologieregulierung},
  author = {Mast, Tobias},
  date = {2024},
  journaltitle = {Wissenschaftsrecht},
  shortjournal = {WissR},
  volume = {57},
  number = {2},
  pages = {101},
  issn = {0948-0218},
  doi = {10.1628/wissr-2024-0011},
  url = {https://www.mohrsiebeck.com/10.1628/wissr-2024-0011},
  urldate = {2025-01-06},
  langid = {ngerman},
  keywords = {⏳,❌}
}

@article{mccosker2024,
  title = {Making Sense of Deepfakes: {{Socializing AI}} and Building Data Literacy on {{GitHub}} and {{YouTube}}},
  shorttitle = {Making Sense of Deepfakes},
  author = {McCosker, Anthony},
  date = {2024-05},
  journaltitle = {New Media \& Society},
  shortjournal = {New Media \& Society},
  volume = {26},
  number = {5},
  pages = {2786--2803},
  issn = {1461-4448, 1461-7315},
  doi = {10.1177/14614448221093943},
  url = {https://journals.sagepub.com/doi/10.1177/14614448221093943},
  urldate = {2025-06-04},
  abstract = {As a form of synthetic media built on the Internet’s extensive visual datasets with evolving machine learning techniques, deepfakes raise the specter of new types of informational harms and possibilities for image-based abuse. There are calls for three types of defensive response: regulation, technical controls, and improved digital or media literacy. Each is problematic by itself. This article asks what kind of literacy can address deepfake harms, proposing an artificial intelligence (AI) and data literacy framework to explore the potential for social learning with deepfakes and identify sites and methods for intervening in their cultures of production. The article applies contextual qualitative content analysis to explore the most popular GitHub repositories and YouTube accounts teaching “how to deepfake.” The analysis shows that these sites contribute to socializing AI and establishing cultures of social learning, offering potential sites of intervention and pointing to new methods for addressing AI and data harms.},
  langid = {english},
  keywords = {⏳},
  file = {/Users/sgraf/Zotero/storage/G856FZF4/McCosker_2024_Making sense of deepfakes Socializing AI and building data literacy on GitHub and YouTube.pdf}
}

@article{mcglynn2017a,
  title = {Image-Based Sexual Abuse},
  author = {McGlynn, Clare and Rackley, Erika},
  date = {2017},
  journaltitle = {Oxford Journal of Legal Studies},
  volume = {37},
  number = {3},
  pages = {534--561},
  issn = {0143-6503, 1464-3820},
  doi = {10.1093/ojls/gqw033},
  url = {http://academic.oup.com/ojls/article/37/3/534/2965256/ImageBased-Sexual-Abuse},
  urldate = {2024-09-19},
  langid = {english},
  keywords = {⏳,unread},
  file = {/Users/sgraf/Zotero/storage/5YTTTH72/McGlynn und Rackley_2017_Image-Based Sexual Abuse.pdf}
}

@article{mcglynn2017b,
  title = {Beyond ‘{{Revenge Porn}}’: {{The Continuum}} of {{Image-Based Sexual Abuse}}},
  shorttitle = {Beyond ‘{{Revenge Porn}}’},
  author = {McGlynn, Clare and Rackley, Erika and Houghton, Ruth},
  date = {2017-04},
  journaltitle = {Feminist Legal Studies},
  shortjournal = {Fem Leg Stud},
  volume = {25},
  number = {1},
  pages = {25--46},
  issn = {0966-3622, 1572-8455},
  doi = {10.1007/s10691-017-9343-2},
  url = {http://link.springer.com/10.1007/s10691-017-9343-2},
  urldate = {2025-06-12},
  langid = {english},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/8I8WFC6B/McGlynn et al._2017_Beyond ‘Revenge Porn’ The Continuum of Image-Based Sexual Abuse.pdf}
}

@article{mckee2022,
  title = {Pornhub, Child Sexual Abuse Materials and Anti-Pornography Campaigning},
  author = {McKee, Alan and Lumby, Catharine},
  date = {2022-10-02},
  journaltitle = {Porn Studies},
  shortjournal = {Porn Studies},
  volume = {9},
  number = {4},
  pages = {464--476},
  issn = {2326-8743, 2326-8751},
  doi = {10.1080/23268743.2022.2083662},
  url = {https://www.tandfonline.com/doi/full/10.1080/23268743.2022.2083662},
  urldate = {2025-08-17},
  langid = {english},
  keywords = {⏳}
}

@article{meineck2022,
  entrysubtype = {nonacademic},
  title = {{{XVideos}}: {{The}} Porn Empire next Door},
  author = {Meineck, Sebastian and Köver, Chris},
  date = {2022-03-11},
  journaltitle = {netzpolitik.org},
  url = {https://netzpolitik.org/2022/xvideos-the-porn-empire-next-door/},
  urldate = {2025-05-25},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/RSVGESY4/_.pdf}
}

@article{meineck2023,
  entrysubtype = {nonacademic},
  title = {Re:Publica:  {{Was Pornoseiten}} Aus Kleinen {{Nackt-Communitys}} Lernen Können},
  author = {Meineck, Sebastian},
  date = {2023-06-07},
  journaltitle = {netzpolitik.org},
  url = {https://netzpolitik.org/2023/republica-was-pornoseiten-aus-kleinen-nackt-communitys-lernen-koennen/},
  file = {/Users/sgraf/Zotero/storage/6TVQZ4HB/Meineck_2023_republica  Was Pornoseiten aus kleinen Nackt-Communitys lernen können.pdf}
}

@article{miller2023,
  title = {{{AI Hyperrealism}}: {{Why AI Faces Are Perceived}} as {{More Real Than Human Ones}}},
  shorttitle = {{{AI Hyperrealism}}},
  author = {Miller, Elizabeth J. and Steward, Ben A. and Witkower, Zak and Sutherland, Clare A. M. and Krumhuber, Eva G. and Dawel, Amy},
  date = {2023-12},
  journaltitle = {Psychological Science},
  shortjournal = {Psychol Sci},
  volume = {34},
  number = {12},
  pages = {1390--1403},
  issn = {0956-7976, 1467-9280},
  doi = {10.1177/09567976231207095},
  url = {https://journals.sagepub.com/doi/10.1177/09567976231207095},
  urldate = {2025-07-04},
  abstract = {Recent evidence shows that AI-generated faces are now indistinguishable from human faces. However, algorithms are trained disproportionately on White faces, and thus White AI faces may appear especially realistic. In Experiment 1 ( N = 124 adults), alongside our reanalysis of previously published data, we showed that White AI faces are judged as human more often than actual human faces—a phenomenon we term AI hyperrealism. Paradoxically, people who made the most errors in this task were the most confident (a Dunning-Kruger effect). In Experiment 2 ( N = 610 adults), we used face-space theory and participant qualitative reports to identify key facial attributes that distinguish AI from human faces but were misinterpreted by participants, leading to AI hyperrealism. However, the attributes permitted high accuracy using machine learning. These findings illustrate how psychological theory can inform understanding of AI outputs and provide direction for debiasing AI algorithms, thereby promoting the ethical use of AI.},
  langid = {english},
  file = {/Users/sgraf/Zotero/storage/ZQVDMWGU/Miller et al._2023_AI Hyperrealism Why AI Faces Are Perceived as More Real Than Human Ones.pdf}
}

@online{ministerstvospravedlnostičeskérepubliky2014,
  type = {[Entry from the Commercial Register]},
  title = {Výpis z Obchodního Rejstříku: {{Traffic F}}, s.r.o.},
  author = {{Ministerstvo spravedlnosti České republiky}},
  date = {2014-04-17},
  url = {https://or.justice.cz/ias/ui/rejstrik-firma.vysledky?subjektId=864709&typ=PLATNY},
  urldate = {2025-09-13},
  organization = {Veřejný rejstřík a Sbírka listin}
}

@online{ministerstvospravedlnostičeskérepubliky2014a,
  type = {[Entry from the Commercial Register]},
  title = {Výpis z Obchodního Rejstříku: {{WGCZ Holding}}, a.s.},
  author = {{Ministerstvo spravedlnosti České republiky}},
  date = {2014-08-18},
  url = {https://or.justice.cz/ias/ui/rejstrik-firma.vysledky?subjektId=872905&typ=PLATNY},
  urldate = {2025-09-13},
  organization = {Veřejný rejstřík a Sbírka listin}
}

@article{mirsky2021,
  title = {The Creation and Detection of Deepfakes: A Survey},
  shorttitle = {The {{Creation}} and {{Detection}} of {{Deepfakes}}},
  author = {Mirsky, Yisroel and Lee, Wenke},
  date = {2021},
  journaltitle = {ACM Computing Surveys},
  shortjournal = {ACM Comput. Surv.},
  volume = {54},
  number = {1},
  pages = {1--41},
  issn = {0360-0300, 1557-7341},
  doi = {10.1145/3425780},
  url = {https://dl.acm.org/doi/10.1145/3425780},
  urldate = {2025-10-17},
  abstract = {Generative deep learning algorithms have progressed to a point where it is difficult to tell the difference between what is real and what is fake. In 2018, it was discovered how easy it is to use this technology for unethical and malicious applications, such as the spread of misinformation, impersonation of political leaders, and the defamation of innocent individuals. Since then, these “deepfakes” have advanced significantly.             In this article, we explore the creation and detection of deepfakes and provide an in-depth view as to how these architectures work. The purpose of this survey is to provide the reader with a deeper understanding of (1) how deepfakes are created and detected, (2) the current trends and advancements in this domain, (3) the shortcomings of the current defense solutions, and (4) the areas that require further research and attention.},
  langid = {english},
  file = {/Users/sgraf/Zotero/storage/6ZD4QGQR/Mirsky und Lee_2022_The Creation and Detection of Deepfakes A Survey.pdf}
}

@online{morandini2023,
  title = {{{DSA Audits}}: Procedural Rules Leave Some Uncertainties},
  author = {Morandini, Anna},
  date = {2023-11-28},
  url = {https://dsa-observatory.eu/2023/11/28/dsa-audits-procedural-rules-leave-some-uncertainties/},
  urldate = {2025-09-19},
  organization = {DSA Observatory},
  keywords = {✅}
}

@article{moravcsik2014,
  title = {Transparency: {{The Revolution}} in {{Qualitative Research}}},
  shorttitle = {Transparency},
  author = {Moravcsik, Andrew},
  date = {2014-01},
  journaltitle = {Political Science and Politics},
  shortjournal = {APSC},
  volume = {47},
  number = {1},
  pages = {48--53},
  issn = {1049-0965, 1537-5935},
  doi = {10.1017/S1049096513001789},
  url = {https://www.cambridge.org/core/product/identifier/S1049096513001789/type/journal_article},
  urldate = {2025-10-01},
  abstract = {Qualitative political science, the use of textual evidence to reconstruct causal mechanisms across a limited number of cases, is currently undergoing a methodological revolution. Many qualitative scholars—whether they use traditional case-study analysis, analytic narrative, structured focused comparison, counterfactual analysis, process tracing, ethnographic and participant-observation, or other methods—now believe that the richness, rigor, and transparency of qualitative research ought to be fundamentally improved.},
  langid = {english},
  file = {/Users/sgraf/Zotero/storage/EW7JRMIP/Moravcsik_2014_Transparency The Revolution in Qualitative Research.pdf}
}

@book{mraz1998,
  title = {Elisabeth: {{Prinzessin}} in {{Bayern}}, {{Kaiserin}} von {{Österreich}}, {{Königin}} von {{Ungarn}}: {{Wunschbilder}} Oder Die {{Kunst}} Der {{Retouche}}},
  shorttitle = {Elisabeth},
  author = {Mraz, Gerda and Fischer-Westhauser, Ulla},
  date = {1998},
  edition = {1. Aufl},
  publisher = {Brandstätter},
  location = {Wien},
  isbn = {978-3-85447-774-7},
  pagetotal = {159},
  keywords = {✅,❌,Austria,Biography Pictorial works,Elisabeth,Empresses,Pictorial works}
}

@article{newton2020,
  title = {My {{NSFW}} Video Has Partial Occlusion: Deepfakes and the Technological Production of Non-Consensual Pornography},
  shorttitle = {My {{NSFW}} Video Has Partial Occlusion},
  author = {Newton, Olivia B. and Stanfill, Mel},
  date = {2020-10},
  journaltitle = {Porn Studies},
  shortjournal = {Porn Studies},
  volume = {7},
  number = {4},
  pages = {398--414},
  issn = {2326-8743, 2326-8751},
  doi = {10.1080/23268743.2019.1675091},
  url = {https://www.tandfonline.com/doi/full/10.1080/23268743.2019.1675091},
  urldate = {2025-06-03},
  langid = {english},
  keywords = {⏳,production},
  file = {/Users/sgraf/Zotero/storage/62NMPQTQ/Newton und Stanfill_2020_My NSFW video has partial occlusion deepfakes and the technological production of non-consensual po.pdf}
}

@online{nklassociatess.r.o.2024,
  title = {Terms of {{Service}}},
  author = {{NKL Associates s.r.o.}},
  date = {2024-02-17},
  url = {https://info.xnxx.com/legal/tos},
  organization = {info.xnxx.com},
  keywords = {✅}
}

@report{nklassociatess.r.o.2025,
  title = {Transparency Report {{XNXX}}.Com},
  author = {{NKL Associates s.r.o.}},
  date = {2025-01-10},
  number = {01.07.2024-31.12.2024},
  url = {https://cdn77-pic.xnxx-cdn.com/videos/thumbs/XNXX_Transparency_Report_-_July_to_December_2024.pdf},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/Y2HXSUYB/NKL Associates s.r.o._2025_TRANSPARENCY REPORT XNXX.com.pdf}
}

@report{nklassociatess.r.o.2025a,
  title = {Transparency Report {{XNXX}}.Com},
  author = {{NKL Associates s.r.o.}},
  date = {2025-08-29},
  number = {2},
  url = {https://cdn77-pic.xnxx-cdn.com/videos/transparency/XNXX_2nd_Transparency_Report_January_to_June_2025.pdf},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/CLDTXMQU/NKL Associates s.r.o._2025_Transparency report XNXX.com.pdf}
}

@online{oconnor2023,
  title = {Our Approach to Responsible {{AI}} Innovation},
  author = {O'Connor, Jennifer Flannery and Moxley, Emily},
  date = {2023-11-14},
  url = {https://blog.youtube/inside-youtube/our-approach-to-responsible-ai-innovation/},
  organization = {YouTube Official Blog: Inside YouTube}
}

@article{öhman2020a,
  title = {Introducing the Pervert’s Dilemma: A Contribution to the Critique of {{Deepfake Pornography}}},
  shorttitle = {Introducing the Pervert’s Dilemma},
  author = {Öhman, Carl},
  date = {2020-06},
  journaltitle = {Ethics and Information Technology},
  shortjournal = {Ethics Inf Technol},
  volume = {22},
  number = {2},
  pages = {133--140},
  issn = {1388-1957, 1572-8439},
  doi = {10.1007/s10676-019-09522-1},
  url = {http://link.springer.com/10.1007/s10676-019-09522-1},
  urldate = {2025-09-09},
  abstract = {Abstract                            Recent technological innovation has made video doctoring increasingly accessible. This has given rise to Deepfake Pornography, an emerging phenomenon in which Deep Learning algorithms are used to superimpose a person’s face onto a pornographic video. Although to most people, Deepfake Pornography is intuitively unethical, it seems difficult to justify this intuition without simultaneously condemning other actions that we do not ordinarily find morally objectionable, such as sexual fantasies. In the present article, I refer to this contradiction as the               pervert’s dilemma               . I propose that the method of Levels of Abstraction, a philosophical mode of enquiry inspired by Formal Methods in computer science, can be employed to formulate at least one possible solution to the dilemma. From this perspective, the permissibility of               some               actions appears to depend on the degree to which they are abstracted from their natural context. I conclude that the dilemma can only be solved when considered at low levels of abstractions, when Deepfakes are situated in the macro-context of gender inequality.},
  langid = {english},
  keywords = {⏳},
  file = {/Users/sgraf/Zotero/storage/SRHEVILI/Öhman_2020_Introducing the pervert’s dilemma a contribution to the critique of Deepfake Pornography.pdf}
}

@incollection{ortolani2025,
  title = {Generative {{AI}} and {{Content Moderation}}},
  booktitle = {The {{Oxford Handbook}} of the {{Foundations}} and {{Regulation}} of {{Generative AI}}},
  author = {Ortolani, Pietro},
  editor = {Hacker, Philipp and Mittelstadt, Brent and Hammer, Sarah and Engel, Andreas},
  date = {2025-04-22},
  edition = {1},
  publisher = {Oxford University Press},
  doi = {10.1093/oxfordhb/9780198940272.013.0020},
  url = {https://academic.oup.com/edited-volume/59908/chapter/512463151},
  urldate = {2025-05-20},
  abstract = {Abstract             The chapter investigates the interplay between Generative AI (GenAI) and content moderation. It addresses both the moderation of content created through GenAI and the use of GenAI in content moderation processes. The chapter argues that the rise of GenAI poses certain challenges to the current content moderation framework, which has been mainly developed with an eye to user-generated content. At the same time, GenAI also has the potential to improve certain aspects of content moderation, such as the drafting of text explaining the rationale of content moderation decisions. The chapter advocates for an increased focus on the human–machine interaction: rather than replacing human decision-making, GenAI should be used to support humans in content moderation decision-making.},
  isbn = {978-0-19-894027-2 978-0-19-894030-2},
  langid = {english},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/ALM5FJSC/Ortolani_2025_Generative AI and Content Moderation.pdf}
}

@report{oversightboard2024,
  type = {Multiple case decision},
  title = {Explicit {{AI}} Images of Female Public Figures},
  author = {{Oversight Board}},
  date = {2024-07-25},
  institution = {Meta Oversight Board},
  url = {https://www.oversightboard.com/decision/bun-7e941o1n/},
  keywords = {⏳},
  file = {/Users/sgraf/Zotero/storage/S5NK576Z/Oversight Board_.pdf}
}

@article{paradiso2024,
  title = {Image-{{Based Sexual Abuse Associated Factors}}: {{A Systematic Review}}},
  shorttitle = {Image-{{Based Sexual Abuse Associated Factors}}},
  author = {Paradiso, Maria Noemi and Rollè, Luca and Trombetta, Tommaso},
  date = {2024-07},
  journaltitle = {Journal of Family Violence},
  shortjournal = {J Fam Viol},
  volume = {39},
  number = {5},
  pages = {931--954},
  issn = {0885-7482, 1573-2851},
  doi = {10.1007/s10896-023-00557-z},
  url = {https://link.springer.com/10.1007/s10896-023-00557-z},
  urldate = {2024-09-19},
  abstract = {Abstract                            Purpose               Image-Based Sexual Abuse (IBSA) is a recently studied form of violence and abuse perpetrated using technology. This systematic review aims to examine and systematize studies exploring factors associated with IBSA (e.g., victimization, perpetration, and propensity to perpetrate).                                         Method               Following the Preferred Reporting Items for Systematic Review and Meta-Analysis (PRISMA) statement, 17 articles were included.                                         Results               The results of this study highlighted conceptual and methodological limitations in the literature on IBSA. Aside from these limitations, this systematic review identified factors associated with IBSA, focusing on four macro-areas: victimization, perpetration, propensity to perpetrate IBSA, and IBSA implications. The results demonstrated the role of psychological, relational, and social variables, although the effect sizes observed in the quantitative studies were small or in few cases moderate.                                         Conclusions               These results suggest further research should be carried out to explore the multidimensionality of IBSA and its associated factors, which may assist in guiding interventions to promote preventive and rehabilitative methods to lower the prevalence of this crime and its consequences.},
  langid = {english},
  keywords = {✅,❌},
  file = {/Users/sgraf/Zotero/storage/YYFRWRBF/Paradiso et al. - 2024 - Image-Based Sexual Abuse Associated Factors A Systematic Review.pdf}
}

@article{petit2025,
  title = {The Limits of ‘Zero Tolerance’ Policies for Animated Pornographic Media},
  author = {Petit, Aurélie},
  date = {2025-05-28},
  journaltitle = {Porn Studies},
  shortjournal = {Porn Studies},
  pages = {1--18},
  issn = {2326-8743, 2326-8751},
  doi = {10.1080/23268743.2025.2491506},
  url = {https://www.tandfonline.com/doi/full/10.1080/23268743.2025.2491506},
  urldate = {2025-06-05},
  langid = {english}
}

@article{podsakoff2016,
  title = {Recommendations for {{Creating Better Concept Definitions}} in the {{Organizational}}, {{Behavioral}}, and {{Social Sciences}}},
  author = {Podsakoff, Philip M. and MacKenzie, Scott B. and Podsakoff, Nathan P.},
  date = {2016-04},
  journaltitle = {Organizational Research Methods},
  shortjournal = {Organizational Research Methods},
  volume = {19},
  number = {2},
  pages = {159--203},
  issn = {1094-4281, 1552-7425},
  doi = {10.1177/1094428115624965},
  url = {https://journals.sagepub.com/doi/10.1177/1094428115624965},
  urldate = {2025-06-11},
  abstract = {Despite the importance of establishing good, clear concept definitions in organizational research, the field lacks a comprehensive source that explains how to effectively develop and articulate a concept’s domain. Thus, the purpose of this article is to explain why clear conceptual definitions are essential for scientific progress and provide a concrete set of steps that researchers can follow to improve their conceptual definitions. First, we define what is meant by a concept, describe the functions served by concepts in scientific endeavors, and identify problems associated with a lack of conceptual clarity. Then we explain why it is so difficult to adequately define concepts. Next, we provide a series of recommendations for scholars in the organizational, behavioral, and social sciences who are either trying to define a new concept or revise the definition of one that already exists in the field. Following this, we provide some examples that generally meet the criteria for a good conceptual definition. We conclude with a set of questions that authors, reviewers, and editors can use as a guide for evaluating concept definitions.},
  langid = {english},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/JV5833FT/Podsakoff et al._2016_Recommendations for Creating Better Concept Definitions in the Organizational, Behavioral, and Socia.pdf}
}

@article{popova2020,
  title = {Reading out of Context: Pornographic Deepfakes, Celebrity and Intimacy},
  shorttitle = {Reading out of Context},
  author = {Popova, Milena},
  date = {2020-10},
  journaltitle = {Porn Studies},
  shortjournal = {Porn Studies},
  volume = {7},
  number = {4},
  pages = {367--381},
  issn = {2326-8743, 2326-8751},
  doi = {10.1080/23268743.2019.1675090},
  url = {https://www.tandfonline.com/doi/full/10.1080/23268743.2019.1675090},
  urldate = {2025-07-02},
  langid = {english},
  keywords = {⏳},
  file = {/Users/sgraf/Zotero/storage/ZXJ8V5MG/Popova_2020_Reading out of context pornographic deepfakes, celebrity and intimacy.pdf}
}

@online{pornhub,
  title = {Our Commitment to {{Trust}} and {{Safety}}},
  author = {{Pornhub}},
  url = {https://help.pornhub.com/hc/en-us/categories/4419836212499},
  urldate = {2025-08-07},
  keywords = {✅}
}

@online{pornhub2019,
  title = {The 2019 Year in Review},
  author = {{Pornhub}},
  date = {2019},
  url = {https://www.pornhub.com/insights/2019-year-in-review#celebrity},
  organization = {Pornhub insights},
  keywords = {✅}
}

@online{pornhub2025,
  type = {Information},
  title = {{{EU Digital Services Act}}},
  author = {{Pornhub}},
  date = {2025-07-01},
  url = {https://www.pornhub.com/information/eu_dsa},
  urldate = {2025-08-12},
  keywords = {✅}
}

@report{pornhubhelp2020,
  type = {report},
  title = {2020 {{Transparency}} Report},
  author = {{Pornhub Help}},
  date = {2020},
  institution = {Pornhub},
  url = {https://help.pornhub.com/hc/en-us/articles/4419860718483-2020-Transparency-Report},
  urldate = {2025-08-14},
  keywords = {✅}
}

@report{pornhubhelp2021,
  type = {report},
  title = {2021 {{Transparency}} Report},
  author = {{Pornhub Help}},
  date = {2021},
  institution = {Pornhub},
  url = {https://help.pornhub.com/hc/en-us/articles/5357457259155-2021-Transparency-Report},
  urldate = {2025-08-14},
  keywords = {✅}
}

@online{pornhubhelp2024,
  title = {Non-{{Consensual Content Policy}}},
  author = {{Pornhub Help}},
  date = {2024-09},
  url = {https://help.pornhub.com/hc/en-us/articles/4419871787027-Non-Consensual-Content-Policy},
  urldate = {2025-08-14},
  organization = {Pornhub Help Center},
  keywords = {✅}
}

@online{pornhubhelp2024a,
  title = {Child {{Sexual Abuse Material Policy}}},
  author = {{Pornhub Help}},
  date = {2024-09},
  url = {https://help.pornhub.com/hc/en-us/articles/4419869793683-Child-Sexual-Abuse-Material-Policy},
  urldate = {2025-08-14},
  organization = {Pornhub Help Center},
  keywords = {✅}
}

@report{pornhubhelp2024b,
  type = {report},
  title = {2024 {{Transparency}} Report (Second Half)},
  author = {{Pornhub Help}},
  date = {2024},
  number = {July 1, 2024 -- December 31, 2024},
  institution = {Aylo},
  url = {https://help.pornhub.com/hc/en-us/articles/38743689517715-2024-Transparency-Report-Second-Half},
  urldate = {2025-08-14},
  keywords = {✅}
}

@report{pornhubhelp2024c,
  type = {report},
  title = {2024 {{Transparency}} Report (First Half)},
  author = {{Pornhub Help}},
  date = {2024},
  number = {January 1, 2024 -- June 30, 2024},
  institution = {Aylo},
  url = {https://help.pornhub.com/hc/en-us/articles/33098088051475-2024-Transparency-Report-First-Half},
  urldate = {2025-08-14},
  keywords = {✅}
}

@online{pornhubhelp2025,
  title = {Community Guidelines},
  author = {{Pornhub Help}},
  date = {2025-08},
  url = {https://help.pornhub.com/hc/en-us/articles/4419900587155-Community-Guidelines},
  urldate = {2025-08-14},
  organization = {Pornhub Help Center},
  keywords = {✅}
}

@online{pornhubhelpc,
  title = {Pornhub {{Trusted Flagger Program}}},
  author = {{Pornhub Help}},
  url = {https://help.pornhub.com/hc/en-us/articles/4419879221907-Pornhub-Trusted-Flagger-Program},
  urldate = {2025-08-07},
  organization = {Pornhub Help Center},
  keywords = {✅}
}

@online{qiwei2024,
  title = {Reporting {{Non-Consensual Intimate Media}}: {{An Audit Study}} of {{Deepfakes}}},
  author = {Qiwei, Li and Zhang, Shihui and Kasper, Andrew T. and Ashkinaze, Joshua and Eaton, Asia A. and Schoenebeck, Sarita and Gilbert, Eric},
  date = {2024},
  eprint = {2409.12138},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.2409.12138},
  pubstate = {prepublished},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/IEYEY5HB/Reporting Non-Consensual Intimate Media An Audit .pdf}
}

@manual{R-dplyr,
  type = {manual},
  title = {Dplyr: A Grammar of Data Manipulation},
  author = {Wickham, Hadley and François, Romain and Henry, Lionel and Müller, Kirill and Vaughan, Davis},
  date = {2023},
  url = {https://dplyr.tidyverse.org}
}

@manual{R-ggplot2,
  type = {manual},
  title = {Ggplot2: {{Create}} Elegant Data Visualisations Using the Grammar of Graphics},
  author = {Wickham, Hadley and Chang, Winston and Henry, Lionel and Pedersen, Thomas Lin and Takahashi, Kohske and Wilke, Claus and Woo, Kara and Yutani, Hiroaki and Dunnington, Dewey and family=Brand, given=Teun, prefix=van den, useprefix=true},
  date = {2025},
  url = {https://ggplot2.tidyverse.org}
}

@manual{R-janitor,
  type = {manual},
  title = {Janitor: {{Simple}} Tools for Examining and Cleaning Dirty Data},
  author = {Firke, Sam},
  date = {2024},
  url = {https://github.com/sfirke/janitor}
}

@manual{R-kableExtra,
  type = {manual},
  title = {{{kableExtra}}: {{Construct}} Complex Table with Kable and Pipe Syntax},
  author = {Zhu, Hao},
  date = {2024},
  url = {http://haozhu233.github.io/kableExtra/}
}

@article{rama2023,
  title = {The Platformization of Gender and Sexual Identities: An Algorithmic Analysis of {{Pornhub}}},
  shorttitle = {The Platformization of Gender and Sexual Identities},
  author = {Rama, Ilir and Bainotti, Lucia and Gandini, Alessandro and Giorgi, Giulia and Semenzin, Silvia and Agosti, Claudio and Corona, Giulia and Romano, Salvatore},
  date = {2023-04-03},
  journaltitle = {Porn Studies},
  shortjournal = {Porn Studies},
  volume = {10},
  number = {2},
  pages = {154--173},
  issn = {2326-8743, 2326-8751},
  doi = {10.1080/23268743.2022.2066566},
  url = {https://www.tandfonline.com/doi/full/10.1080/23268743.2022.2066566},
  urldate = {2025-03-05},
  langid = {english},
  keywords = {⏳},
  file = {/Users/sgraf/Zotero/storage/3W7TTWRI/Rama et al._2023_The platformization of gender and sexual identities an algorithmic analysis of Pornhub.pdf}
}

@incollection{richardson2000,
  title = {Writing: A Method of Inquiry},
  booktitle = {Handbook of {{Qualitative Research}}},
  author = {Richardson, L},
  editor = {Denzin, N K and Lincoln, Y S},
  date = {2000},
  edition = {2},
  pages = {923--948},
  publisher = {SAGE},
  location = {Thousand Oaks, CA,},
  file = {/Users/sgraf/Zotero/storage/F9XBRDKV/Richardson_2000_Writing a method of inquiry.pdf}
}

@article{rieder2020b,
  title = {Towards Platform Observability},
  author = {Rieder, Bernhard and Hofmann, Jeanette},
  date = {2020-12-18},
  journaltitle = {Internet Policy Review},
  volume = {9},
  number = {4},
  issn = {2197-6775},
  doi = {10.14763/2020.4.1535},
  url = {https://policyreview.info/articles/analysis/towards-platform-observability},
  urldate = {2024-11-24},
  langid = {english},
  keywords = {⏳},
  file = {/Users/sgraf/Zotero/storage/R8JDL94F/Rieder und Hofmann - 2020 - Towards platform observability.pdf}
}

@article{rigotti2022,
  title = {Towards an {{EU}} Criminal Law on Violence against Women: {{The}} Ambitions and Limitations of the {{Commission}}’s Proposal to Criminalise Image-Based Sexual Abuse},
  author = {Rigotti, Carlotta and McGlynn, Clare M. S.},
  date = {2022},
  journaltitle = {New Journal of European Criminal Law IJECL},
  pages = {1--26},
  url = {https://ssrn.com/abstract=4379096},
  file = {/Users/sgraf/Zotero/storage/QQUI468F/Rigotti und McGlynn_2022_Towards an EU criminal law on violence against women The ambitions and limitations of the Commissio.pdf}
}

@article{rigotti2024,
  title = {Image-{{Based Sexual Abuse}} and {{EU Law}}: A Critical Analysis},
  shorttitle = {Image-{{Based Sexual Abuse}} and {{EU Law}}},
  author = {Rigotti, Carlotta and McGlynn, Clare and Benning, Franziska},
  date = {2024-12},
  journaltitle = {German Law Journal},
  shortjournal = {German Law Journal},
  volume = {25},
  number = {9},
  pages = {1472--1493},
  issn = {2071-8322},
  doi = {10.1017/glj.2024.49},
  url = {https://www.cambridge.org/core/product/identifier/S207183222400049X/type/journal_article},
  urldate = {2025-10-09},
  abstract = {In May 2024, the European Union adopted the Directive on violence against women and domestic violence, marking the first EU-wide binding legislation to address various forms of sexualized and gendered harm. This Article provides the first comprehensive analysis of the Directive’s provisions on image-based sexual abuse (“IBSA”), encompassing the non-consensual taking, creating, and sharing of intimate materials, as well as threats to distribute them. While acknowledging the aim to harmonize legislation at the Union level, the Article identifies a range of limitations and the failure to fully reflect the diverse experiences of victims. Additionally, the Article evaluates the complementary roles in combating IBSA of the Digital Services Act and the AI Act which impose obligations on online platforms, search engines, and AI developers. Overall, the current EU framework represents a promising but partial approach. If the EU is to comprehensively address IBSA and safeguard victims’ rights, implementation beyond the minimum will be required together with proactive, effective regulation.},
  langid = {english},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/UPS2WWBJ/Rigotti et al._2024_Image-Based Sexual Abuse and EU Law A Critical Analysis.pdf}
}

@article{risius2024,
  title = {Shadowbanning: {{An Opaque Form}} of {{Content Moderation}}},
  shorttitle = {Shadowbanning},
  author = {Risius, Marten and Blasiak, Kevin Marc},
  date = {2024-12},
  journaltitle = {Business \& Information Systems Engineering},
  shortjournal = {Bus Inf Syst Eng},
  volume = {66},
  number = {6},
  pages = {817--829},
  publisher = {{Springer Science and Business Media LLC}},
  issn = {2363-7005, 1867-0202},
  doi = {10.1007/s12599-024-00905-3},
  url = {https://link.springer.com/10.1007/s12599-024-00905-3},
  urldate = {2025-07-18},
  langid = {english},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/8SLMIKEU/Risius und Blasiak_2024_Shadowbanning An Opaque Form of Content Moderation.pdf}
}

@incollection{roberts2017,
  title = {Content {{Moderation}}},
  booktitle = {Encyclopedia of {{Big Data}}},
  author = {Roberts, Sarah T.},
  editor = {Schintler, Laurie A. and McNeely, Connie L.},
  date = {2017},
  pages = {1--4},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-319-32001-4_44-1},
  url = {http://link.springer.com/10.1007/978-3-319-32001-4_44-1},
  urldate = {2025-03-05},
  isbn = {978-3-319-32001-4},
  langid = {english},
  keywords = {⏳,❌}
}

@article{roberts2018,
  title = {Digital Detritus: '{{Error}}' and the Logic of Opacity in Social Media Content Moderation},
  shorttitle = {Digital Detritus},
  author = {Roberts, Sarah T.},
  date = {2018-03-01},
  journaltitle = {First Monday},
  shortjournal = {FM},
  issn = {1396-0466},
  doi = {10.5210/fm.v23i3.8283},
  url = {https://www.firstmonday.org/ojs/index.php/fm/article/view/8283},
  urldate = {2025-04-01},
  abstract = {The late 2016 case of the Facebook content moderation controversy over the infamous Vietnam-era photo, “The Terror of War,” is examined in this paper for both its specifics, as well as a mechanism to engage in a larger discussion of the politics and economics of the content moderation of user-generated content. In the context of mainstream commercial social media platforms, obfuscation and secrecy work together to form an operating logic of opacity, a term and concept introduced in this paper. The lack of clarity around platform policies, procedures and the values that inform them lead users to wildly different interpretations of the user experience on the same site, resulting in confusion in no small part by the platforms’ own design. Platforms operationalize their content moderation practices under a complex web of nebulous rules and procedural opacity, while governments and other actors clamor for tighter controls on some material, and other members of civil society demand greater freedoms for online expression. Few parties acknowledge the fact that mainstream social media platforms are already highly regulated, albeit rarely in such a way that can be satisfactory to all. The final turn in the paper connects the functions of the commercial content moderation process on social media platforms like Facebook to their output, being either the content that appears on a site, or content that is rescinded: digital detritus. While meaning and intent of user-generated content may often be imagined to be the most important factors by which content is evaluated for a site, this paper argues that its value to the platform as a potentially revenue-generating commodity is actually the key criterion and the one to which all moderation decisions are ultimately reduced. The result is commercialized online spaces that have far less to offer in terms of political and democratic challenge to the status quo and which, in fact, may serve to reify and consolidate power rather than confront it.},
  keywords = {❌}
}

@incollection{roberts2019,
  title = {Understanding Commercial Content Moderation},
  booktitle = {Behind the Screen : {{Content}} Moderation in the Shadows of Social Media},
  author = {Roberts, Sarah T.},
  date = {2019},
  pages = {33--72},
  publisher = {Yale University Press},
  keywords = {⏳},
  file = {/Users/sgraf/Zotero/storage/IKEKL3BX/Behind_the_Screen_Content_Moderation_in_the_Shadow..._----_(TWO._Understanding_Commercial_Content_Moderation).pdf}
}

@article{romeromoreno2024,
  title = {Generative {{AI}} and Deepfakes: A Human Rights Approach to Tackling Harmful Content},
  shorttitle = {Generative {{AI}} and Deepfakes},
  author = {Romero Moreno, Felipe},
  date = {2024-09},
  journaltitle = {International Review of Law, Computers \& Technology},
  shortjournal = {International Review of Law, Computers \& Technology},
  volume = {38},
  number = {3},
  pages = {297--326},
  issn = {1360-0869, 1364-6885},
  doi = {10.1080/13600869.2024.2324540},
  url = {https://www.tandfonline.com/doi/full/10.1080/13600869.2024.2324540},
  urldate = {2025-06-03},
  langid = {english},
  keywords = {⏳,legal},
  file = {/Users/sgraf/Zotero/storage/RWGBN5SL/Romero Moreno_2024_Generative AI and deepfakes a human rights approach to tackling harmful content.pdf}
}

@book{saldaña2013,
  title = {The Coding Manual for Qualitative Researchers},
  author = {Saldaña, Johnny},
  date = {2013},
  edition = {2. ed},
  publisher = {SAGE Publ},
  location = {Los Angeles, Calif.},
  abstract = {An in-depth guide to each of the multiple approaches available for coding qualitative data. In total, 32 different approaches to coding are covered, ranging in complexity from beginner to advanced level and covering the full range of types of qualitative data from interview transcripts to field notes},
  isbn = {978-1-4462-4736-5 978-1-4462-4737-2},
  langid = {english},
  pagetotal = {303},
  file = {/Users/sgraf/Zotero/storage/FAPZUIRX/Saldaña_2013_The coding manual for qualitative researchers.pdf}
}

@article{sanders2025,
  title = {Non-Consensual Sharing of Images: {{Commercial}} Content Creators, Sexual Content Creation Platforms and the Lack of Protection},
  shorttitle = {Non-Consensual Sharing of Images},
  author = {Sanders, Teela and Trueman, Gaynor and Worthington, Kate and Keighley, Rachel},
  date = {2025-01},
  journaltitle = {New Media \& Society},
  shortjournal = {New Media \& Society},
  volume = {27},
  number = {1},
  pages = {84--105},
  issn = {1461-4448, 1461-7315},
  doi = {10.1177/14614448231172711},
  url = {https://journals.sagepub.com/doi/10.1177/14614448231172711},
  urldate = {2025-06-04},
  abstract = {In this article, we explore the experiences of commercial content creators who have their content (videos, photos, and images) misused. This article reports from a mixed-methods study consisting of 16 interviews with content creators; nine interviews with practitioners who support sex workers and interviews with seven adult service website (ASW) operators. These qualitative data are supported by 221 responses to a survey from the content creators’ community. We describe how content creators experience blackmail, threats of exposure and recording without knowledge, stalking, harassment, doxing, ‘deepfakes’ and impersonation. We conclude that the online sex work environment may not be as safe as previous research has demonstrated, and that commercial content creators are often ignored by governance and platforms following sex workers’ complaints regarding their content being misused. We reflect on the forthcoming UK Online Safety Bill as compared to the US Stop Enabling Sex Traffickers Act/Fight Online Sex Trafficking Act (SESTA/FOSTA) law which have seen implications across the globe for digital sex workers. We offer solutions for ASWs to act more responsibly.},
  langid = {english},
  file = {/Users/sgraf/Zotero/storage/YYAMHXGD/Sanders et al._2025_Non-consensual sharing of images Commercial content creators, sexual content creation platforms and.pdf}
}

@article{saner2024,
  entrysubtype = {nonacademic},
  title = {Inside the {{Taylor Swift}} Deepfake Scandal: ‘{{It}}’s Men Telling a Powerful Woman to Get Back in Her Box’},
  author = {Saner, Emine},
  date = {2024-01-31},
  journaltitle = {theguardian.com},
  url = {https://www.theguardian.com/technology/2024/jan/31/inside-the-taylor-swift-deepfake-scandal-its-men-telling-a-powerful-woman-to-get-back-in-her-box},
  urldate = {2025-03-21},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/8VX3DYNE/Saner_2024_Inside the Taylor Swift deepfake scandal ‘It’s men telling a powerful woman to get back in her box’.pdf}
}

@book{saukko2003,
  title = {Doing {{Research}} in {{Cultural Studies}}},
  author = {Saukko, Paula},
  date = {2003},
  publisher = {SAGE Publications Ltd},
  location = {6 Bonhill Street,~London~England~EC2A 4PU~United Kingdom},
  doi = {10.4135/9781849209021},
  url = {https://methods.sagepub.com/book/doing-research-in-cultural-studies},
  urldate = {2025-09-29},
  isbn = {978-0-7619-6504-6 978-1-84920-902-1},
  file = {/Users/sgraf/Zotero/storage/IZHWFC6Q/Saukko_2003_Doing Research in Cultural Studies.pdf}
}

@article{schafer2025,
  title = {To Screenshot or Not to Screenshot? {{Tensions}} in Representing Visual Social Media Platform Posts},
  shorttitle = {{{TO SCREENSHOT OR NOT TO SCREENSHOT}}?},
  author = {Schafer, Joseph Scott and Halperin, Brett A. and Ghosh, Sourojit and Vera, Julie},
  date = {2025-01-02},
  journaltitle = {AoIR Selected Papers of Internet Research},
  shortjournal = {SPIR},
  issn = {2162-3317, 2162-3317},
  doi = {10.5210/spir.v2024i0.14055},
  url = {https://spir.aoir.org/ojs/index.php/spir/article/view/14055},
  urldate = {2025-10-03},
  abstract = {The rise to prominence of visual social media platforms (VSMPs) including TikTok, Instagram, and YouTube has led to increasing amounts of research attention directed to these platforms. As research engages multimodal platforms, representing their content (including text, audio, image, and video components) increasingly becomes both important and complex. The AoIR Internet Research Ethics (IRE) 3.0 guidelines stipulate that “we need to elaborate an ethics addressing the distinctive issues clustering around the production, sharing, and thereby research on visual images” (franzke et al., 2020). In this paper, we begin making such an elaboration, describing considerations necessary when representing screenshots. We provide an overview of four current approaches to representing VSMP posts and annotate their tensions.},
  langid = {english},
  file = {/Users/sgraf/Zotero/storage/ENSIN322/Schafer et al._2025_TO SCREENSHOT OR NOT TO SCREENSHOT TENSIONS IN REPRESENTING VISUAL SOCIAL MEDIA PLATFORM POSTS.pdf}
}

@article{schaffner2024,
  title = {"{{Community Guidelines Make}} This the {{Best Party}} on the {{Internet}}": {{An In-Depth Study}} of {{Online Platforms}}' {{Content Moderation Policies}}},
  shorttitle = {"{{Community Guidelines Make}} This the {{Best Party}} on the {{Internet}}"},
  author = {Schaffner, Brennan and Bhagoji, Arjun Nitin and Cheng, Siyuan and Mei, Jacqueline and Shen, Jay L. and Wang, Grace and Chetty, Marshini and Feamster, Nick and Lakier, Genevieve and Tan, Chenhao},
  date = {2024},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.2405.05225},
  url = {https://arxiv.org/abs/2405.05225},
  urldate = {2025-07-23},
  abstract = {Moderating user-generated content on online platforms is crucial for balancing user safety and freedom of speech. Particularly in the United States, platforms are not subject to legal constraints prescribing permissible content. Each platform has thus developed bespoke content moderation policies, but there is little work towards a comparative understanding of these policies across platforms and topics. This paper presents the first systematic study of these policies from the 43 largest online platforms hosting user-generated content, focusing on policies around copyright infringement, harmful speech, and misleading content. We build a custom web-scraper to obtain policy text and develop a unified annotation scheme to analyze the text for the presence of critical components. We find significant structural and compositional variation in policies across topics and platforms, with some variation attributable to disparate legal groundings. We lay the groundwork for future studies of ever-evolving content moderation policies and their impact on users.},
  version = {1},
  keywords = {⏳,FOS: Computer and information sciences,Human-Computer Interaction (cs.HC),Social and Information Networks (cs.SI)},
  file = {/Users/sgraf/Zotero/storage/7HDV82FW/Schaffner et al._2024_Community Guidelines Make this the Best Party on the Internet An In-Depth Study of Online Platfor.pdf}
}

@report{seiling2024,
  title = {Response to the {{Consultation}} on the {{Delegated Regulation}} on {{Data Access}} Provided for in the {{Digital Services Act}}},
  author = {Seiling, Lukas and Ohme, Jakob and Klinger, Ulrike},
  date = {2024},
  institution = {Weizenbaum Institute},
  issn = {2940-8490},
  doi = {10.34669/WI.PP/11},
  url = {https://www.weizenbaum-library.de/handle/id/762},
  urldate = {2025-01-16},
  abstract = {This response provides feedback on the Delegated Regulation on Data Access provided for in the Digital Services Act. It is informed by a variety of exchanges with empirical platform researchers across Germany and Europe. The first section highlights clarifications and proposed procedures for non-public data access which are practical, workable or welcomed by scientists for other reasons. The second section outlines further opportunities for clarification, additions, or modifications to the draft text, particularly regarding the data access procedure, the data access portal, the types of data, as well as the documentation and modalities of data access.},
  langid = {english},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/GICDNC6T/Seiling et al._2024_Response to the Consultation on the Delegated Regulation on Data Access provided for in the Digital.pdf}
}

@article{semenzin2020,
  title = {The {{Use}} of {{Telegram}} for {{Non-Consensual Dissemination}} of {{Intimate Images}}: {{Gendered Affordances}} and the {{Construction}} of {{Masculinities}}},
  shorttitle = {The {{Use}} of {{Telegram}} for {{Non-Consensual Dissemination}} of {{Intimate Images}}},
  author = {Semenzin, Silvia and Bainotti, Lucia},
  date = {2020-10},
  journaltitle = {Social Media + Society},
  shortjournal = {Social Media + Society},
  volume = {6},
  number = {4},
  pages = {2056305120984453},
  issn = {2056-3051, 2056-3051},
  doi = {10.1177/2056305120984453},
  url = {https://journals.sagepub.com/doi/10.1177/2056305120984453},
  urldate = {2025-06-04},
  abstract = {This article analyses the role of Telegram in orienting, amplifying, and normalizing the non-consensual diffusion of intimate images (NCII). We focus on the sense of anonymity, the platform’s weak regulation, and the possibility of creating large male communities, arguing that these affordances are “gendered affordances” as they orient male participants’ harassment behaviors and, in concert with an established misogynist culture, contribute to the reinstatement of hegemonic masculinity. The research draws on data collected through an online covert ethnography of Italian Telegram channels and groups.},
  langid = {english},
  keywords = {⏳,Distribution},
  file = {/Users/sgraf/Zotero/storage/IQJNWNLX/Semenzin und Bainotti_2020_The Use of Telegram for Non-Consensual Dissemination of Intimate Images Gendered Affordances and th.pdf}
}

@online{shahi2025a,
  title = {A {{Year}} of the {{DSA Transparency Database}}: {{What}} It ({{Does Not}}) {{Reveal About Platform Moderation During}} the 2024 {{European Parliament Election}}},
  shorttitle = {A {{Year}} of the {{DSA Transparency Database}}},
  author = {Shahi, Gautam Kishore and Tessa, Benedetta and Trujillo, Amaury and Cresci, Stefano},
  date = {2025-04-09},
  eprint = {2504.06976},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2504.06976},
  url = {http://arxiv.org/abs/2504.06976},
  urldate = {2025-10-08},
  abstract = {Social media platforms face heightened risks during major political events; yet, how platforms adapt their moderation practices in response remains unclear. The Digital Services Act Transparency Database offers an unprecedented opportunity to systematically study content moderation at scale, enabling researchers and policymakers to assess platforms’ compliance and effectiveness. Herein, we analyze 1.58 billion self-reported moderation actions taken by eight large social media platforms during an extended period of eight months surrounding the 2024 European Parliament elections. Our findings reveal a lack of adaptation in moderation strategies, as platforms did not exhibit significant changes in their enforcement behaviors surrounding the elections. This raises concerns about whether platforms adapted their moderation practices at all, or if structural limitations of the database concealed possible adjustments. Moreover, we found that noted transparency and accountability issues persist nearly a year after initial concerns were raised. These results highlight the limitations of current self-regulatory approaches and underscore the need for stronger enforcement and data access mechanisms to ensure that online platforms uphold their responsibility in safeguarding democratic processes.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Computers and Society,Computer Science - Emerging Technologies,Computer Science - Human-Computer Interaction},
  file = {/Users/sgraf/Zotero/storage/87XUSBCZ/Shahi et al._2025_A Year of the DSA Transparency Database What it (Does Not) Reveal About Platform Moderation During.pdf}
}

@report{shenkman2021,
  title = {Do You See What {{I}} See? {{Capabilities}} and Limits of Automated Multimedia Content Analysis},
  author = {Shenkman, Carey and Thakur, Dhanaraj and Llansó, E},
  date = {2021},
  institution = {Center for Democracy \& Technology},
  url = {https://cdt.org/wp-content/uploads/2021/05/2021-05-18-Do-You-See-What-I-See-Capabilities-Limits-of-Automated-Multimedia-Content-Analysis-Full-Report-2033-FINAL.pdf},
  file = {/Users/sgraf/Zotero/storage/9KCI2R78/Shenkman et al._2021_Do you see what I see Capabilities and limits of automated multimedia content analysis.pdf}
}

@online{similarweb2025,
  title = {Top Websites Ranking - Most Visited Websites in the World},
  author = {{Similarweb}},
  date = {2025-08},
  url = {https://www.similarweb.com/top-websites/},
  urldate = {2025-08-12},
  organization = {similarweb.com},
  keywords = {✅}
}

@online{sippy2024,
  title = {Behind the {{Deepfake}}: 8\% {{Create}}; 90\% {{Concerned}}. {{Surveying}} Public Exposure to and Perceptions of Deepfakes in the {{UK}}},
  shorttitle = {Behind the {{Deepfake}}},
  author = {Sippy, Tvesha and Enock, Florence and Bright, Jonathan and Margetts, Helen Z.},
  date = {2024},
  doi = {10.48550/ARXIV.2407.05529},
  url = {https://arxiv.org/abs/2407.05529},
  urldate = {2025-08-03},
  abstract = {This article examines public exposure to and perceptions of deepfakes based on insights from a nationally representative survey of 1403 UK adults. The survey is one of the first of its kind since recent improvements in deepfake technology and widespread adoption of political deepfakes. The findings reveal three key insights. First, on average, 15\% of people report exposure to harmful deepfakes, including deepfake pornography, deepfake frauds/scams and other potentially harmful deepfakes such as those that spread health/religious misinformation/propaganda. In terms of common targets, exposure to deepfakes featuring celebrities was 50.2\%, whereas those featuring politicians was 34.1\%. And 5.7\% of respondents recall exposure to a selection of high profile political deepfakes in the UK. Second, while exposure to harmful deepfakes was relatively low, awareness of and fears about deepfakes were high (and women were significantly more likely to report experiencing such fears than men). As with fears, general concerns about the spread of deepfakes were also high; 90.4\% of the respondents were either very concerned or somewhat concerned about this issue. Most respondents (at least 91.8\%) were concerned that deepfakes could add to online child sexual abuse material, increase distrust in information and manipulate public opinion. Third, while awareness about deepfakes was high, usage of deepfake tools was relatively low (8\%). Most respondents were not confident about their detection abilities and were trustful of audiovisual content online. Our work highlights how the problem of deepfakes has become embedded in public consciousness in just a few years; it also highlights the need for media literacy programmes and other policy interventions to address the spread of harmful deepfakes.},
  pubstate = {prepublished},
  version = {1},
  keywords = {⏳,Computers and Society (cs.CY),FOS: Computer and information sciences},
  file = {/Users/sgraf/Zotero/storage/YA2LXUVE/Sippy et al._2024_Behind the Deepfake 8% Create; 90% Concerned. Surveying public exposure to and perceptions of deepf.pdf}
}

@inproceedings{solaiman2023,
  title = {The {{Gradient}} of {{Generative AI Release}}: {{Methods}} and {{Considerations}}},
  shorttitle = {The {{Gradient}} of {{Generative AI Release}}},
  booktitle = {2023 {{ACM Conference}} on {{Fairness}}, {{Accountability}}, and {{Transparency}}},
  author = {Solaiman, Irene},
  date = {2023-06-12},
  pages = {111--122},
  publisher = {ACM},
  location = {Chicago IL USA},
  doi = {10.1145/3593013.3593981},
  url = {https://dl.acm.org/doi/10.1145/3593013.3593981},
  urldate = {2025-10-17},
  eventtitle = {{{FAccT}} '23: The 2023 {{ACM Conference}} on {{Fairness}}, {{Accountability}}, and {{Transparency}}},
  isbn = {979-8-4007-0192-4},
  langid = {english},
  file = {/Users/sgraf/Zotero/storage/9SF4DMAH/Solaiman_2023_The Gradient of Generative AI Release Methods and Considerations.pdf}
}

@article{sorbán2023,
  title = {An Elephant in the Room—{{EU}} Policy Gaps in the Regulation of Moderating Illegal Sexual Content on Video-Sharing Platforms},
  author = {Sorbán, Kinga},
  date = {2023-11-28},
  journaltitle = {International Journal of Law and Information Technology},
  volume = {31},
  number = {3},
  pages = {171--185},
  issn = {0967-0769, 1464-3693},
  doi = {10.1093/ijlit/eaad024},
  url = {https://academic.oup.com/ijlit/article/31/3/171/7273696},
  urldate = {2024-09-09},
  abstract = {Abstract             With the availability of broadband internet and a significant increase in storage capacity, people are sharing a dynamically growing amount of multimedia content on video-sharing platforms, including sexually explicit content. While sexual content on the internet is not illegal per se and remains in the domain of economic services, there are certain forms of sexually explicit content that are criminally unlawful, such as child pornography or non-consensual pornography. This article explores why the current business-oriented regulatory environment fails to provide effective tools to combat illegal sexual content: first, from the perspective of content moderation on video-sharing platforms, and then from the perspective of substantive criminal law. After mapping the gaps in policy at all levels of content regulation, the article offers recommendations to address these issues, open up a policy debate and influence policy makers.},
  langid = {english},
  keywords = {✅,legal},
  file = {/Users/sgraf/Zotero/storage/XPA7NIZC/Sorbán - 2023 - An elephant in the room—EU policy gaps in the regu.pdf}
}

@book{sprenger2024,
  title = {Das Plattformverfahren: Ausbalancierte Rechtsdurchsetzung mittels Verfahrensgrundsätzen},
  shorttitle = {Das Plattformverfahren},
  author = {Sprenger, Tim},
  date = {2024},
  series = {Normsetzung und Entscheidungsverfahren – Schriftenreihe des Weizenbaum-Instituts für normative Wissenschaften},
  edition = {1. Auflage},
  number = {2},
  publisher = {Nomos Verlagsgesellschaft mbH \& Co. KG},
  location = {Baden-Baden},
  doi = {10.5771/9783748949527},
  isbn = {978-3-7489-4952-7},
  langid = {german},
  pagetotal = {1},
  file = {/Users/sgraf/Zotero/storage/B69XW9NJ/9783748949527-23.pdf;/Users/sgraf/Zotero/storage/D3HZGI52/9783748949527-357.pdf;/Users/sgraf/Zotero/storage/XR4K4ZG6/Sprenger_2024_Das Plattformverfahren Ausbalancierte Rechtsdurchsetzung mittels Verfahrensgrundsätzen.pdf}
}

@article{stardust2024,
  title = {Mandatory Age Verification for Pornography Access: {{Why}} It Can't and Won't ‘Save the Children’},
  shorttitle = {Mandatory Age Verification for Pornography Access},
  author = {Stardust, Zahra and Obeid, Abdul and McKee, Alan and Angus, Daniel},
  date = {2024-06},
  journaltitle = {Big Data \& Society},
  shortjournal = {Big Data \& Society},
  volume = {11},
  number = {2},
  pages = {20539517241252129},
  issn = {2053-9517, 2053-9517},
  doi = {10.1177/20539517241252129},
  url = {https://journals.sagepub.com/doi/10.1177/20539517241252129},
  urldate = {2025-10-14},
  abstract = {Age verification is currently gaining traction among some western democracies as a means to restrict minors’ access to online pornography. In this article we consider the ramifications of applying age estimation software to this task. We analyse a public dataset of 10,139 facial images processed through a commonly used high-performance convolutional neural network approach and find significant inconsistencies in classification performance. Notably, the software demonstrates racial bias, with highest accuracy for the Caucasian category and lowest accuracy for the African category. It also displays age and gender bias, with lower accuracy for young males compared to young females. In addition to underwhelming technical performance, we argue that the concept of employing automated processes to restrict access to pornography is not only problematic but fundamentally misconceived. The systems being proposed to automate age verification create greater user data privacy risks and divert resourcing that could be spent on strategies that are proven to support healthy sexual development. Ultimately, mandatory age verification systems create barriers to post-pubescent young people seeking information about sex online. Our study concludes that the underlying problem with age verification, therefore, is not only technical but more profoundly political: even if the system can be made to work, it should not be.},
  langid = {english},
  file = {/Users/sgraf/Zotero/storage/2WL6BTNF/Stardust et al._2024_Mandatory age verification for pornography access Why it can't and won't ‘save the children’.pdf}
}

@article{stegeman2021,
  title = {Regulating and Representing Camming: Strict Limits on Acceptable Content on Webcam Sex Platforms},
  shorttitle = {Regulating and Representing Camming},
  author = {Stegeman, Hanne Marleen},
  date = {2021},
  journaltitle = {New Media \& Society},
  shortjournal = {New Media \& Society},
  volume = {26},
  number = {1},
  pages = {329--345},
  issn = {1461-4448, 1461-7315},
  doi = {10.1177/14614448211059117},
  url = {https://journals.sagepub.com/doi/10.1177/14614448211059117},
  urldate = {2025-06-04},
  abstract = {This article analyses the discursive construction of the limits of webcamming in terms of service agreements by BongaCams, LiveJasmin and Chaturbate, three of the world’s most popular webcam sex platforms. Through this analysis, the moderation practices in the webcamming industry are examined. Regulation of sexual platforms and its implications for representations of online sex work are still largely unclear. Through a critical discourse analysis of seven webcam platform terms of service documents, this article scrutinises the norms for camming as dictated by industry leading platforms. This analysis shows that these platforms, for legal and financial reasons, reject the idea of camming as sexually explicit or as (sex) work. Such a construction of camming limits sexual expression online, obstructs online sex workers’ labour rights and perpetuates sex work stigma. This article sheds light on how digital platforms can establish and maintain norms which regulate users’ online expressions, working conditions and representations.},
  langid = {english}
}

@article{stilinovic2025,
  title = {Creative {{Underspheres}} and Democratic Challenges: {{Exploring}} the Implications of Generative {{AI}} Misuse},
  shorttitle = {Creative {{Underspheres}} and Democratic Challenges},
  author = {Stilinovic, Milica and Bailo, Francesco and Hutchinson, Jonathon},
  date = {2025-05-15},
  journaltitle = {New Media \& Society},
  shortjournal = {New Media \& Society},
  pages = {14614448251338511},
  issn = {1461-4448, 1461-7315},
  doi = {10.1177/14614448251338511},
  url = {https://journals.sagepub.com/doi/10.1177/14614448251338511},
  urldate = {2025-06-04},
  abstract = {This article introduces the concept of the Undersphere – a networked community brought together via creative exchange – to highlight how the increased proliferation of Generative AI poses risks not yet acknowledged by policymakers within emerging AI regulatory frameworks. Employing a single case study methodology – namely, exploring exchanges made on r/StableDiffusion, a known subgroup on Reddit – it illustrates the conceptual parameters of the Undersphere, outlines the potential for creative harm within the GenAI space, and counters these elements against the AI regulatory frameworks found within the EU AI Act. It concludes that a risk management framework that provides a more fluid approach to addressing risks, such as those found in governance frameworks aimed at eradicating climate change, could be better positioned to address insecurities manifesting from the GenAI space.},
  langid = {english},
  file = {/Users/sgraf/Zotero/storage/SSC4VHC4/Stilinovic et al._2025_Creative Underspheres and democratic challenges Exploring the implications of generative AI misuse.pdf}
}

@article{sybert2022,
  title = {The Demise of \#{{NSFW}}: {{Contested}} Platform Governance and {{Tumblr}}’s 2018 Adult Content Ban},
  shorttitle = {The Demise of \#{{NSFW}}},
  author = {Sybert, Jeanna},
  date = {2022-10},
  journaltitle = {New Media \& Society},
  shortjournal = {New Media \& Society},
  volume = {24},
  number = {10},
  pages = {2311--2331},
  issn = {1461-4448, 1461-7315},
  doi = {10.1177/1461444821996715},
  url = {https://journals.sagepub.com/doi/10.1177/1461444821996715},
  urldate = {2025-06-04},
  abstract = {On December 3, 2018, Tumblr announced that it would ban sexually explicit content from the platform, drawing immediate backlash from users. The ensuing discord on the site is conceptualized here as contested platform governance, or a conflict between users and ownership, in which not only are a platform’s policies and features challenged, but also its core values, identity, and/or purposes are put into question. By examining 238 Tumblr posts, this analysis identifies the unique ways users combatted the ban and (re)inscribed community values, while also contesting the owners’ legitimacy to govern the platform. Holding implications for the site’s long-term survival, such conflicts capture a critical moment in which the boundaries of power between users and ownership are challenged and, possibly, transformed. By examining Tumblr’s Not Safe For Work (NSFW) ban through the lens of platform governance, this study offers insight into how power and its limits are negotiated online.},
  langid = {english},
  keywords = {⏳,✅},
  file = {/Users/sgraf/Zotero/storage/DPF4ZQRD/Sybert_2022_The demise of #NSFW Contested platform governance and Tumblr’s 2018 adult content ban.pdf}
}

@article{thurman2021,
  title = {The Regulation of Internet Pornography: {{What}} a Survey of Under‐18s Tells Us about the Necessity for and Potential Efficacy of Emerging Legislative Approaches},
  shorttitle = {The Regulation of Internet Pornography},
  author = {Thurman, Neil and Obster, Fabian},
  date = {2021-09},
  journaltitle = {Policy \& Internet},
  shortjournal = {Policy \&amp; Internet},
  volume = {13},
  number = {3},
  pages = {415--432},
  issn = {1944-2866, 1944-2866},
  doi = {10.1002/poi3.250},
  url = {https://onlinelibrary.wiley.com/doi/10.1002/poi3.250},
  urldate = {2024-09-09},
  abstract = {Abstract             In 2017, the UK Parliament passed an Act requiring legal pornographic websites to implement ‘robust’ age verification checks. Although the Act inspired lawmakers elsewhere to propose similar legislation, it was never enacted, in part because it did not cover social media platforms. Instead, the UK government has turned to its Online Harms White Paper—which does target social media platforms—to protect children from online pornography. There is, however, scant evidence on the media platforms and technologies children use to access pornography. To fill this knowledge gap, we conducted a survey of 16‐ and 17‐year‐olds in the United Kingdom. The results show that more (63\%) had seen pornography on social media platforms than on pornographic websites (47\%), suggesting the UK government was right to target such platforms in its latest proposals. However, pornography was much more frequently viewed on pornographic websites than on social media, showing how important the regulation of such sites remains. Furthermore, our finding that 46\% of 16‐ and 17‐year‐olds had used a virtual private network or Tor browser adds weight to concerns that restrictions on legal internet pornography—such as age verification checks—imposed by a single country may be circumvented by those the restrictions are designed to protect.           ,              摘要             2017年，英国议会通过一项法案，要求合法的色情网站执行“稳健的”年龄验证措施。尽管该法案启发了其他地方的立法者提出相似法律，但该法案却从未颁布，这部分归因于其没有涵盖社交媒体平台。相反，英国政府转向《网络危害白皮书》—该白皮书以社交媒体平台为目标—来保护儿童远离网络色情。不过，几乎没有关于儿童获取色情网站所使用的媒体平台和技术的研究。为填补该知识空白，我们对英国16‐17岁的未成年人进行了一项调查。调查结果显示，比起浏览色情网站（47\%），更多的调查对象（63\%）通过社交媒体平台浏览色情内容，这暗示英国政府在最近的提议中瞄准这类平台是正确的。不过，比起社交媒体，色情网站的浏览次数高得多，这表明了对这类网站的监管仍然是重要的。此外，我们的研究发现—46\%的调查对象曾使用虚拟专用网络或Tor浏览器—强调了相关顾虑，即由单个国家强制执行的合法网络色情限制（例如年龄验证）可能被保护对象所规避。           ,              Resumen             En 2017, el Parlamento del Reino Unido aprobó una ley que requiere que los sitios web pornográficos legales implementen controles de verificación de edad "robustos". Aunque la ley inspiró a los legisladores de otros lugares a proponer una legislación similar, nunca se promulgó, en parte porque no cubría las plataformas de redes sociales. En cambio, el gobierno del Reino Unido ha recurrido a su Libro blanco sobre daños en línea, que se dirige a las plataformas de redes sociales, para proteger a los niños de la pornografía en línea. Sin embargo, hay poca evidencia sobre las plataformas de medios y las tecnologías que utilizan los niños para acceder a la pornografía. Para llenar este vacío de conocimiento, realizamos una encuesta a jóvenes de 16 y 17 años en el Reino Unido. Los resultados muestran que más (63\%) había visto pornografía en plataformas de redes sociales que en sitios web pornográficos (47\%), lo que sugiere que el gobierno del Reino Unido hizo bien en apuntar a tales plataformas en sus últimas propuestas. Sin embargo, la pornografía se ve con mucha más frecuencia en sitios web pornográficos que en las redes sociales, lo que demuestra lo importante que sigue siendo la regulación de dichos sitios. Además, nuestro hallazgo de que el 46\% de los jóvenes de 16 y 17 años habían usado un navegador VPN o Tor aumenta las preocupaciones de que las restricciones sobre la pornografía legal en Internet, como los controles de verificación de edad, impuestas por un solo país pueden ser eludidas por aquellos las restricciones están diseñadas para proteger.},
  langid = {english},
  keywords = {⏳,unread},
  file = {/Users/sgraf/Zotero/storage/Y7S8I8B9/Thurman und Obster - 2021 - The regulation of internet pornography What a sur.pdf}
}

@article{thurman2022,
  title = {Lessons from {{France}} on the Regulation of {{Internet}} Pornography: {{How}} Displacement Effects, Circumvention, and Legislative Scope May Limit the Efficacy of {{Article}} 23},
  shorttitle = {Lessons from {{France}} on the Regulation of {{Internet}} Pornography},
  author = {Thurman, Neil and Nalmpatian, Asmik and Obster, Fabian},
  date = {2022-09},
  journaltitle = {Policy \& Internet},
  shortjournal = {Policy \& Internet},
  volume = {14},
  number = {3},
  pages = {690--710},
  issn = {1944-2866, 1944-2866},
  doi = {10.1002/poi3.293},
  url = {https://onlinelibrary.wiley.com/doi/10.1002/poi3.293},
  urldate = {2024-09-09},
  abstract = {Abstract             In 2020, the French Parliament passed an amendment that put the country at the forefront of attempts by democratic states to restrict young people's access to legal online pornography. This study examines the necessity for and potential efficacy of the amendment, Article 23,~through a comparative analysis of emerging legislative and regulatory approaches in France, the UK, Canada, Utah, and Germany, and through a survey of French 15‐, 16‐, and 17‐year‐olds. Among~other things, our survey shows that 41\% of 15‐, 16‐, and 17‐year‐olds in France visit dedicated pornographic sites, on average monthly and often much more frequently. However, the range of media platforms via which French adolescents are exposed to pornography, their knowledge about technologies that could circumvent age verification, and the power, scope, and implementation of Article 23 may limit the legislation's efficacy. Our findings suggest the mechanisms that may limit its efficacy include media displacement, socio‐technical circumvention, and the Article's relatively broad and imprecise nature. This study has implications for legislators and regulators in democratic countries beyond France as they too grapple with the challenges of regulating online pornography. Furthermore, it extends the often contradictory and/or limited evidence that exists about adolescents' consumption of pornography.           ,              摘要             2020年，法国议会通过了一项修订案，此举在由民主国家发起的限制年轻人对合法网络色情获取的一系列举措中占据重要位置。通过对法国、英国、加拿大、犹他州、以及德国的法律措施和监管措施进行比较分析，并通过对法国的15‐17岁未成年人进行调研，本研究分析了该修订案的必要性和潜在效能。我们的调查显示，除其他因素外，法国15‐17岁未成年中有41\%的人平均每月访问并且经常更频繁地访问专门的色情网站。不过，法国未成年人接触的色情媒体平台范围、其对能规避年龄验证的技术的了解、以及《法案第23条》（Article 23）的权力、范围和执行，这些因素能限制该法案的效能。我们的研究发现暗示，能限制该法律效能的机制包括媒体替代（media displacement）、社会‐技术规避、以及该法案相对宽泛和模糊的性质。本研究对法国之外的民主国家的立法者和监管者具有意义，因为他们也在努力应对网络色情监管挑战。此外，本研究扩展了有关未成年人色情消费的证据，后者经常是不一致和/或不充足的。           ,              Resumen             En 2020, el parlamento francés aprobó una enmienda que colocó al país a la vanguardia de los intentos de los estados democráticos de restringir el acceso de los jóvenes a la pornografía legal en línea. Este estudio examina la necesidad y la eficacia potencial de la enmienda a través de un análisis comparativo de enfoques legislativos y regulatorios emergentes en Francia, el Reino Unido, Canadá, Utah y Alemania, y a través de una encuesta de franceses de 15, 16 y 17 años. Entre otras cosas, nuestra encuesta muestra que el 41\% de los jóvenes de 15, 16 y 17 años en Francia visitan sitios pornográficos dedicados, en promedio mensualmente y, a menudo, con mucha más frecuencia. Sin embargo, la variedad de plataformas de medios a través de las cuales los adolescentes franceses están expuestos a la pornografía, su conocimiento sobre tecnologías que podrían eludir la verificación de edad y el poder, el alcance y la implementación del Artículo 23 pueden limitar su eficacia. Nuestros hallazgos sugieren que los mecanismos que pueden limitar la eficacia de la legislación incluyen el desplazamiento de los medios, la elusión sociotécnica y la naturaleza relativamente amplia e imprecisa del artículo. Este estudio tiene implicaciones para los legisladores y reguladores en países democráticos más allá de Francia, ya que ellos también lidian con los desafíos de regular la pornografía en línea. Además, amplía la evidencia muchas veces contradictoria y/o limitada que existe sobre el consumo de pornografía por parte de los adolescentes.},
  langid = {english},
  keywords = {⏳,unread},
  file = {/Users/sgraf/Zotero/storage/CN36NS8P/Thurman et al. - 2022 - Lessons from France on the regulation of Internet .pdf}
}

@article{tiidenberg2021,
  title = {Sex, Power and Platform Governance},
  author = {Tiidenberg, Katrin},
  date = {2021-10-02},
  journaltitle = {Porn Studies},
  shortjournal = {Porn Studies},
  volume = {8},
  number = {4},
  pages = {381--393},
  issn = {2326-8743, 2326-8751},
  doi = {10.1080/23268743.2021.1974312},
  url = {https://www.tandfonline.com/doi/full/10.1080/23268743.2021.1974312},
  urldate = {2025-03-05},
  langid = {english},
  keywords = {⏳},
  file = {/Users/sgraf/Zotero/storage/HMTGKB4M/Tiidenberg_2021_Sex, power and platform governance.pdf}
}

@article{timmerman2023,
  title = {Studying the {{Online Deepfake Community}}},
  author = {Timmerman, Brian and Mehta, Pulak and Deb, Progga and Gallagher, Kevin and Dolan-Gavitt, Brendan and Garg, Siddharth and Greenstadt, Rachel},
  date = {2023-09-21},
  journaltitle = {Journal of Online Trust and Safety},
  shortjournal = {jots},
  volume = {2},
  number = {1},
  issn = {2770-3142},
  doi = {10.54501/jots.v2i1.126},
  url = {https://www.tsjournal.org/index.php/jots/article/view/126},
  urldate = {2025-07-05},
  abstract = {Deepfakes have become a dual-use technology with applications in the domains of art, science, and industry. However, the technology can also be leveraged maliciously in areas such as disinformation, identity fraud, and harassment. In response to the technology's dangerous potential many deepfake creation communities have been deplatformed, including the technology's originating community~– r/deepfakes. Opening in February 2018, just eight days after the removal of r/deepfakes, MrDeepFakes (MDF) went online as a privately owned platform to fulfill the role of community hub, and has since grown into the largest dedicated deepfake creation and discussion platform currently online. This position of community hub is balanced against the site's other main purpose, which is the hosting of deepfake pornography depicting public figures- produced without consent. In this paper we explore the two largest deepfake communities that have existed via a mixed methods approach utilizing quantitative and qualitative analysis. We seek to identify how these platforms were and are used by their members, what opinions these deepfakers hold about the technology and how it is seen by society at large, and identify how deepfakes-as-disinformation is viewed by the community. We find that there is a large emphasis on technical discussion on these platforms, intermixed with potentially malicious content. Additionally, we find the deplatforming of deepfake communities early in the technology's life has significantly impacted trust regarding alternative community platforms.},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/UDYA32NA/Timmerman et al._2023_Studying the Online Deepfake Community.pdf}
}

@article{tremmel2020,
  entrysubtype = {nonacademic},
  title = {Am {{I}} in {{Porn}} \& {{Pimeyes}}: {{Warum Gesichtserkennung}} Gegen {{Rachepornos}} Bedenklich Ist},
  author = {Tremmel, Moritz},
  date = {2020-08-13},
  journaltitle = {Golem},
  url = {https://www.golem.de/news/am-i-in-porn-pimeyes-warum-gesichtserkennung-gegen-rachepornos-bedenklich-ist-2008-150103.html}
}

@article{trujillo2025,
  title = {The {{DSA Transparency Database}}: Auditing Self-Reported Moderation Actions by Social Media},
  shorttitle = {The {{DSA Transparency Database}}},
  author = {Trujillo, Amaury and Fagni, Tiziano and Cresci, Stefano},
  date = {2025-05-02},
  journaltitle = {Proceedings of the ACM on Human-Computer Interaction},
  shortjournal = {Proc. ACM Hum.-Comput. Interact.},
  volume = {9},
  number = {2},
  pages = {1--28},
  issn = {2573-0142},
  doi = {10.1145/3711085},
  url = {https://dl.acm.org/doi/10.1145/3711085},
  urldate = {2025-09-28},
  abstract = {Since September 2023, the Digital Services Act (DSA) obliges large online platforms to submit detailed data on each moderation action they take within the European Union (EU) to the DSA Transparency Database. From its inception, this centralized database has sparked scholarly interest as an unprecedented and potentially unique trove of data on real-world online moderation. Here, we thoroughly analyze all 353.12M records submitted by the eight largest social media platforms in the EU during the first 100 days of the database. Specifically, we conduct a platform-wise comparative study of their: volume of moderation actions, grounds for decision, types of applied restrictions, types of moderated content, timeliness in undertaking and submitting moderation actions, and use of automation. Furthermore, we systematically cross-check the contents of the database with the platforms' own transparency reports. Our analyses reveal that (i) the platforms adhered only in part to the philosophy and structure of the database, (ii) the structure of the database is partially inadequate for the platforms' reporting needs, (iii) the platforms exhibited substantial differences in their moderation actions, (iv) a remarkable fraction of the database data is inconsistent, (v) the platform X (formerly Twitter) presents the most inconsistencies. Our findings have far-reaching implications for policymakers and scholars across diverse disciplines. They offer guidance for future regulations that cater to the reporting needs of online platforms in general, but also highlight opportunities to improve and refine the database itself.},
  langid = {english},
  keywords = {⏳},
  file = {/Users/sgraf/Zotero/storage/ZK5EADU3/Trujillo et al._2025_The DSA Transparency Database Auditing Self-reported Moderation Actions by Social Media.pdf}
}

@report{uklawcommission2022,
  title = {Intimate Image Abuse: A Final Report},
  author = {{UK Law Commission}},
  date = {2022-07-06},
  number = {Law Com No 407},
  pages = {505},
  institution = {Law Commission},
  url = {https://webarchive.nationalarchives.gov.uk/ukgwa/20250109101427mp_/https://cloud-platform-e218f50a4812967ba1215eaecede923f.s3.amazonaws.com/uploads/sites/30/2022/07/Intimate-image-abuse-final-report.pdf},
  urldate = {2025-06-16},
  file = {/Users/sgraf/Zotero/storage/7HGLM6S4/UK Law Commission_2022_Intimate image abuse a final report.pdf}
}

@inproceedings{umbach2024,
  title = {Non-{{Consensual Synthetic Intimate Imagery}}: {{Prevalence}}, {{Attitudes}}, and {{Knowledge}} in 10 {{Countries}}},
  shorttitle = {Non-{{Consensual Synthetic Intimate Imagery}}},
  booktitle = {Proceedings of the {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Umbach, Rebecca and Henry, Nicola and Beard, Gemma Faye and Berryessa, Colleen M.},
  date = {2024-05-11},
  pages = {1--20},
  publisher = {ACM},
  location = {Honolulu HI USA},
  doi = {10.1145/3613904.3642382},
  url = {https://dl.acm.org/doi/10.1145/3613904.3642382},
  urldate = {2025-08-03},
  eventtitle = {{{CHI}} '24: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {979-8-4007-0330-0},
  langid = {english},
  keywords = {⏳},
  file = {/Users/sgraf/Zotero/storage/FEVLTFUR/Umbach et al._2024_Non-Consensual Synthetic Intimate Imagery Prevalence, Attitudes, and Knowledge in 10 Countries.pdf}
}

@article{vandernagel2020,
  title = {Verifying Images: Deepfakes, Control, and Consent},
  shorttitle = {Verifying Images},
  author = {Van Der Nagel, Emily},
  date = {2020-10},
  journaltitle = {Porn Studies},
  shortjournal = {Porn Studies},
  volume = {7},
  number = {4},
  pages = {424--429},
  issn = {2326-8743, 2326-8751},
  doi = {10.1080/23268743.2020.1741434},
  url = {https://www.tandfonline.com/doi/full/10.1080/23268743.2020.1741434},
  urldate = {2025-06-03},
  langid = {english},
  keywords = {⏳},
  file = {/Users/sgraf/Zotero/storage/TFDL2SLJ/Van Der Nagel_2020_Verifying images deepfakes, control, and consent.pdf}
}

@article{velez2019,
  title = {“{{Why Take}} the {{Photo}} If {{You Didn}}’t {{Want It Online}}?”: {{Agency}}, {{Transformation}}, and {{Nonconsensual Pornography}}},
  shorttitle = {“{{Why Take}} the {{Photo}} If {{You Didn}}’t {{Want It Online}}?},
  author = {Velez, Meghan},
  date = {2019-10-02},
  journaltitle = {Women's Studies in Communication},
  volume = {42},
  number = {4},
  pages = {452--470},
  publisher = {Informa UK Limited},
  issn = {0749-1409, 2152-999X},
  doi = {10.1080/07491409.2019.1676350},
  url = {https://www.tandfonline.com/doi/full/10.1080/07491409.2019.1676350},
  urldate = {2025-07-15},
  langid = {english},
  file = {/Users/sgraf/Zotero/storage/52XVE76N/Velez_2019_“Why Take the Photo if You Didn’t Want It Online” Agency, Transformation, and Nonconsensual Pornog.pdf}
}

@article{viola2023,
  title = {Designed to Abuse? {{Deepfakes}} and the Non-Consensual Diffusion of Intimate Images},
  shorttitle = {Designed to Abuse?},
  author = {Viola, Marco and Voto, Cristina},
  date = {2023-01-13},
  journaltitle = {Synthese},
  shortjournal = {Synthese},
  volume = {201},
  number = {1},
  pages = {30},
  issn = {1573-0964},
  doi = {10.1007/s11229-022-04012-2},
  url = {https://link.springer.com/10.1007/s11229-022-04012-2},
  urldate = {2025-06-03},
  abstract = {Abstract                            The illicit diffusion of intimate photographs or videos intended for private use is a troubling phenomenon known as the diffusion of Non-Consensual Intimate Images (NCII). Recently, it has been feared that the spread of deepfake technology, which allows users to fabricate fake intimate images or videos that are indistinguishable from genuine ones, may dramatically extend the scope of NCII. In the present essay, we counter this pessimistic view, arguing for               qualified               optimism instead. We hypothesize that the growing diffusion of deepfakes will end up disrupting the status that makes our visual experience of photographic images and videos epistemically and affectively special; and that once divested of this status, NCII will lose much of their allure in the eye of the perpetrators, probably resulting in diminished diffusion. We conclude by offering some caveats and drawing some implications to better understand, and ultimately better counter, this phenomenon.},
  langid = {english},
  keywords = {⏳},
  file = {/Users/sgraf/Zotero/storage/WKD8QLMR/Viola und Voto_2023_Designed to abuse Deepfakes and the non-consensual diffusion of intimate images.pdf}
}

@article{waldron2010,
  title = {Dignity and Defamation: The Visibility of Hate},
  author = {Waldron, Jeremy},
  date = {2010},
  journaltitle = {Harvard Law Review},
  volume = {Vol. 123},
  pages = {1596--1657},
  file = {/Users/sgraf/Zotero/storage/HES6SE9Y/Waldron_2010_Dignity and defamation the visibility of hate.pdf}
}

@article{warzel2018,
  entrysubtype = {nonacademic},
  title = {Pornhub Banned Deepfake Celebrity Sex Videos, but the Site Is Still Full of Them},
  author = {Warzel, Charlie},
  date = {2018-04-19},
  url = {https://www.buzzfeednews.com/article/charliewarzel/pornhub-banned-deepfake-celebrity-sex-videos-but-the-site#.hrzVy3bM5V},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/GWVXQ3GL/Warzel_2018_Pornhub banned deepfake celebrity sex videos, but the site is still full of them.pdf}
}

@article{webber2023,
  title = {Pornhub and {{Policy}}: {{Examining}} the {{Erasure}} of {{Pornography Workers}} in {{Canadian Platform Governance}}},
  shorttitle = {Pornhub and {{Policy}}},
  author = {Webber, Valerie and MacDonald, Maggie and Duguay, Stefanie and McKelvey, Fenwick},
  date = {2023-06-01},
  journaltitle = {Canadian Journal of Communication},
  volume = {48},
  number = {2},
  pages = {381--404},
  publisher = {University of Toronto Press Inc. (UTPress)},
  issn = {0705-3657, 1499-6642},
  doi = {10.3138/cjc.2022-0044},
  url = {https://cjc.utppublishing.com/doi/10.3138/cjc.2022-0044},
  urldate = {2025-05-22},
  abstract = {Background: In 2021, the Canadian Parliamentary Standing Committee on Access to Information, Privacy and Ethics (ETHI) conducted an inquiry around Pornhub, following allegations that parent company MindGeek profits from non-consensual content.  Analysis: This article offers a discourse analysis of the ETHI’s process, testimony, and report on Pornhub using Carol Bacchi’s policy analysis method, “What is the problem represented to be?”  Conclusions and implications: This study reveals a policy process blatantly influenced by anti-porn sentiments, resulting in hearings that framed porn as sexual violence rather than sex industry labour. It exposes how ETHI’s approach failed to constructively engage existing regulations, precarious labour conditions, or platform operations. The result is ineffective policy recommendations that procedurally exclude relevant stakeholders and do not adequately protect platform users from harm.},
  langid = {english},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/4ZZ6QLB2/Webber et al._2023_Pornhub and Policy Examining the Erasure of Pornography Workers in Canadian Platform Governance.pdf}
}

@report{webgroupczechrepublica.s.2024,
  title = {Transparency Report},
  author = {{WebGroup Czech Republic, a.s.}},
  date = {2024-12-20},
  number = {01.06-30.11.2024},
  institution = {WebGroup Czech Republic, a.s. (xvideos.com)},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/LUGL4XPR/WebGroup Czech Republic, a.s._2024_Transparency report.pdf}
}

@report{webgroupczechrepublica.s.2024a,
  title = {Transparency Report},
  author = {{WebGroup Czech Republic, a.s.}},
  date = {2024},
  number = {02.-05.2024},
  institution = {WebGroup Czech Republic, a.s. (xvideos.com)},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/K3AVRI8K/WebGroup Czech Republic, a.s._Transparency report.pdf}
}

@report{webgroupczechrepublica.s.2024b,
  title = {Risk Assessment \& Risk Management Report},
  author = {{WebGroup Czech Republic a.s.}},
  date = {2024-04-18},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/9IKACWCV/WebGroup Czech Republic a.s. und Hradecký_2024_Risk assessment & risk management report.pdf}
}

@online{webgroupczechrepublica.s.2024c,
  title = {Terms of {{Service}}},
  author = {{WebGroup Czech Republic, a.s.}},
  date = {2024-02-17},
  url = {https://info.xvideos.net/legal/tos},
  organization = {XVideos info page}
}

@report{webgroupczechrepublica.s.2025,
  title = {Transparency Report},
  author = {{WebGroup Czech Republic, a.s.}},
  date = {2025-02-28},
  number = {01.06.2024-31.12.2024},
  institution = {WebGroup Czech Republic, a.s. (xvideos.com)},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/5WZ9D36M/WebGroup Czech Republic, a.s._2025_Transparency report.pdf}
}

@report{webgroupczechrepublica.s.2025a,
  title = {Risk Assessment \& Risk Management Report},
  author = {{WebGroup Czech Republic a.s.}},
  date = {2025-04},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/ALLTHF8S/WebGroup Czech Republic a.s._2025_Risk assessment & risk management report.pdf}
}

@report{webgroupczechrepublica.s.2025b,
  title = {Audit Implementation Report},
  author = {{WebGroup Czech Republic, a.s.}},
  date = {2025-05},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/KU2PWDK2/WebGroup Czech Republic, a.s._2025_Audit implementation report.pdf}
}

@report{webgroupczechrepublica.s.2025c,
  title = {Transparency Report},
  author = {{WebGroup Czech Republic, a.s.}},
  date = {2025-08-29},
  number = {3},
  url = {https://cdn77-pic.xvideos-cdn.com/videos/transparency/XVideos_3rd_Transparency_Report_January_to_June_2025.pdf},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/M2DZ5N8X/WebGroup Czech Republic, a.s. (xvideos.com)_2025_Transparency report.pdf}
}

@article{west2024,
  title = {Image-Based Sexual Violence and Imperfect Victims: The Case for Platform Cooperativism in the Online Sex Industry},
  shorttitle = {Image-Based Sexual Violence and Imperfect Victims},
  author = {West, Josie Rachel},
  date = {2024-06-26},
  journaltitle = {Porn Studies},
  shortjournal = {Porn Studies},
  pages = {1--15},
  issn = {2326-8743, 2326-8751},
  doi = {10.1080/23268743.2024.2362154},
  url = {https://www.tandfonline.com/doi/full/10.1080/23268743.2024.2362154},
  urldate = {2025-06-03},
  langid = {english},
  file = {/Users/sgraf/Zotero/storage/RQCUN8QJ/West_2024_Image-based sexual violence and imperfect victims the case for platform cooperativism in the online.pdf}
}

@book{williams2002,
  title = {Truth and Truthfulness: An Essay in Genealogy},
  author = {Williams, Bernard},
  date = {2002},
  eprint = {j.ctt7ssz4},
  eprinttype = {jstor},
  publisher = {Princeton University Press},
  url = {http://www.jstor.org/stable/j.ctt7ssz4},
  urldate = {2025-10-17},
  abstract = {What does it mean to be truthful? What role does truth play in our lives? What do we lose if we reject truthfulness? No philosopher is better suited to answer these questions than Bernard Williams. Writing with his characteristic combination of passion and elegant simplicity, he explores the value of truth and finds it to be both less and more than we might imagine.  Modern culture exhibits two attitudes toward truth: suspicion of being deceived (no one wants to be fooled) and skepticism that objective truth exists at all (no one wants to be naive). This tension between a demand for truthfulness and the doubt that there is any truth to be found is not an abstract paradox. It has political consequences and signals a danger that our intellectual activities, particularly in the humanities, may tear themselves to pieces.  Williams's approach, in the tradition of Nietzsche's genealogy, blends philosophy, history, and a fictional account of how the human concern with truth might have arisen. Without denying that we should worry about the contingency of much that we take for granted, he defends truth as an intellectual objective and a cultural value. He identifies two basic virtues of truth, Accuracy and Sincerity, the first of which aims at finding out the truth and the second at telling it. He describes different psychological and social forms that these virtues have taken and asks what ideas can make best sense of them today.  {$<$}em{$>$}Truth and Truthfulness{$<$}/em{$>$}presents a powerful challenge to the fashionable belief that truth has no value, but equally to the traditional faith that its value guarantees itself. Bernard Williams shows us that when we lose a sense of the value of truth, we lose a lot both politically and personally, and may well lose everything.},
  isbn = {978-0-691-11791-1}
}

@article{williams2025,
  entrysubtype = {nonacademic},
  title = {Free Speech Advocates Express Concerns as {{TAKE IT DOWN Act}} Passes {{US}} Senate},
  author = {Williams, Kaylee},
  date = {2025-02-21},
  journaltitle = {Tech Policy Press},
  url = {https://www.techpolicy.press/free-speech-advocates-express-concerns-as-take-it-down-act-passes-us-senate/},
  urldate = {2025-04-02},
  file = {/Users/sgraf/Zotero/storage/TT4JIMAX/Williams_2025_Free Speech Advocates Express Concerns As TAKE IT DOWN Act Passes US Senate.pdf}
}

@article{witt2022,
  title = {Platform {{Regulation}} in {{Europe}}— {{{\mkbibemph{Per Se}}}} {{Rules}} to the {{Rescue}}?},
  author = {Witt, Anne C},
  date = {2022-09-15},
  journaltitle = {Journal of Competition Law \& Economics},
  volume = {18},
  number = {3},
  pages = {670--708},
  issn = {1744-6414, 1744-6422},
  doi = {10.1093/joclec/nhac001},
  url = {https://academic.oup.com/jcle/article/18/3/670/6535681},
  urldate = {2025-03-05},
  abstract = {ABSTRACT             Mainstream competition law has failed to protect competition in core digital platform markets. This is partially due to enforcement agencies’ current commitment to proving the investigated conduct’s actual effects on competition and consumer welfare on the basis of in-depth assessments of each case’s individual circumstances before intervening in the market. While reducing the likelihood of erroneously prohibiting conduct that is not actually harmful, this approach is too time- and resource-consuming to protect competition in digital markets prone to tipping. This contribution argues that well-designed per se rules offer a promising alternative. Against this background, it critically assesses how three emerging European models of platform regulation (the draft EU Digital Markets Act, the draft UK Pro-Competition Regime, and the German Digitalisation Act) balance the objectives of ensuring time- and cost-effective enforcement, avoiding enforcement errors, and maximizing legal certainty for platforms. It concludes that the UK model currently promises to strike the best balance between these competing aims.},
  langid = {english},
  keywords = {⏳,❌}
}

@book{wolcott1994,
  title = {Transforming Qualitative Data: Description, Analysis, and Interpretation},
  shorttitle = {Transforming Qualitative Data},
  author = {Wolcott, Harry F.},
  date = {1994},
  publisher = {SAGE},
  isbn = {978-0-8039-5281-2 978-0-8039-5280-5},
  pagetotal = {433}
}

@online{xnxx,
  title = {Content Control},
  author = {{XNXX}},
  url = {https://info.xnxx.com/legal/control},
  urldate = {2025-08-26},
  organization = {info.xnxx.com},
  keywords = {✅}
}

@online{xnxx2002,
  title = {{{XNXX}}: {{Daily}} Hardcore High Quality Series Only},
  author = {{XNXX}},
  date = {2002-06-05},
  url = {https://web.archive.org/web/20020605231501/http://www.xnxx.com/free.shtml},
  urldate = {2025-09-13},
  organization = {Internet Archive},
  keywords = {✅}
}

@online{xnxx2025,
  title = {Mandatory Information / Reports},
  author = {{XNXX}},
  date = {2025-08-08},
  url = {https://info.xnxx.com/legal/mandatory-information},
  urldate = {2025-09-13},
  organization = {XNXX info page},
  keywords = {✅}
}

@online{xnxxa,
  title = {Abuse Reporting Form (Exclude Copyright)},
  author = {{XNXX}},
  url = {https://info.xnxx.com/takedown-amateur},
  urldate = {2025-09-14},
  organization = {info.xnxx.com},
  keywords = {✅}
}

@online{xnxxb,
  title = {Content Protection},
  author = {{XNXX}},
  url = {https://info.xnxx.com/content/fingerprint},
  organization = {Information and links}
}

@online{xvideos,
  title = {Account Status},
  author = {{XVideos}},
  url = {https://info.xvideos.net/account-status},
  urldate = {2025-09-13},
  organization = {XVideos info page},
  keywords = {✅}
}

@online{xvideos2007,
  title = {{{XVideos}}: {{Bigger}} and {{Better}} than the Others...{{Xvideos}}.Com},
  author = {{XVideos}},
  date = {2007-05-06},
  url = {https://web.archive.org/web/20070506121524/http://www.xvideos.com/},
  urldate = {2025-09-13},
  organization = {Internet Archive},
  keywords = {✅}
}

@online{xvideos2025,
  title = {Mandatory Information / Reports},
  author = {{XVideos}},
  date = {2025-08-09},
  url = {https://info.xvideos.net/legal/mandatory-information},
  urldate = {2025-09-13},
  organization = {XVideos info page},
  keywords = {✅}
}

@online{xvideosa,
  title = {Abuse Reporting Form (Excluding Copyright)},
  author = {{XVideos}},
  url = {https://info.xvideos.net/takedown-amateur},
  urldate = {2025-09-14},
  organization = {Information and links}
}

@online{xvideosb,
  title = {Contact Form – Authorities},
  author = {{XVideos}},
  url = {https://info.xvideos.net/authority-contact},
  urldate = {2025-08-26},
  keywords = {✅}
}

@online{xvideosc,
  title = {Content Protection},
  author = {{XVideos}},
  url = {https://info.xvideos.net/content/fingerprint},
  organization = {Information and links}
}

@article{yanow2007,
  title = {Interpretation in Policy Analysis: {{On}} Methods and Practice},
  shorttitle = {Interpretation in Policy Analysis},
  author = {Yanow, Dvora},
  date = {2007-03},
  journaltitle = {Critical Policy Studies},
  shortjournal = {Critical Policy Studies},
  volume = {1},
  number = {1},
  pages = {110--122},
  issn = {1946-0171, 1946-018X},
  doi = {10.1080/19460171.2007.9518511},
  url = {http://www.tandfonline.com/doi/abs/10.1080/19460171.2007.9518511},
  urldate = {2025-04-04},
  langid = {english},
  keywords = {⏳,✅},
  file = {/Users/sgraf/Zotero/storage/JC2ABC2W/Interpretation in policy analysis  On methods and practice.pdf;/Users/sgraf/Zotero/storage/PMI76LIN/Yanow_2007_Interpretation in policy analysis On methods and practice.pdf}
}

@incollection{yanow2007a,
  title = {Qualitative-{{Interpretive Methods}} in {{Policy Research}}},
  booktitle = {Handbook of Public Policy Analysis: Theory, Politics, and Methods},
  author = {Yanow, Dvora},
  editor = {Fischer, Frank and Miller, Gerald},
  date = {2007},
  series = {Public {{Administration}} and {{Public Policy}}},
  edition = {1st edition},
  pages = {405--416},
  publisher = {Routledge},
  location = {New York},
  doi = {10.4324/9781315093192},
  abstract = {"The study of public policy and the methods of policy analysis are among the most rapidly developing areas in the social sciences. Policy analysis has emerged to provide a better understanding of the policymaking process and to supply decision makers with reliable policy-relevant knowledge about pressing economic and social problems. Presenting a broad, comprehensive perspective, the Handbook of Public Policy Analysis: Theory, Politics, and Methods covers the historical development of policy analysis, its role in the policy process, and empirical methods. The handbook considers the theory generated by these methods and the normative and ethical issues surrounding their practice. Written by leading experts in the field, this book-Deals with the basic origins and evolution of public policy Examines the stages of the policy-making processIdentifies political advocacy and expertise in the policy processFocuses on rationality in policy decision-making and the role of policy networks and learningDetails argumentation, rhetoric, and narratives Explores the comparative, cultural, and ethical aspects of public policy Explains primary quantitative-oriented analytical methods employed in policy researchAddresses the qualitative sides of policy analysis Discusses tools used to refine policy choicesTraces the development of policy analysis in selected national contextsThe Handbook of Public Policy Analysis: Theory, Politics, and Methods describes the theoretical debates that have recently defined the field, including the work of postpositivist, interpretivist, and social constructionist scholars. This book also explores the interplay between empirical and normative analysis, a crucial issue running through contemporary debates."--Provided by publisher},
  isbn = {978-1-315-09319-2},
  langid = {english},
  keywords = {⏳},
  file = {/Users/sgraf/Zotero/storage/PURF6CKD/Fischer und Miller_2017_Handbook of public policy analysis theory, politics, and methods.pdf}
}

@online{youtubehelp,
  title = {Disclosing Use of Altered or Synthetic Content},
  author = {{YouTube Help}},
  url = {https://support.google.com/youtube/answer/14328491?hl=en-GB&co=GENIE.Platform%3DDesktop},
  organization = {Help center – Policy, safety and copyright}
}

@online{youtubehelpa,
  title = {Nudity \& Sexual Content Policy},
  author = {{YouTube Help}},
  url = {https://support.google.com/youtube/answer/2802002?sjid=1053035187831839611-EU},
  organization = {Help center}
}

@article{zhu2020,
  title = {Deepfakes for Medical Video De-Identification: Privacy Protection and Diagnostic Information Preservation},
  shorttitle = {Deepfakes for {{Medical Video De-Identification}}},
  author = {Zhu, Bingquan and Fang, Hao and Sui, Yanan and Li, Luming},
  date = {2020},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.2003.00813},
  url = {https://arxiv.org/abs/2003.00813},
  urldate = {2025-10-17},
  abstract = {Data sharing for medical research has been difficult as open-sourcing clinical data may violate patient privacy. Traditional methods for face de-identification wipe out facial information entirely, making it impossible to analyze facial behavior. Recent advancements on whole-body keypoints detection also rely on facial input to estimate body keypoints. Both facial and body keypoints are critical in some medical diagnoses, and keypoints invariability after de-identification is of great importance. Here, we propose a solution using deepfake technology, the face swapping technique. While this swapping method has been criticized for invading privacy and portraiture right, it could conversely protect privacy in medical video: patients' faces could be swapped to a proper target face and become unrecognizable. However, it remained an open question that to what extent the swapping de-identification method could affect the automatic detection of body keypoints. In this study, we apply deepfake technology to Parkinson's disease examination videos to de-identify subjects, and quantitatively show that: face-swapping as a de-identification approach is reliable, and it keeps the keypoints almost invariant, significantly better than traditional methods. This study proposes a pipeline for video de-identification and keypoint preservation, clearing up some ethical restrictions for medical data sharing. This work could make open-source high quality medical video datasets more feasible and promote future medical research that benefits our society.},
  version = {1},
  keywords = {Artificial Intelligence (cs.AI),Computer Vision and Pattern Recognition (cs.CV),FOS: Computer and information sciences}
}

@article{ziewitz2016,
  title = {Governing {{Algorithms}}: {{Myth}}, {{Mess}}, and {{Methods}}},
  shorttitle = {Governing {{Algorithms}}},
  author = {Ziewitz, Malte},
  date = {2016-01},
  journaltitle = {Science, Technology, \& Human Values},
  shortjournal = {Science, Technology, \& Human Values},
  volume = {41},
  number = {1},
  pages = {3--16},
  issn = {0162-2439, 1552-8251},
  doi = {10.1177/0162243915608948},
  url = {https://journals.sagepub.com/doi/10.1177/0162243915608948},
  urldate = {2025-04-04},
  abstract = {Algorithms have developed into somewhat of a modern myth. On the one hand, they have been depicted as powerful entities that rule, sort, govern, shape, or otherwise control our lives. On the other hand, their alleged obscurity and inscrutability make it difficult to understand what exactly is at stake. What sustains their image as powerful yet inscrutable entities? And how to think about the politics and governance of something that is so difficult to grasp? This editorial essay provides a critical backdrop for the special issue, treating algorithms not only as computational artifacts but also as sensitizing devices that can help us rethink some entrenched assumptions about agency, transparency, and normativity.},
  langid = {english},
  keywords = {⏳},
  file = {/Users/sgraf/Zotero/storage/5SPRL99F/ziewitz-2015-governing-algorithms-myth-mess-and-methods.pdf}
}

@legislation{zotero-item-13064,
  title = {Draft {{Delegated Act}}},
  file = {/Users/sgraf/Zotero/storage/CVJJJLJ3/090166e513e46d31.pdf}
}

@article{zotero-item-14407,
  title = {Directive ({{EU}}) 2024/1385 of the {{European Parliament}} and of the {{Council}} of 14 {{May}} 2024 on Combating Violence against Women and Domestic Violence},
  langid = {english},
  file = {/Users/sgraf/Zotero/storage/T3ILBCDU/Directive (EU) 20241385 of the European Parliament and of the Council of 14 May 2024 on combating v.pdf}
}

@article{zuboff2015,
  title = {Big Other: Surveillance Capitalism and the Prospects of an Information Civilization},
  shorttitle = {Big Other},
  author = {Zuboff, Shoshana},
  date = {2015-03},
  journaltitle = {Journal of Information Technology},
  shortjournal = {Journal of Information Technology},
  volume = {30},
  number = {1},
  pages = {75--89},
  issn = {0268-3962, 1466-4437},
  doi = {10.1057/jit.2015.5},
  url = {https://journals.sagepub.com/doi/10.1057/jit.2015.5},
  urldate = {2025-10-17},
  abstract = {This article describes an emergent logic of accumulation in the networked sphere, ‘surveillance capitalism,’ and considers its implications for ‘information civilization.’ The institutionalizing practices and operational assumptions of Google Inc. are the primary lens for this analysis as they are rendered in two recent articles authored by Google Chief Economist Hal Varian. Varian asserts four uses that follow from computer-mediated transactions: data extraction and analysis,’ ‘new contractual forms due to better monitoring,’ ‘personalization and customization, ’ and continuous experiments. ’ An examination of the nature and consequences of these uses sheds light on the implicit logic of surveillance capitalism and the global architecture of computer mediation upon which it depends. This architecture produces a distributed and largely uncontested new expression of power that I christen: Big Other. ’ It is constituted by unexpected and often illegible mechanisms of extraction, commodification, and control that effectively exile persons from their own behavior while producing new markets of behavioral prediction and modification. Surveillance capitalism challenges democratic norms and departs in key ways from the centuries-long evolution of market capitalism.},
  langid = {english},
  file = {/Users/sgraf/Zotero/storage/VH5BHGPZ/Zuboff_2015_Big other surveillance capitalism and the prospects of an information civilization.pdf}
}
