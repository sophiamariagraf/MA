@book{2015,
  title = {{{eGirls}}, {{eCitizens Putting Technology}}, {{Theory}} and {{Policy}} into {{Dialogue}} with {{Girls}}’ and {{Young Women}}’s {{Voices}}},
  date = {2015},
  publisher = {University of Ottawa Press},
  doi = {10.1353/book.40672},
  url = {https://muse.jhu.edu/book/40672},
  urldate = {2024-09-09},
  isbn = {978-0-7766-2259-0},
  langid = {english},
  keywords = {⏳},
  file = {/Users/sgraf/Zotero/storage/HECJ8CLN/2015 - eGirls, eCitizens Putting Technology, Theory and P.pdf}
}

@report{ajder2019,
  title = {The {{State}} of {{Deepfakes}}: {{Landscape}}, {{Threats}}, and {{Impact}}},
  author = {Ajder, Henry and Patrini, Giorgio and Cavalli, Francesco and Cullen, Laurence},
  date = {2019-09},
  institution = {Deeptrace},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/4Q9B5MZ3/Ajder et al._2019_The State of Deepfakes Landscape, Threats, and Impact.pdf}
}

@article{alilunas2024,
  title = {What We Must Be: {{AI}} and the Future of Porn Studies},
  shorttitle = {What We Must Be},
  author = {Alilunas, Peter},
  date = {2024-01-02},
  journaltitle = {Porn Studies},
  shortjournal = {Porn Studies},
  volume = {11},
  number = {1},
  pages = {99--112},
  issn = {2326-8743, 2326-8751},
  doi = {10.1080/23268743.2024.2312181},
  url = {https://www.tandfonline.com/doi/full/10.1080/23268743.2024.2312181},
  urldate = {2025-06-05},
  langid = {english}
}

@article{anciaux2025,
  title = {Imagining Markets and Crafting Value: The Emergence of an {{AI-generated}} Pornographic Content Ecosystem},
  shorttitle = {Imagining Markets and Crafting Value},
  author = {Anciaux, Arnaud and Gramaccia, Julie A.},
  date = {2025-05-15},
  journaltitle = {Porn Studies},
  shortjournal = {Porn Studies},
  pages = {1--16},
  issn = {2326-8743, 2326-8751},
  doi = {10.1080/23268743.2025.2492332},
  url = {https://www.tandfonline.com/doi/full/10.1080/23268743.2025.2492332},
  urldate = {2025-06-03},
  langid = {english}
}

@article{atlam2025,
  title = {{{SLM-DFS}}: {{A}} Systematic Literature Map of Deepfake Spread on Social Media},
  shorttitle = {{{SLM-DFS}}},
  author = {Atlam, El-Sayed and Almaliki, Malik and Elmarhomy, Ghada and Almars, Abdulqader M. and Elsiddieg, Awatif M.A. and ElAgamy, Rasha},
  date = {2025-01},
  journaltitle = {Alexandria Engineering Journal},
  volume = {111},
  pages = {446--455},
  publisher = {Elsevier BV},
  issn = {1110-0168},
  doi = {10.1016/j.aej.2024.10.076},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1110016824012420},
  urldate = {2025-07-23},
  langid = {english},
  file = {/Users/sgraf/Zotero/storage/M65CUD5D/Atlam et al._2025_SLM-DFS A systematic literature map of deepfake spread on social media.pdf}
}

@book{atteveldt2022,
  title = {Computational Analysis of Communication: A Practical Introduction to the Analysis of Texts, Networks, and Images with Code Examples in {{Python}} and {{R}}},
  shorttitle = {Computational Analysis of Communication},
  author = {family=Atteveldt, given=Wouter, prefix=van, useprefix=false and Trilling, Damian and Arcíla Calderón, Carlos},
  date = {2022},
  publisher = {Wiley Blackwell},
  location = {Hoboken, USA Sussex, UK},
  url = {https://v2.cssbook.net},
  abstract = {"The use of computers is nothing new in the social sciences. In fact, one could argue that some disciplines within the social sciences have even be early adopters of computational approaches. Take the gathering and analyzing of large-scale survey data, dating back until the use of the Hollerith Machine in the 1890 US census. Long before every scholar had a personal computer on their desk, social scientists were using punch cards and mainframe computers to deal with such data. If we think of the analysis of communication more specifically, we see attempts to automate content analysis already in the 1960's [see, e.g. Scharkow, 2017]. Yet, something has profoundly changed in the last decades. The amount and kind of data we can collect as well as the computational power we have access to have increased dramatically. In particular, digital traces that we leave when communicating online, from access logs to comments we place, have required new approaches [e.g., Trilling, 2017]. At the same time, better computational facilities now allow us to ask questions we could not answer before"--},
  isbn = {978-1-119-68023-9},
  langid = {english},
  pagetotal = {314},
  keywords = {⏳},
  file = {/Users/sgraf/Zotero/storage/UYHB8AEA/Atteveldt et al._2022_Computational analysis of communication a practical introduction to the analysis of texts, networks.pdf}
}

@online{aylo2023,
  title = {Brands},
  author = {{Aylo}},
  date = {2023},
  url = {https://aylo.com/brands/},
  urldate = {2025-08-12},
  organization = {aylo.com},
  keywords = {✅}
}

@online{aylofreesitesltd,
  title = {Core values},
  author = {{Aylo Freesites Ltd}},
  url = {https://help.pornhub.com/hc/en-us/articles/4419871944723-Core-Values},
  urldate = {2025-08-12},
  langid = {1},
  organization = {help.pornhub.com},
  keywords = {✅}
}

@report{aylofreesitesltd2024,
  title = {{{EU DSA Transparency Report}} - {{August}} 2024},
  author = {{Aylo Freesites Ltd}},
  date = {2024-08-30},
  url = {https://help.pornhub.com/hc/en-us/articles/32596021061267-EU-DSA-Transparency-Report-August-2024},
  keywords = {✅}
}

@report{aylofreesitesltd2025,
  title = {Report on the Results of the Risk  Assessment for {{Pornhub}}.Com Pursuant  to {{Article}} 34 of the {{Digital Services Act}}},
  author = {{Aylo Freesites Ltd}},
  date = {2025-04},
  pages = {75},
  institution = {Aylo Freesites Limited},
  url = {https://ei.phncdn.com/static/misc/legal/Risk_Assessment_for_Pornhub_April_2025_1752958273.pdf},
  urldate = {2025-08-10},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/6Y5MB4XY/Risk_Assessment_for_Pornhub_April_2025_1752958273-2.pdf}
}

@article{aylofreesitesltd2025a,
  title = {Audit {{Implementation Report}} for {{Pornhub}}.Com Pursuant to {{Article}} 37 of the {{Digital Services Act}}},
  author = {{Aylo Freesites Ltd}},
  date = {2025-05},
  url = {https://ei.phncdn.com/static/misc/legal/Audit_Implementation_Report_for_Pornhub_May_2025_1752958259.pdf},
  langid = {english},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/2BC45FLJ/Ltd_Audit Implementation Report for Pornhub.com pursuant to Article 37 of the Digital Services Act.pdf}
}

@online{aylofreesitesltd2025b,
  title = {{{EU Digital Services Act}}},
  author = {{Aylo Freesites Ltd}},
  date = {2025-07-01},
  url = {https://www.pornhub.com/information/eu_dsa},
  urldate = {2025-08-12},
  organization = {pornhub.com},
  keywords = {✅}
}

@online{aylofreesitesltd2025c,
  title = {Premium Sign-Up},
  author = {{Aylo Freesites Ltd}},
  date = {2025},
  url = {https://pornhubpremium.com},
  organization = {pornhubpremium.com},
  keywords = {✅}
}

@online{aylofreesitesltd2025d,
  title = {Terms {{Of Service}}},
  author = {{Aylo Freesites Ltd}},
  date = {2025-06-30},
  url = {https://www.pornhub.com/information/terms},
  urldate = {2025-08-06},
  organization = {pornhub.com},
  keywords = {✅}
}

@report{aylofreesitesltd2025e,
  title = {{{DSA Transparency}} Report – {{February}} 2025},
  author = {{Aylo Freesites Ltd}},
  year = {28 February 2025, updated 21 March 2025},
  url = {https://help.pornhub.com/hc/en-us/articles/38929180749587-DSA-Transparency-report-February-2025},
  keywords = {✅}
}

@inproceedings{batra2025,
  title = {{{SocialDF}}: {{Benchmark Dataset}} and {{Detection Model}} for {{Mitigating Harmful Deepfake Content}} on {{Social Media Platforms}}},
  shorttitle = {{{SocialDF}}},
  booktitle = {Proceedings of the 4th {{ACM International Workshop}} on {{Multimedia AI}} against {{Disinformation}}},
  author = {Batra, Arnesh and Khemani, Jashn and Gumber, Arush and Kumar, Anushk and Jain, Arhan and Gupta, Somil},
  date = {2025-06-30},
  pages = {81--89},
  publisher = {ACM},
  location = {Chicago USA},
  doi = {10.1145/3733567.3735573},
  url = {https://dl.acm.org/doi/10.1145/3733567.3735573},
  urldate = {2025-07-23},
  eventtitle = {{{MAD}}'25: 4th {{ACM International Workshop}} on {{Multimedia AI}} against {{Disinformation}}}
}

@article{birrer2024,
  title = {What We Know and Don’t Know about Deepfakes: {{An}} Investigation into the State of the Research and Regulatory Landscape},
  shorttitle = {What We Know and Don’t Know about Deepfakes},
  author = {Birrer, Alena and Just, Natascha},
  date = {2024-05-22},
  journaltitle = {New Media \& Society},
  shortjournal = {New Media \& Society},
  pages = {14614448241253138},
  issn = {1461-4448, 1461-7315},
  doi = {10.1177/14614448241253138},
  url = {https://journals.sagepub.com/doi/10.1177/14614448241253138},
  urldate = {2025-06-04},
  abstract = {The emergence of deepfakes has raised concerns among researchers, policymakers, and the public. However, many of these concerns stem from alarmism rather than well-founded evidence. This article provides an overview of what is currently known about deepfakes based on a systematic review of empirical research. It also examines and critically assesses regulatory responses globally through qualitative content analysis of policy and legal documents. The findings highlight gaps in our knowledge of deepfakes, making it difficult to assess the appropriateness and need for regulatory action. While deepfake technology may not introduce entirely new and unique regulatory problems at present, it can amplify existing problems such as the spread of non-consensual pornography and disinformation. Effective oversight and enforcement of existing rules, along with careful consideration of required adjustments will therefore be crucial. Altogether, this underscores the importance of more empirical research into the evolving challenges posed by deepfakes and calls for adaptive policy approaches.},
  langid = {english},
  keywords = {⏳},
  file = {/Users/sgraf/Zotero/storage/3I5CELYF/Birrer und Just_2024_What we know and don’t know about deepfakes An investigation into the state of the research and reg.pdf}
}

@incollection{brownsword2025,
  title = {Generative {{AI}} and the {{Rule}} of {{Law}}},
  booktitle = {The {{Oxford Handbook}} of the {{Foundations}} and {{Regulation}} of {{Generative AI}}},
  author = {Brownsword, Roger},
  editor = {Hacker, Philipp and Mittelstadt, Brent and Hammer, Sarah and Engel, Andreas},
  date = {2025-04-22},
  edition = {1},
  publisher = {Oxford University Press},
  doi = {10.1093/oxfordhb/9780198940272.013.0013},
  url = {https://academic.oup.com/edited-volume/59908/chapter/512459946},
  urldate = {2025-05-20},
  abstract = {Abstract             This chapter explores the application of the Rule of Law to generative AI. It is in the nature of a prolegomenon to debates about the particular rules and principles that should be adopted for the governance of this latest technology. The preliminary issues addressed relate to what the Rule of Law says about private governance, about exemptions for emergency or exceptional states, about how explicit and bespoke governance should be, about participatory and inclusive governance, about substantive constraints, and about universal values (and existential threats). Contrasting the Rule of Law with an ideal of ‘good governance’, the chapter suggests that the right question is not so much whether there are publicly declared rules about the lawful application of generative AI but whether the regulation of generative AI is in line with the ideals of good governance.},
  isbn = {978-0-19-894027-2 978-0-19-894030-2},
  langid = {english},
  keywords = {⏳},
  file = {/Users/sgraf/Zotero/storage/9AWP7GJH/Brownsword_2025_Generative AI and the Rule of Law.pdf}
}

@report{bundeskriminalamtbka2024,
  title = {Bundeslagebilder - {{Geschlechtsspezifisch}} Gegen {{Frauen}} Gerichtete {{Straftaten}} 2023},
  author = {{Bundeskriminalamt (BKA)}},
  date = {2024-11-19},
  institution = {Bundeskriminalamt (BKA)},
  file = {/Users/sgraf/Zotero/storage/8L564ZI4/Bundeskriminalamt (BKA)_2024_Bundeslagebilder - Geschlechtsspezifisch gegen Frauen gerichtete Straftaten 2023.pdf}
}

@book{burgess2019,
  title = {The {{SAGE}} Handbook of Social Media},
  editor = {Burgess, Jean and Marwick, Alice E. and Poell, Thomas},
  date = {2019},
  edition = {Paperback edition},
  publisher = {Sage reference},
  location = {Los Angeles London New Delhi Singapore Washington DC Melbourne},
  isbn = {978-1-4129-6229-2 978-1-5264-8687-5},
  langid = {english},
  pagetotal = {639},
  keywords = {⏳,❌},
  file = {/Users/sgraf/Zotero/storage/H7SRV65D/Burgess et al._2019_The SAGE handbook of social media.pdf}
}

@article{burgess2020,
  entrysubtype = {nonacademic},
  title = {Porn Sites Still Won’t Take down Nonconsensual Deepfakes},
  author = {Burgess, Matt},
  date = {2020-08-30},
  journaltitle = {Wired.com},
  url = {https://www.wired.com/story/porn-sites-still-wont-take-down-non-consensual-deepfakes/},
  keywords = {⏳,✅},
  file = {/Users/sgraf/Zotero/storage/DUZ6SMNA/Burgess_2020_Porn sites still won’t take down nonconsensual deepfakes.pdf}
}

@article{butler2025,
  title = {Sex Worker Human Digital Twins and Intellectual Property: On Collaborative Futures for Sex Thinkers, Technologists, and Lawyers},
  shorttitle = {Sex Worker Human Digital Twins and Intellectual Property},
  author = {Butler, Yvette and Egwuatu, Chibundo and Canham, Matthew and Sawyer, Ben D.},
  date = {2025-04-23},
  journaltitle = {Porn Studies},
  shortjournal = {Porn Studies},
  pages = {1--16},
  issn = {2326-8743, 2326-8751},
  doi = {10.1080/23268743.2025.2466612},
  url = {https://www.tandfonline.com/doi/full/10.1080/23268743.2025.2466612},
  urldate = {2025-06-05},
  langid = {english}
}

@online{casas2025,
  title = {Academic {{Access}} to {{Social Media Data}} for the {{Study}} of {{Political Online Safety}}},
  author = {Casas, Andreu and Dagher, Georgia and O'Loughlin, Ben},
  date = {2025-01-16},
  doi = {10.31235/osf.io/7pcjd},
  url = {https://osf.io/7pcjd},
  urldate = {2025-03-10},
  abstract = {In this report we provide an overview of the kinds of data academics need in order to conduct independent research into political online safety matters on social media platforms, and the challenges they currently face. Additionally, we put forward ideas regarding novel governance structures that would enable high-quality independent research, while protecting users’ rights and data privacy, in the United Kingdom.},
  pubstate = {prepublished},
  keywords = {⏳,❌}
}

@article{celarier2021,
  entrysubtype = {nonacademic},
  title = {Bill {{Ackman}} Sent a Text to the {{CEO}} of {{Mastercard}}. {{What}} Happened next Is a Parable for {{ESG}}.},
  author = {Celarier, Michelle},
  date = {2021-06-16},
  journaltitle = {institutionalinvestor.com},
  url = {https://www.institutionalinvestor.com/article/2bswuu1nfc040ho7ghudc/culture/bill-ackman-sent-a-text-to-the-ceo-of-mastercard-what-happened-next-is-a-parable-for-esg}
}

@report{codingrights2017,
  title = {Online {{Gender-Based Violence}}: Diagnosis, Solutions and Challenges. {{Joint}} Contribution from {{Brazil}} to the {{UN}} Special Rapporteur on Violence against Women},
  author = {{Coding Rights} and {InternetLab}},
  date = {2017},
  location = {São Paulo},
  url = {http://www.internetlab.org.br/wp-content/uploads/2017/11/Relatorio_ ViolenciaGenero_ONU.pdf},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/5CWME3IR/Coding Rights und InternetLab_2017_Online Gender-Based Violence diagnosis, solutions and challenges. Joint contribution from Brazil to.pdf}
}

@article{cole2018,
  entrysubtype = {nonacademic},
  title = {Pornhub Is Banning {{AI-generated}} Fake Porn Videos, Says They’re Nonconsensual},
  author = {Cole, Samantha},
  date = {2018-02-06},
  journaltitle = {Vice.com},
  url = {https://www.vice.com/en/article/pornhub-bans-deepfakes/},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/3958I3LV/Cole_2018_Pornhub is banning AI-generated fake porn videos, says they’re nonconsensual.pdf}
}

@article{cole2020,
  entrysubtype = {nonacademic},
  title = {The Ugly Truth behind {{Pornhub}}’s ‘{{Year In Review}}’},
  author = {Cole, Samantha},
  date = {2020-02-18},
  journaltitle = {Vice.com},
  url = {https://www.vice.com/en/article/pornhub-year-in-review-deepfake/},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/MEPQYYIT/Cole_2020_The ugly truth behind Pornhub’s ‘Year In Review’.pdf}
}

@article{cole2020a,
  entrysubtype = {nonacademic},
  title = {‘{{War}} against Sex Workers:’ {{What Visa}} and {{Mastercard}} Dropping {{Pornhub}} Means to Performers},
  author = {Cole, Samantha},
  date = {2020-12-11},
  journaltitle = {Vice.com},
  url = {https://www.vice.com/en/article/sex-workers-what-visa-and-mastercard-dropping-pornhub-means-to-performers/}
}

@video{compton2023,
  type = {Dokumentation},
  entrysubtype = {film},
  title = {Alptraum {{Deepfake-Pornos}}},
  editor = {Compton, Sophie and Reuben, Hamlyn},
  editortype = {director},
  namea = {{arte/ ZDF}},
  nameatype = {collaborator},
  date = {2023},
  url = {https://www.arte.tv/de/videos/119514-000-A/alptraum-deepfake-pornos/},
  urldate = {2024-11-15},
  abstract = {Eine junge Frau findet heraus, dass von ihr auf Pornoseiten Deepfakes kursieren. Mittels einer KI wurde ihr Gesicht auf Pornovideos kopiert – mit Klarnamen und Adresse. Die junge Frau macht sich auf die Suche nach dem Urheber dieser Videos, sie trifft dabei auf andere junge Frauen, die dasselbe erlebt haben, und erfährt, wie leicht es ist, mit KI solche Fakes zu produzieren. Die 23-jährige Studentin Taylor Klein stößt eines Tages im Internet auf gefakte Pornovideos von sich selbst. Jemand hat mittels KI ihr Gesicht auf Pornovideos kopiert. Die Dokumentation beschreibt die schmerzhafte und emotionale Suche der jungen Frau nach dem Urheber dieser gefakten Videos, die jemand auf einschlägigen Pornoseiten hochgeladen hat. Die Videos sind zwar gefälscht, aber ihr Gesicht, ihr Name, ihre Adresse wurden vom Verursacher angegeben und sind es nicht. Taylor trifft andere junge Frauen, die ebenfalls Opfer von Deepfakes wurden. Die Zahl der im Netz kursierenden Deepfake-Pornos wächst rasant. Frauen sind in 99 Prozent der Fälle die Opfer. Ob das Video echt ist oder ein Fake, lässt sich im Nachhinein kaum erkennen, so lebensecht wirken die KI-generierten Videos. Der psychische, emotionale und soziale Schaden für die betroffenen Frauen ist immens. Die Dokumentation zeigt eindrücklich, wie leicht es ist, diese Deepfakes herzustellen – inzwischen ist die KI so weit ausgereift, dass ein einziges hochaufgelöstes Foto ausreicht, um ein Video von 60 Sekunden herzustellen. Der Film zeigt auch, wie hilflos die Rechtsprechung derzeit noch ist, wenn es um die Bestrafung eines solchen Missbrauchs geht und dass den jungen Frauen oftmals nur der Rückzug aus der digitalen Welt übrigbleibt.},
  keywords = {⏳}
}

@article{datta2025,
  entrysubtype = {nonacademic},
  title = {Porn Platforms Report {{EU}} User Collapse, May Dodge {{DSA}} Scrutiny},
  author = {Datta, Anupriya},
  date = {2025-02-18},
  journaltitle = {euractiv.com},
  url = {https://www.euractiv.com/section/tech/news/porn-platforms-report-a-major-drop-in-eu-users-to-evade-dsa-responsibility/?_ga=2.226876890.69505057.1740046886-1334932735.1740046886},
  urldate = {2025-03-21},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/ZEVC5I34/Datta_2025_Porn platforms report EU user collapse, may dodge DSA scrutiny.pdf}
}

@article{denardis2015,
  title = {Internet Governance by Social Media Platforms},
  author = {DeNardis, L. and Hackl, A.M.},
  date = {2015-10},
  journaltitle = {Telecommunications Policy},
  shortjournal = {Telecommunications Policy},
  volume = {39},
  number = {9},
  pages = {761--770},
  issn = {03085961},
  doi = {10.1016/j.telpol.2015.04.003},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0308596115000592},
  urldate = {2025-03-05},
  langid = {english},
  keywords = {⏳,❌}
}

@report{deutscherjuristinnenbunde.v.2023,
  type = {Policy Paper},
  title = {Bekämpfung Bildbasierter Sexualisierter {{Gewalt}}},
  author = {{Deutscher Juristinnenbund e.V.}},
  date = {2023-06-07},
  url = {https://www.djb.de/fileadmin/user_upload/presse/stellungnahmen/st23-17_Bildbasierte_Gewalt.pdf},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/P2FJVPFQ/Deutscher Juristinnenbund e.V. - 2023 - Bekämpfung bildbasierter sexualisierter Gewalt.pdf}
}

@inproceedings{ding2025,
  title = {The {{Malicious Technical Ecosystem}}: {{Exposing Limitations}} in {{Technical Governance}} of {{AI-Generated Non-Consensual Intimate Images}} of {{Adults}}},
  shorttitle = {The {{Malicious Technical Ecosystem}}},
  author = {Ding, Michelle L. and Suresh, Harini},
  date = {2025},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.2504.17663},
  url = {https://arxiv.org/abs/2504.17663},
  urldate = {2025-07-08},
  abstract = {In this paper, we adopt a survivor-centered approach to locate and dissect the role of sociotechnical AI governance in preventing AI-Generated Non-Consensual Intimate Images (AIG-NCII) of adults, colloquially known as "deep fake pornography." We identify a "malicious technical ecosystem" or "MTE," comprising of open-source face-swapping models and nearly 200 "nudifying" software programs that allow non-technical users to create AIG-NCII within minutes. Then, using the National Institute of Standards and Technology (NIST) AI 100-4 report as a reflection of current synthetic content governance methods, we show how the current landscape of practices fails to effectively regulate the MTE for adult AIG-NCII, as well as flawed assumptions explaining these gaps.},
  version = {1},
  keywords = {✅,Artificial Intelligence (cs.AI),Computers and Society (cs.CY),FOS: Computer and information sciences,Human-Computer Interaction (cs.HC),Machine Learning (cs.LG)},
  file = {/Users/sgraf/Zotero/storage/4NKQA238/Ding und Suresh_2025_The Malicious Technical Ecosystem Exposing Limitations in Technical Governance of AI-Generated Non-.pdf}
}

@article{dvoskin2024,
  title = {Speaking {{Back}} to {{Sexual Privacy Invasions}}},
  author = {Dvoskin, Brenda},
  date = {2024},
  journaltitle = {Washington Law Review},
  volume = {99},
  number = {1},
  pages = {59--106},
  url = {https://digitalcommons.law.uw.edu/cgi/viewcontent.cgi?article=5301&context=wlr},
  keywords = {⏳},
  file = {/Users/sgraf/Zotero/storage/ISYQQAW3/Dvoskin_2024_Speaking Back to Sexual Privacy Invasions.pdf}
}

@report{europeancommission,
  title = {Digital {{Services Terms}} and {{Conditions Database}} –~{{User}} Guide},
  author = {{European Commission}},
  file = {/Users/sgraf/Zotero/storage/43URZ4XE/European Commission_Digital Services Terms and Conditions Database – User guide.pdf}
}

@report{europeancommission2023a,
  type = {Press release},
  title = {Commission Designates Second Set of {{Very Large Online Platforms}} under the {{Digital Services Act}}},
  author = {{European Commission}},
  date = {2023-12-20},
  location = {Brussels},
  url = {https://ec.europa.eu/commission/presscorner/api/files/document/print/en/ip_23_6763/IP_23_6763_EN.pdf},
  file = {/Users/sgraf/Zotero/storage/VSZ5I6YJ/European Commission_2023_Commission designates second set of Very Large Online Platforms under the Digital Services Act.pdf}
}

@report{europeancommission2024b,
  type = {Press release},
  title = {Commission Designates Adult Content Platform {{XNXX}} as {{Very Large Online Platform}} under the {{Digital Services Act}}},
  author = {{European Commission}},
  date = {2024-07-10},
  location = {Brussels},
  url = {https://ec.europa.eu/commission/presscorner/api/files/document/print/en/ip_24_3723/IP_24_3723_EN.pdf},
  file = {/Users/sgraf/Zotero/storage/Q3VW8TX6/European Commission_2024_Commission designates adult content platform XNXX as Very Large Online Platform under the Digital Se.pdf}
}

@legislation{europeancommissionb,
  title = {{{REGULATION}} ({{EU}}) 2024/1689 {{OF THE EUROPEAN PARLIAMENT AND OF THE COUNCIL}}  of 13 {{June}} 2024  Laying down Harmonised Rules on Artificial Intelligence and Amending {{Regulations}} ({{EC}}) {{No}} 300/2008, ({{EU}}) {{No}} 167/2013, ({{EU}}) {{No}} 168/2013, ({{EU}}) 2018/858, ({{EU}}) 2018/1139 and ({{EU}}) 2019/2144 and {{Directives}} 2014/90/{{EU}}, ({{EU}}) 2016/797 and ({{EU}}) 2020/1828 ({{Artificial Intelligence Act}})},
  author = {{European Commission}},
  file = {/Users/sgraf/Zotero/storage/FJUT8NJR/OJ%3AL_202401689%3AEN%3ATXT.pdf}
}

@legislation{europeancommissionc,
  title = {{{REGULATION}} ({{EU}}) 2022/2065 {{OF THE EUROPEAN PARLIAMENT AND OF THE COUNCIL}}  of 19 {{October}} 2022  on a {{Single Market For Digital Services}} and Amending {{Directive}} 2000/31/{{EC}} ({{Digital Services Act}})},
  author = {{European Commission}},
  url = {http://data.europa.eu/eli/reg/2022/2065/oj},
  file = {/Users/sgraf/Zotero/storage/86AHYCMS/Regulation (EU) 20222065 of the European Parliame.pdf;/Users/sgraf/Zotero/storage/TI4ISGAX/CELEX%3A32022R2065%3ADE%3ATXT-2.pdf}
}

@article{falduti2023,
  title = {Mapping the {{Interdisciplinary Research}} on {{Non-consensual Pornography}}: {{Technical}} and {{Quantitative Perspectives}}},
  shorttitle = {Mapping the {{Interdisciplinary Research}} on {{Non-consensual Pornography}}},
  author = {Falduti, Mattia and Tessaris, Sergio},
  date = {2023-09-30},
  journaltitle = {Digital Threats: Research and Practice},
  shortjournal = {Digital Threats},
  volume = {4},
  number = {3},
  pages = {1--22},
  issn = {2692-1626, 2576-5337},
  doi = {10.1145/3608483},
  url = {https://dl.acm.org/doi/10.1145/3608483},
  urldate = {2025-06-03},
  abstract = {The phenomenon of the non-consensual distribution of intimate or sexually explicit digital images of adults, a.k.a. non-consensual pornography (NCP) or revenge pornography, is under the spotlight for the toll it is taking on society. Law enforcement statistics confirm a dramatic global rise in abuses. For this reason, the research community is investigating different strategies to fight and mitigate the abuses and their effects. Since the phenomenon involves different aspects of personal and social interaction among users of social media and content sharing platforms, in the literature it is addressed under different academic disciplines. However, while most of the literature reviews focus on non-consensual pornography either from a social science or psychological perspective, to the best of our knowledge a systematic review of the research on the technical aspects of the problem is still missing. In this work, we present a Systematic Mapping Study (SMS) of the literature, looking at this interdisciplinary phenomenon through a technical lens. Therefore, we focus on the cyber side of the crime of non-consensual pornography with the aim of describing the state-of-the-art and the future lines of research from a technical and quantitative perspective.},
  langid = {english},
  keywords = {⏳},
  file = {/Users/sgraf/Zotero/storage/QTXNWAB6/Falduti und Tessaris_2023_Mapping the Interdisciplinary Research on Non-consensual Pornography Technical and Quantitative Per.pdf}
}

@article{fisher2024,
  title = {Moderating {{Synthetic Content}}: The {{Challenge}} of {{Generative AI}}},
  shorttitle = {Moderating {{Synthetic Content}}},
  author = {Fisher, Sarah A. and Howard, Jeffrey W. and Kira, Beatriz},
  date = {2024-12},
  journaltitle = {Philosophy \& Technology},
  shortjournal = {Philos. Technol.},
  volume = {37},
  number = {4},
  pages = {133},
  issn = {2210-5433, 2210-5441},
  doi = {10.1007/s13347-024-00818-9},
  url = {https://link.springer.com/10.1007/s13347-024-00818-9},
  urldate = {2025-06-03},
  abstract = {Abstract             Artificially generated content threatens to seriously disrupt the public sphere. Generative AI massively facilitates the production of convincing portrayals of fabricated events. We have already begun to witness the spread of synthetic misinformation, political propaganda, and non-consensual intimate deepfakes. Malicious uses of the new technologies can only be expected to proliferate over time. In the face of this threat, social media platforms must surely act. But how? While it is tempting to think they need new sui generis policies targeting synthetic content, we argue that the challenge posed by generative AI should be met through the enforcement of general platform rules. We demonstrate that the threat posed to individuals and society by AI-generated content is no different in kind from that of ordinary harmful content—a threat which is already well recognised. Generative AI massively increases the problem but, ultimately, it requires the same approach. Therefore, platforms do best to double down on improving and enforcing their existing rules, regardless of whether the content they are dealing with was produced by humans or machines.},
  langid = {english},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/NMSHSR2X/Fisher et al._2024_Moderating Synthetic Content the Challenge of Generative AI.pdf}
}

@inbook{flynn2019,
  title = {Image-{{Based Sexual Abuse}}},
  booktitle = {Oxford {{Research Encyclopedia}} of {{Criminology}} and {{Criminal Justice}}},
  author = {Flynn, Asher},
  date = {2019-03-26},
  publisher = {Oxford University Press},
  doi = {10.1093/acrefore/9780190264079.013.534},
  url = {https://oxfordre.com/criminology/view/10.1093/acrefore/9780190264079.001.0001/acrefore-9780190264079-e-534},
  urldate = {2024-09-19},
  abstract = {Image-based sexual abuse (IBSA) is a form of technology-facilitated sexual violence. The term describes a pattern of behaviors involving the nonconsensual creation, distribution, and/or threats to distribute, nude or sexual images. Also known as “revenge pornography” or “nonconsensual pornography,” IBSA affects a significant proportion of the population. A study conducted by Powell, Scott, Flynn, and McCook of IBSA across Australia, the United Kingdom, and New Zealand found that one in six individuals aged between 16 and 64 years have experienced at least one form of IBSA victimization, and one in six individuals have engaged in at least one form of IBSA perpetration.             Perpetrators of IBSA can include intimate partners, family members, friends, acquaintances, and persons unknown to the victim, with diverse motivations, including sexual gratification, retribution, coercive control, social notoriety, monetary gain, and voyeurism. The images themselves may be self-created by the victim as a “selfie” or produced consensually in the context of a relationship. Alternatively, images may be digitally altered, taken surreptitiously in public or private settings, or created coercively, or they may have been taken of a sexual assault or rape. While IBSA is not itself new, technology has created a conducive and large-scale platform for such abuse to occur.},
  bookauthor = {Flynn, Asher},
  isbn = {978-0-19-026407-9},
  langid = {english},
  keywords = {⏳}
}

@article{flynn2022,
  title = {Deepfakes and {{Digitally Altered Imagery Abuse}}: {{A Cross-Country Exploration}} of an {{Emerging}} Form of {{Image-Based Sexual Abuse}}},
  shorttitle = {Deepfakes and {{Digitally Altered Imagery Abuse}}},
  author = {Flynn, Asher and Powell, Anastasia and Scott, Adrian J and Cama, Elena},
  date = {2022-10-13},
  journaltitle = {The British Journal of Criminology},
  volume = {62},
  number = {6},
  pages = {1341--1358},
  issn = {0007-0955, 1464-3529},
  doi = {10.1093/bjc/azab111},
  url = {https://academic.oup.com/bjc/article/62/6/1341/6448791},
  urldate = {2025-06-16},
  abstract = {Abstract             Deepfake and digitally altered nude and sexual imagery is a serious and harmful emerging form of image-based sexual abuse (IBSA). This article reports on a multi-methods and cross-country study of IBSA across the United Kingdom, New Zealand and Australia, with a specific focus on the creation, distribution and threat to distribute deepfake and digitally altered imagery. Our findings suggest this abuse involves poly-victimization and poly-perpetration, and is disproportionately experienced and engaged in by those with mobility and/or communication assistance needs, members of the LGB+ community, males, young people and racial minorities (perpetration only). In this article, we discuss the pervasiveness and harms of deepfake and digitally altered imagery abuse, as well as challenges in legal responses, policing and prevention.},
  langid = {english},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/NDERYADD/Flynn et al._2022_Deepfakes and Digitally Altered Imagery Abuse A Cross-Country Exploration of an Emerging form of Im.pdf}
}

@online{förster2025,
  title = {A {{Multi-Level Strategy}} for {{Deepfake Content Moderation}} under {{EU Regulation}}},
  author = {Förster, Max-Paul and Deck, Luca and Weidlich, Raimund and Kühl, Niklas},
  date = {2025},
  doi = {10.48550/ARXIV.2507.08879},
  url = {https://arxiv.org/abs/2507.08879},
  urldate = {2025-07-23},
  abstract = {The growing availability and use of deepfake technologies increases risks for democratic societies, e.g., for political communication on online platforms. The EU has responded with transparency obligations for providers and deployers of Artificial Intelligence (AI) systems and online platforms. This includes marking deepfakes during generation and labeling deepfakes when they are shared. However, the lack of industry and enforcement standards poses an ongoing challenge. Through a multivocal literature review, we summarize methods for marking, detecting, and labeling deepfakes and assess their effectiveness under EU regulation. Our results indicate that individual methods fail to meet regulatory and practical requirements. Therefore, we propose a multi-level strategy combining the strengths of existing methods. To account for the masses of content on online platforms, our multi-level strategy provides scalability and practicality via a simple scoring mechanism. At the same time, it is agnostic to types of deepfake technology and allows for context-specific risk weighting.},
  pubstate = {prepublished},
  version = {1},
  keywords = {✅,Artificial Intelligence (cs.AI),Computers and Society (cs.CY),FOS: Computer and information sciences},
  file = {/Users/sgraf/Zotero/storage/52BG8K2D/Förster et al._2025_A Multi-Level Strategy for Deepfake Content Moderation under EU Regulation.pdf}
}

@article{franco2024,
  title = {“{{Controlling}} the Keys to the {{Golden City}}”: {{The}} Payment Ecosystem and the Regulation of Adult Webcamming and Subscription-Based Fan Platforms},
  shorttitle = {“{{Controlling}} the Keys to the {{Golden City}}”},
  author = {Franco, Rébecca S},
  date = {2024-12-11},
  journaltitle = {New Media \& Society},
  shortjournal = {New Media \& Society},
  pages = {14614448241303465},
  issn = {1461-4448, 1461-7315},
  doi = {10.1177/14614448241303465},
  url = {https://journals.sagepub.com/doi/10.1177/14614448241303465},
  urldate = {2025-06-04},
  abstract = {This article examines the role of payment intermediaries in regulating the platformized adult industry and demonstrates how the adult industry responds to their power and the rules they set. Based on 16 expert interviews, fieldwork at 3 industry conferences, and document analysis of rules, content guidelines, terms, and conditions, the author teases out the intricate interplay between credit card networks, payment processors, and adult platforms. Visa and Mastercard’s rules, enforced by payment processors and implemented by platforms, create a selective, private ordering of permissible content that surpasses legal requirements. This process is impelled by the brand safety and commercial interests of global corporations, without accountability to the industry or consideration for sex workers’ needs. The article calls for the need to hold payment intermediaries as de facto regulators of online sexual commerce and key actors in platform governance accountable toward the industry and workers they impact.},
  langid = {english}
}

@article{frosio2018,
  title = {Why Keep a Dog and Bark Yourself? {{From}} Intermediary Liability to Responsibility},
  shorttitle = {Why Keep a Dog and Bark Yourself?},
  author = {Frosio, Giancarlo F},
  date = {2018-03-01},
  journaltitle = {International Journal of Law and Information Technology},
  volume = {26},
  number = {1},
  pages = {1--33},
  issn = {0967-0769, 1464-3693},
  doi = {10.1093/ijlit/eax021},
  url = {https://academic.oup.com/ijlit/article/26/1/1/4745804},
  urldate = {2025-04-07},
  langid = {english},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/245K7FNL/Frosio_2018_Why keep a dog and bark yourself From intermediary liability to responsibility.pdf}
}

@article{frosio2023,
  title = {Taking Fundamental Rights Seriously in the {{Digital Services Act}}'s Platform Liability Regime},
  author = {Frosio, Giancarlo and Geiger, Christophe},
  date = {2023-01},
  journaltitle = {European Law Journal},
  shortjournal = {European Law Journal},
  volume = {29},
  number = {1--2},
  pages = {31--77},
  issn = {1351-5993, 1468-0386},
  doi = {10.1111/eulj.12475},
  url = {https://onlinelibrary.wiley.com/doi/10.1111/eulj.12475},
  urldate = {2024-09-09},
  abstract = {Abstract             This article highlights how the EU fundamental rights framework should inform the liability regime of platforms foreseen in secondary EU law, in particular with regard to the reform of the E‐commerce directive by the Digital Services Act. In order to identify all possible tensions between the liability regime of platforms on the one hand, and fundamental rights on the other hand, and in order to contribute to a well‐balanced and proportionate European legal instrument, this article addresses these potential conflicts from the standpoint of users (those who share content and those who access it), platforms, regulators and other stakeholders involved. Section 2 delves into the intricate landscape of online intermediary liability, interrogating how the E‐Commerce Directive and the emerging Digital Services Act grapple with the delicate equilibrium between shielding intermediaries and upholding the competing rights of other stakeholders. The article then navigates in Section 3 the fraught terrain of fundamental rights as articulated by the European Court of Human Rights (ECtHR) and the Court of Justice of the European Union (CJEU) under the aegis of the European Convention on Human Rights and the EU Charter. This section poses an urgent inquiry: can the DSA's foundational principles reconcile these legal frameworks in a manner that fuels democracy rather than stifles it through inadvertent censorship? Section 4 then delves into the intricate relationship between fundamental rights and the DSA reform. This section conducts a comprehensive analysis of the key provisions of the DSA, emphasising how they underscore the importance of fundamental rights. In addition to mapping out the strengths of the framework the section also identifies existing limitations within the DSA and suggests potential pathways for further refinement and improvement. This article concludes by outlining key avenues for achieving a balanced and fundamental rights‐compliant regulatory framework for platform liability within the EU.},
  langid = {english},
  keywords = {⏳,unread},
  file = {/Users/sgraf/Zotero/storage/D2V558KY/Frosio und Geiger - 2023 - Taking fundamental rights seriously in the Digital.pdf}
}

@report{fticonsulting2025,
  type = {Audit report},
  title = {Independant Audit {{Article}} 37 of {{Regulation}} ({{EU}}) 2022/2065 ({{Digital Services Act}})},
  author = {{FTI Consulting}},
  date = {2025-04},
  pages = {286},
  url = {https://ei.phncdn.com/static/misc/legal/Audit_Report_for_Pornhub_April_2025_1753199885.pdf},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/S8J58UHH/Audit_Report_for_Pornhub_April_2025_1753199885.pdf}
}

@inproceedings{gamage2022,
  title = {Are {{Deepfakes Concerning}}? {{Analyzing Conversations}} of {{Deepfakes}} on {{Reddit}} and {{Exploring Societal Implications}}},
  shorttitle = {Are {{Deepfakes Concerning}}?},
  booktitle = {{{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Gamage, Dilrukshi and Ghasiya, Piyush and Bonagiri, Vamshi and Whiting, Mark E. and Sasahara, Kazutoshi},
  date = {2022-04-27},
  pages = {1--19},
  publisher = {ACM},
  location = {New Orleans LA USA},
  doi = {10.1145/3491102.3517446},
  url = {https://dl.acm.org/doi/10.1145/3491102.3517446},
  urldate = {2025-07-07},
  eventtitle = {{{CHI}} '22: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-4503-9157-3},
  langid = {english},
  keywords = {⏳},
  file = {/Users/sgraf/Zotero/storage/YQ8ILIB9/Gamage et al._2022_Are Deepfakes Concerning Analyzing Conversations of Deepfakes on Reddit and Exploring Societal Impl.pdf}
}

@article{gillespie,
  title = {Reduction / {{Borderline}} Content / {{Shadowbanning}}},
  author = {Gillespie, Tarleton},
  langid = {english},
  keywords = {⏳},
  file = {/Users/sgraf/Zotero/storage/8YDPQJ4T/Gillespie_Reduction  Borderline content  Shadowbanning.pdf}
}

@book{gillespie2018a,
  title = {Custodians of the {{Internet}}: Platforms, Content Moderation, and the Hidden Decisions That Shape Social Media},
  shorttitle = {Custodians of the {{Internet}}},
  author = {Gillespie, Tarleton},
  date = {2018},
  publisher = {Yale University Press},
  location = {New Haven [Connecticut]},
  abstract = {"Most users want their Twitter feed, Facebook page, and YouTube comments to be free of harassment and porn. Whether faced with 'fake news' or livestreamed violence, 'content moderators'--who censor or promote user-posted content--have never been more important. This is especially true when the tools that social media platforms use to curb trolling, ban hate speech, and censor pornography can also silence the speech you need to hear. [The author] provides an overview of current social media practices and explains the underlying rationales for how, when, and why these policies are enforced. In doing so, [the author] highlights that content moderation receives too little public scrutiny even as it is shapes social norms and creates consequences for public discourse, cultural production, and the fabric of society. Based on interviews with content moderators, creators, and consumers, this ... book is ... for anyone who's ever clicked 'like' or 'retweet.'"},
  isbn = {978-0-300-17313-0 978-0-300-26143-1},
  langid = {english},
  keywords = {⏳,❌}
}

@article{gillespie2020,
  title = {Content Moderation, {{AI}}, and the Question of Scale},
  author = {Gillespie, Tarleton},
  date = {2020-07},
  journaltitle = {Big Data \& Society},
  shortjournal = {Big Data \& Society},
  volume = {7},
  number = {2},
  pages = {2053951720943234},
  issn = {2053-9517, 2053-9517},
  doi = {10.1177/2053951720943234},
  url = {https://journals.sagepub.com/doi/10.1177/2053951720943234},
  urldate = {2025-06-04},
  abstract = {AI seems like the perfect response to the growing challenges of content moderation on social media platforms: the immense scale of the data, the relentlessness of the violations, and the need for human judgments without wanting humans to have to make them. The push toward automated content moderation is often justified as a necessary response to the scale: the enormity of social media platforms like Facebook and YouTube stands as the reason why AI approaches are desirable, even inevitable. But even if we could effectively automate content moderation, it is not clear that we should.},
  langid = {english},
  keywords = {⏳},
  file = {/Users/sgraf/Zotero/storage/2TUKSY2D/Gillespie_2020_Content moderation, AI, and the question of scale.pdf}
}

@article{gillespie2020a,
  title = {Expanding the Debate about Content Moderation: {{Scholarly}} Research Agendas for the Coming Policy Debates},
  shorttitle = {Expanding the Debate about Content Moderation},
  author = {Gillespie, Tarleton and Aufderheide, Patricia and Carmi, Elinor and Gerrard, Ysabel and Gorwa, Robert and Matamoros-Fernández, Ariadna and Roberts, Sarah T. and Sinnreich, Aram and Myers West, Sarah},
  date = {2020-10-21},
  journaltitle = {Internet Policy Review},
  volume = {9},
  number = {4},
  publisher = {{Internet Policy Review, Alexander von Humboldt Institute for Internet and Society}},
  issn = {2197-6775},
  doi = {10.14763/2020.4.1512},
  url = {https://policyreview.info/articles/analysis/expanding-debate-about-content-moderation-scholarly-research-agendas-coming-policy},
  urldate = {2025-07-18},
  langid = {english},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/LT2WTPUG/Gillespie et al._2020_Expanding the debate about content moderation Scholarly research agendas for the coming policy deba.pdf}
}

@article{gillespie2022,
  title = {Do {{Not Recommend}}? {{Reduction}} as a {{Form}} of {{Content Moderation}}},
  shorttitle = {Do {{Not Recommend}}?},
  author = {Gillespie, Tarleton},
  date = {2022-07},
  journaltitle = {Social Media + Society},
  volume = {8},
  number = {3},
  publisher = {SAGE Publications},
  issn = {2056-3051, 2056-3051},
  doi = {10.1177/20563051221117552},
  url = {https://journals.sagepub.com/doi/10.1177/20563051221117552},
  urldate = {2025-07-21},
  abstract = {Public debate about content moderation has overwhelmingly focused on removal: social media platforms deleting content and suspending users, or opting not to do so. However, removal is not the only available remedy. Reducing the visibility of problematic content is becoming a commonplace element of platform governance. Platforms use machine learning classifiers to identify content they judge misleading enough, risky enough, or offensive enough that, while it does not warrant removal according to the site guidelines, warrants demoting them in algorithmic rankings and recommendations. In this essay, I document this shift and explain how reduction works. I then raise questions about what it means to use recommendation as a means of content moderation.},
  langid = {english},
  keywords = {⏳},
  file = {/Users/sgraf/Zotero/storage/9NP64EPA/Gillespie_2022_Do Not Recommend Reduction as a Form of Content Moderation.pdf}
}

@article{goldman2021,
  title = {Content {{Moderation Remedies}}},
  author = {Goldman, Eric},
  date = {2021},
  journaltitle = {SSRN Electronic Journal},
  shortjournal = {SSRN Journal},
  publisher = {Elsevier BV},
  issn = {1556-5068},
  doi = {10.2139/ssrn.3810580},
  url = {https://www.ssrn.com/abstract=3810580},
  urldate = {2025-07-20},
  langid = {english},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/EZ7IIJUI/Goldman_2021_Content Moderation Remedies.pdf}
}

@article{gongane2022,
  title = {Detection and Moderation of Detrimental Content on Social Media Platforms: Current Status and Future Directions},
  shorttitle = {Detection and Moderation of Detrimental Content on Social Media Platforms},
  author = {Gongane, Vaishali U. and Munot, Mousami V. and Anuse, Alwin D.},
  date = {2022-12},
  journaltitle = {Social Network Analysis and Mining},
  shortjournal = {Soc. Netw. Anal. Min.},
  volume = {12},
  number = {1},
  publisher = {{Springer Science and Business Media LLC}},
  issn = {1869-5450, 1869-5469},
  doi = {10.1007/s13278-022-00951-3},
  url = {https://link.springer.com/10.1007/s13278-022-00951-3},
  urldate = {2025-07-23},
  langid = {english},
  keywords = {⏳},
  file = {/Users/sgraf/Zotero/storage/67DNETBJ/Gongane et al._2022_Detection and moderation of detrimental content on social media platforms current status and future.pdf}
}

@online{goodfellow2014,
  title = {Generative {{Adversarial Networks}}},
  author = {Goodfellow, Ian J. and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  date = {2014},
  doi = {10.48550/ARXIV.1406.2661},
  url = {https://arxiv.org/abs/1406.2661},
  urldate = {2025-07-23},
  abstract = {We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to 1/2 everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples.},
  pubstate = {prepublished},
  version = {1},
  keywords = {⏳,✅,FOS: Computer and information sciences,Machine Learning (cs.LG),Machine Learning (stat.ML)},
  file = {/Users/sgraf/Zotero/storage/HTTQ2TXD/Goodfellow et al._2014_Generative Adversarial Networks.pdf}
}

@article{gorwa2019,
  title = {What Is Platform Governance?},
  author = {Gorwa, Robert},
  date = {2019-05-12},
  journaltitle = {Information, Communication \& Society},
  shortjournal = {Information, Communication \& Society},
  volume = {22},
  number = {6},
  pages = {854--871},
  issn = {1369-118X, 1468-4462},
  doi = {10.1080/1369118X.2019.1573914},
  url = {https://www.tandfonline.com/doi/full/10.1080/1369118X.2019.1573914},
  urldate = {2024-11-24},
  langid = {english},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/3GTVIXSM/Gorwa - 2019 - What is platform governance.pdf}
}

@article{gorwa2020,
  title = {Algorithmic Content Moderation: {{Technical}} and Political Challenges in the Automation of Platform Governance},
  shorttitle = {Algorithmic Content Moderation},
  author = {Gorwa, Robert and Binns, Reuben and Katzenbach, Christian},
  date = {2020-01},
  journaltitle = {Big Data \& Society},
  shortjournal = {Big Data \& Society},
  volume = {7},
  number = {1},
  issn = {2053-9517, 2053-9517},
  doi = {10.1177/2053951719897945},
  url = {http://journals.sagepub.com/doi/10.1177/2053951719897945},
  urldate = {2025-03-14},
  langid = {english},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/EBI7HBG3/Gorwa et al._2020_Algorithmic content moderation Technical and political challenges in the automation of platform gov.pdf}
}

@book{gorwa2024a,
  title = {The Politics of Platform Regulation: {{How}} Governments Shape Online Content Moderation},
  shorttitle = {The {{Politics}} of {{Platform Regulation}}},
  author = {Gorwa, Robert},
  date = {2024},
  series = {Oxford {{Studies}} in {{Digital Politics}}},
  publisher = {Oxford University Press},
  location = {New York},
  abstract = {As digital platforms have become more integral to not just how we live, but also to how we do politics, the rules governing online expression, behavior, and interaction created by large multinational technology firms—popularly termed ‘content moderation,’ ‘platform governance,’ or ‘trust and safety’—have increasingly become the target of government regulatory efforts. This book provides a conceptual and empirical analysis of the important and emerging tech policy terrain of ‘platform regulation.’ How, why, and where exactly is it happening? Why now? And how do we best understand the vast array of strategies being deployed across jurisdictions to tackle this issue? The book outlines three strategies commonly pursued by government actors seeking to combat issues relating to the proliferation of hate speech, disinformation, child abuse imagery, and other forms of harmful content on user-generated content platforms: convincing, collaborating, and contesting. It then outlines a theoretical model for explaining the adoption of these different strategies in different political contexts and regulatory episodes. This model is explored through detailed case study chapters—driven by a combination of stakeholder interviews and new policymaking documents obtained via freedom of information requests—looking at policy development in Germany, Australia and New Zealand, and the United States},
  isbn = {978-0-19-769288-2 978-0-19-769285-1 978-0-19-769286-8},
  langid = {english},
  pagetotal = {1},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/SGQ4CMCT/Gorwa - 2024 - The Politics of Platform Regulation How Governmen.pdf}
}

@article{gorwa2024b,
  title = {Moderating Model Marketplaces: Platform Governance Puzzles for {{AI}} Intermediaries},
  shorttitle = {Moderating Model Marketplaces},
  author = {Gorwa, Robert and Veale, Michael},
  date = {2024-07-02},
  journaltitle = {Law, Innovation and Technology},
  volume = {16},
  number = {2},
  pages = {341--391},
  publisher = {Informa UK Limited},
  issn = {1757-9961, 1757-997X},
  doi = {10.1080/17579961.2024.2388914},
  url = {https://www.tandfonline.com/doi/full/10.1080/17579961.2024.2388914},
  urldate = {2025-05-22},
  langid = {english},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/9SV3IVIB/Gorwa und Veale_2024_Moderating model marketplaces platform governance puzzles for AI intermediaries.pdf}
}

@report{gorwa2024c,
  title = {Real {{Time Threats Analysis}} of {{Trust}} and {{Safety Practices}} for {{Child Sexual Exploitation}} and {{Abuse}} ({{CSEA}}) {{Prevention}} on {{Livestreaming Platforms}}},
  author = {Gorwa, Robert and Thakur, Dhanaraj},
  date = {2024-11},
  institution = {Center for Democracy \& Technology},
  url = {https://cdt.org/wp-content/uploads/2024/11/CDT-Research-Real-Time-Threats-hqp-final.pdf},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/JZH6UWVA/CDT-Research-Real-Time-Threats-hqp-final.pdf}
}

@article{gosztonyi2025,
  title = {The {{European}} Regulation of Porn Platforms before and after the {{Digital Services Act}}},
  author = {Gosztonyi, Gergely and Ruszkai, Szonja and Lendvai, Gergely Ferenc},
  date = {2025-04-04},
  journaltitle = {Porn Studies},
  shortjournal = {Porn Studies},
  pages = {1--16},
  issn = {2326-8743, 2326-8751},
  doi = {10.1080/23268743.2025.2476962},
  url = {https://www.tandfonline.com/doi/full/10.1080/23268743.2025.2476962},
  urldate = {2025-04-11},
  langid = {english},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/4KS2DISD/Gosztonyi et al._2025_The European regulation of porn platforms before and after the Digital Services Act.pdf}
}

@online{griffin2025b,
  title = {A {{Stakeholder Mapping}} and {{Research AgendaThe Politics}} of {{Risk}} in the {{Digital Services Act}}},
  author = {Griffin, Rachel},
  date = {2025},
  eprinttype = {Weizenbaum Institute},
  issn = {2748-5625},
  doi = {10.34669/WI.WJDS/5.2.6},
  url = {https://ojs.weizenbaum-institut.de/index.php/wjds/article/view/5_2_6},
  urldate = {2025-06-19},
  abstract = {The EU’s 2022 Digital Services Act requires large online platforms to regularly assess and mitigate ‘systemic risks’ to various public-interest goals, including fundamental rights, civic discourse, public health and security. Drawing on social constructionist understandings of risk, this article theorizes systemic risk management under the DSA as an arena for political power and contestation, since translating its broadly-defined abstract principles into actionable risk management procedures will entail making many contestable political decisions about how online platforms should be governed. This raises the question: who will exercise power in these decision-making processes? Providing some first answers to this question, this article makes three key contributions. First, it maps the key stakeholder groups involved, and the legal and institutional mechanisms through which they can participate in DSA systemic risk management. Second, it critically analyzes the power dynamics and unequal resources that will structure stakeholder participation. Third, this stakeholder mapping provides a foundation for future research on the politics of DSA systemic risks. The article concludes with reflections on directions for future research on the political agendas, priorities and strategies that shape platform governance.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {⏳,FOS: Law,FOS: Political science,FOS: Social sciences},
  file = {/Users/sgraf/Zotero/storage/TEM5F2CG/Griffin_2025_A Stakeholder Mapping and Research AgendaThe Politics of Risk in the Digital Services Act.pdf}
}

@article{grimmelmann2015,
  title = {The Virtues of Moderation},
  author = {Grimmelmann, James},
  date = {2015},
  journaltitle = {Yale Journal of Law \& Technology},
  volume = {17},
  number = {42},
  eprint = {20.500.13051/7798},
  eprinttype = {hdl},
  url = {http://hdl.handle.net/20.500.13051/7798},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/B8TXWMQM/Grimmelmann_2015_The Virtues of Moderation.pdf}
}

@incollection{grison2024,
  title = {Playing {{Hide}} and {{Seek}} with {{Algorithms}} in the“{{Gay TikTok}}”: {{From Shadowbanning}} to {{Platform Affordances}}},
  booktitle = {Online {{Virality}}: {{Spread}} and {{Influence}}},
  author = {Grison, Thilbaut},
  editor = {Schafer, Valérie and Pailler, Fred},
  date = {2024},
  pages = {S. 249 -- 268},
  keywords = {⏳},
  file = {/Users/sgraf/Zotero/storage/EDPGV7LA/Grison_2024_Playing Hide and Seek with Algorithms in the“Gay TikTok” From Shadowbanning to Platform Affordances.pdf}
}

@incollection{hacker2025,
  title = {Generative {{Discrimination}}: {{What Happens When Generative AI Exhibits Bias}}, and {{What Can Be Done About It}}},
  shorttitle = {Generative {{Discrimination}}},
  booktitle = {The {{Oxford Handbook}} of the {{Foundations}} and {{Regulation}} of {{Generative AI}}},
  author = {Hacker, Philipp and Mittelstadt, Brent and Wachter, Sandra and Zuiderveen Borgesius, Frederik},
  editor = {Hacker, Philipp and Mittelstadt, Brent and Hammer, Sarah and Engel, Andreas},
  date = {2025-04-22},
  edition = {1},
  publisher = {Oxford University Press},
  doi = {10.1093/oxfordhb/9780198940272.013.0016},
  url = {https://academic.oup.com/edited-volume/59908/chapter/512461244},
  urldate = {2025-05-20},
  abstract = {Abstract             As generative Artificial Intelligence (genAI) is increasingly used across sectors, its potential for societal benefit is paired with risks of discrimination. This chapter explores how genAI challenges non-discrimination law, identifying two primary types of discriminatory outputs: (i) demeaning and abusive content; and (ii) subtler biases from inadequate representation of protected groups. The latter includes genAI output that, while not discriminatory in a single instance, has discriminatory effects over time. For example, a genAI system may predominantly display white men when asked for examples of people in important jobs. The chapter examines the resources of existing EU law in addressing such cases and demonstrates how traditional legal categories, such as direct and indirect discrimination and harassment, are sometimes inadequate for genAI. The final part also offers suggestions on updating EU laws and mitigating biases pre-emptively in training and input data.},
  isbn = {978-0-19-894027-2 978-0-19-894030-2},
  langid = {english},
  keywords = {⏳},
  file = {/Users/sgraf/Zotero/storage/K4X9JJHH/Hacker et al._2025_Generative Discrimination What Happens When Generative AI Exhibits Bias, and What Can Be Done About.pdf}
}

@online{han2024,
  title = {Characterizing the {{MrDeepFakes Sexual Deepfake Marketplace}}},
  author = {Han, Catherine and Li, Anne and Kumar, Deepak and Durumeric, Zakir},
  date = {2024},
  doi = {10.48550/ARXIV.2410.11100},
  url = {https://arxiv.org/abs/2410.11100},
  urldate = {2025-04-05},
  abstract = {The prevalence of sexual deepfake material has exploded over the past several years. Attackers create and utilize deepfakes for many reasons: to seek sexual gratification, to harass and humiliate targets, or to exert power over an intimate partner. In part enabling this growth, several markets have emerged to support the buying and selling of sexual deepfake material. In this paper, we systematically characterize the most prominent and mainstream marketplace, MrDeepFakes. We analyze the marketplace economics, the targets of created media, and user discussions of how to create deepfakes, which we use to understand the current state-of-the-art in deepfake creation. Our work uncovers little enforcement of posted rules (e.g., limiting targeting to well-established celebrities), previously undocumented attacker motivations, and unexplored attacker tactics for acquiring resources to create sexual deepfakes.},
  pubstate = {prepublished},
  keywords = {✅,Computers and Society (cs.CY),Cryptography and Security (cs.CR),FOS: Computer and information sciences,Human-Computer Interaction (cs.HC),Social and Information Networks (cs.SI)},
  file = {/Users/sgraf/Zotero/storage/5N4LY9WS/Han et al._2024_Characterizing the MrDeepFakes Sexual Deepfake Marketplace.pdf}
}

@article{harper2021,
  title = {Delineating Non-Consensual Sexual Image Offending: {{Towards}} an Empirical Approach},
  shorttitle = {Delineating Non-Consensual Sexual Image Offending},
  author = {Harper, Craig A. and Fido, Dean and Petronzi, Dominic},
  date = {2021-05},
  journaltitle = {Aggression and Violent Behavior},
  shortjournal = {Aggression and Violent Behavior},
  volume = {58},
  pages = {101547},
  issn = {13591789},
  doi = {10.1016/j.avb.2021.101547},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S135917892100001X},
  urldate = {2025-06-03},
  langid = {english},
  keywords = {⏳},
  file = {/Users/sgraf/Zotero/storage/WMF32MRL/Harper et al._2021_Delineating non-consensual sexual image offending Towards an empirical approach.pdf}
}

@inproceedings{hawkins2025,
  title = {Deepfakes on {{Demand}}: The Rise of Accessible Non-Consensual Deepfake Image Generators},
  shorttitle = {Deepfakes on {{Demand}}},
  author = {Hawkins, Will and Russell, Chris and Mittelstadt, Brent},
  date = {2025},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.2505.03859},
  url = {https://arxiv.org/abs/2505.03859},
  urldate = {2025-05-20},
  abstract = {Advances in multimodal machine learning have made text-to-image (T2I) models increasingly accessible and popular. However, T2I models introduce risks such as the generation of non-consensual depictions of identifiable individuals, otherwise known as deepfakes. This paper presents an empirical study exploring the accessibility of deepfake model variants online. Through a metadata analysis of thousands of publicly downloadable model variants on two popular repositories, Hugging Face and Civitai, we demonstrate a huge rise in easily accessible deepfake models. Almost 35,000 examples of publicly downloadable deepfake model variants are identified, primarily hosted on Civitai. These deepfake models have been downloaded almost 15 million times since November 2022, with the models targeting a range of individuals from global celebrities to Instagram users with under 10,000 followers. Both Stable Diffusion and Flux models are used for the creation of deepfake models, with 96\% of these targeting women and many signalling intent to generate non-consensual intimate imagery (NCII). Deepfake model variants are often created via the parameter-efficient fine-tuning technique known as low rank adaptation (LoRA), requiring as few as 20 images, 24GB VRAM, and 15 minutes of time, making this process widely accessible via consumer-grade computers. Despite these models violating the Terms of Service of hosting platforms, and regulation seeking to prevent dissemination, these results emphasise the pressing need for greater action to be taken against the creation of deepfakes and NCII.},
  version = {1},
  keywords = {✅,68T01,Artificial Intelligence (cs.AI),Computer Vision and Pattern Recognition (cs.CV),Computers and Society (cs.CY),FOS: Computer and information sciences},
  file = {/Users/sgraf/Zotero/storage/EL7FX9MK/Hawkins et al._2025_Deepfakes on Demand the rise of accessible non-consensual deepfake image generators.pdf}
}

@inproceedings{henderson2023,
  title = {Self-{{Destructing Models}}: {{Increasing}} the {{Costs}} of {{Harmful Dual Uses}} of {{Foundation Models}}},
  shorttitle = {Self-{{Destructing Models}}},
  booktitle = {Proceedings of the 2023 {{AAAI}}/{{ACM Conference}} on {{AI}}, {{Ethics}}, and {{Society}}},
  author = {Henderson, Peter and Mitchell, Eric and Manning, Christopher and Jurafsky, Dan and Finn, Chelsea},
  date = {2023-08-08},
  pages = {287--296},
  publisher = {ACM},
  location = {Montréal QC Canada},
  doi = {10.1145/3600211.3604690},
  url = {https://dl.acm.org/doi/10.1145/3600211.3604690},
  urldate = {2025-08-03},
  eventtitle = {{{AIES}} '23: {{AAAI}}/{{ACM Conference}} on {{AI}}, {{Ethics}}, and {{Society}}},
  isbn = {979-8-4007-0231-0},
  langid = {english},
  file = {/Users/sgraf/Zotero/storage/WJM5T2MV/Henderson et al._2023_Self-Destructing Models Increasing the Costs of Harmful Dual Uses of Foundation Models.pdf}
}

@article{henry2018,
  title = {Policing Image-Based Sexual Abuse: Stakeholder Perspectives},
  shorttitle = {Policing Image-Based Sexual Abuse},
  author = {Henry, Nicola and Flynn, Asher and Powell, Anastasia},
  date = {2018-11-02},
  journaltitle = {Police Practice and Research},
  shortjournal = {Police Practice and Research},
  volume = {19},
  number = {6},
  pages = {565--581},
  issn = {1561-4263, 1477-271X},
  doi = {10.1080/15614263.2018.1507892},
  url = {https://www.tandfonline.com/doi/full/10.1080/15614263.2018.1507892},
  urldate = {2024-09-19},
  langid = {english},
  keywords = {⏳,❌},
  file = {/Users/sgraf/Zotero/storage/28XS22L2/Henry et al. - 2018 - Policing image-based sexual abuse stakeholder perspectives.pdf}
}

@article{henry2018a,
  title = {Technology-{{Facilitated Sexual Violence}}: {{A Literature Review}} of {{Empirical Research}}},
  shorttitle = {Technology-{{Facilitated Sexual Violence}}},
  author = {Henry, Nicola and Powell, Anastasia},
  date = {2018-04},
  journaltitle = {Trauma, Violence, \& Abuse},
  shortjournal = {Trauma, Violence, \& Abuse},
  volume = {19},
  number = {2},
  pages = {195--208},
  issn = {1524-8380, 1552-8324},
  doi = {10.1177/1524838016650189},
  url = {https://journals.sagepub.com/doi/10.1177/1524838016650189},
  urldate = {2025-06-12},
  abstract = {Technology-facilitated sexual violence (TFSV) refers to a range of behaviors where digital technologies are used to facilitate both virtual and face-to-face sexually based harms. Such behaviors include online sexual harassment, gender- and sexuality-based harassment, cyberstalking, image-based sexual exploitation, and the use of a carriage service to coerce a victim into an unwanted sexual act. This article reviews the current state of knowledge on these different dimensions, drawing on existing empirical studies. While there is a growing body of research into technology-facilitated harms perpetrated against children and adolescents, there is a dearth of qualitative and quantitative research on TFSV against adults. Moreover, few of the existing studies provide reliable data on the nature, scope, and impacts of TFSV. Preliminary studies, however, indicate that some harms, much like sexual violence more broadly, may be predominantly gender-, sexuality-, and age-based, with young women being overrepresented as victims in some categories. This review collects the empirical evidence to date regarding the prevalence and gender-based nature of TFSV against adults and discusses the implications for policy and programs, as well as suggestions for future research.},
  langid = {english},
  keywords = {⏳},
  file = {/Users/sgraf/Zotero/storage/5SD7V9C7/Henry und Powell_2018_Technology-Facilitated Sexual Violence A Literature Review of Empirical Research.pdf}
}

@article{hoboken2023,
  title = {Putting the {{DSA}} into {{Practice}}: {{Enforcement}}, {{Access}} to {{Justice}}, and {{Global Implications}}},
  shorttitle = {Putting the {{DSA}} into {{Practice}}},
  author = {Hoboken, Joris and Buri, Ilaria and Quintais, João and Fahy, Ronan and Appelman, Naomi and Straub, Marlene},
  with = {{Fachinformationsdienst Für Internationale Und Interdisziplinäre Rechtsforschung}},
  date = {2023},
  publisher = {Verfassungsbooks},
  doi = {10.17176/20230208-093135-0},
  url = {https://intr2dok.vifa-recht.de/receive/mir_mods_00015033},
  urldate = {2025-03-07},
  abstract = {Die Veröffentlichung des Gesetzes über digitale Dienste im Amtsblatt markiert das Ende eines jahrelangen Entwurfs- und Verhandlungsprozesses und schlägt ein neues Kapitel auf: das seiner Durchsetzung, des praktikablen Zugangs zur Justiz und des Potenzials, weltweite Präzedenzfälle zu schaffen. Das Gesetz wurde als Europas neue „digitale Verfassung“ bezeichnet, die den Vorrang der demokratischen Regelsetzung vor den privaten transnationalen Ordnungsmechanismen von Big Tech bekräftigt. Damit will die Europäische Union einmal mehr einen globalen Standard für die Regulierung des digitalen Umfelds setzen. Doch wird das Gesetz über digitale Dienste die Erwartungen erfüllen können, und unter welchen Bedingungen? Martin Husovec Will the Digital Services Act Work?: On Money and Effort Folkert Wilman Between Preservation and Clarification: The Evolution of the DSA's Liability Rules in Light of the CJEU's Case Law Sebastian Becker and Jan Penfrat The DSA Fails to Reign in the Most Harmful Digital Platform Businesses – But It Is Still Useful Alexandra Geese Why the DSA Could Save Us From the Rise of Authoritarian Regimes Ilaria Buri A Regulator Caught Between Conflicting Policy Objectives: Reflections on the European Commission ́s Role as DSA Enforcer Julian Jaursch Platform Oversight: Here is what a Strong Digital Services Coordinator Should Look Like Alessandro Mantelero Fundamental Rights Impact Assessment in the DSA Asha Allen An Intersectional Lens on Online Gender-Based Violence and the Digital Services Act Catalina Goanta Now What: Exploring the DSA's Enforcement Futures in Relation to Social Media Platforms and Native Advertising Pietro Ortolani If You Build it, They Will Come: The DSA “Procedure Before Substance” Approach Aleksandra Kuczerawy Remedying Overremoval Tomiwa Ilori Contextualisation over Replication: The Possible Impacts of the Digital Services Act on Content Regulation in African Countries Nayanatara Ranganathan Regulating Influence, Timidly Nicolo Zingales The DSA as a Paradigm Shift for Online Intermediaries' Due Diligence: Hail To Meta-Regulation Daphne Keller The European Union's New Digital Services Act and the Rest of the World},
  langid = {english},
  keywords = {⏳,340},
  file = {/Users/sgraf/Zotero/storage/6SWWR3VX/Hoboken et al._2023_Putting the DSA into Practice Enforcement, Access to Justice, and Global Implications.pdf}
}

@report{homesecurityheroes2023,
  title = {2023 {{State}} of {{Deepfakes}}: {{Realities}}, {{Threats}}, and {{Impact}}},
  author = {{Home Security Heroes}},
  date = {2023},
  url = {https://www.securityhero.io/state-of-deepfakes/},
  file = {/Users/sgraf/Zotero/storage/W23FESU5/state-of-deepfake-infographic-2023.pdf}
}

@article{hoppenstedt2025,
  entrysubtype = {nonacademic},
  title = {The {{Growing Problem}} of {{Fake Porn Images}}},
  author = {Hoppenstedt, Max and Höfner, Roman and Buschek, Christo and Böhm, Markus},
  date = {2025-01-03},
  journaltitle = {spiegel.de},
  url = {https://www.spiegel.de/international/zeitgeist/artificial-intelligence-and-deepfakes-the-growing-problem-of-fake-porn-images-a-82fd8d6c-f4e3-4237-9066-978cbed496cf},
  urldate = {2025-05-05},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/K668MBL5/Hoppenstedt et al._2025_The Growing Problem of Fake Porn Images.pdf}
}

@article{huber2024,
  title = {Non-Consensual Intimate Image Distribution: {{Nature}}, Removal, and Implications for the {{Online Safety Act}}},
  shorttitle = {Non-Consensual Intimate Image Distribution},
  author = {Huber, Antoinette Raffaela and Ward, Zara},
  date = {2024-07-21},
  journaltitle = {European Journal of Criminology},
  shortjournal = {European Journal of Criminology},
  issn = {1477-3708, 1741-2609},
  doi = {10.1177/14773708241255821},
  url = {https://journals.sagepub.com/doi/10.1177/14773708241255821},
  urldate = {2024-09-09},
  abstract = {Research was conducted in partnership with the Revenge Porn Helpline (RPH) to examine the location and removal of non-consensual intimate image (NCII) abuse. By examining reports to the helpline, data were collected to uncover where intimate images were being non-consensually distributed, how they were proportionally distributed across platforms, and avenues for image removal. The data confirm that social media plays a key role in NCII distribution and provides further insight into where images are being distributed outside of social media platforms. Data on image removal indicate that knowledge of how to navigate different types of platforms is important for image removal success, making contributions from organisations such as the RPH vital, and highlighting the need to make reporting processes more accessible. The findings also indicate significant gaps within the Online Safety Act which will need to be addressed if the Act is to effectively protect victim-survivors. In particular, the need to move beyond focusing on services with the largest user numbers and broadening the scope to include smaller high-risk and problematic platforms.},
  langid = {english},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/855HFEAL/Huber und Ward - 2024 - Non-consensual intimate image distribution Nature.pdf}
}

@article{husovec2023,
  title = {Rising above Liability: The {{Digital Services Act}} as a Blueprint for the Second Generation of Global Internet Rules},
  shorttitle = {Rising {{Above Liability}}},
  author = {Husovec, Martin},
  date = {2023},
  publisher = {Berkeley Technology Journal},
  doi = {10.15779/Z38M902431},
  url = {https://lawcat.berkeley.edu/record/1287997},
  urldate = {2025-03-29},
  keywords = {⏳},
  file = {/Users/sgraf/Zotero/storage/ERCXRAPU/Husovec, Martin;_2023_Rising Above Liability The Digital Services Act as a Blueprint for the Second Generation Of Global.pdf}
}

@report{internetmatters.org2024,
  title = {The New Face of Digital Abuse: {{Children}}'s Experiences of Nude Deepfakes},
  author = {{internetmatters.org}},
  date = {2024-10},
  url = {https://www.internetmatters.org/hub/research/children-experiences-nude-deepfakes-research/},
  urldate = {2025-07-02},
  keywords = {⏳},
  file = {/Users/sgraf/Zotero/storage/BUKJGSUH/internetmatters.org_2024_The new face of digital abuse Children's experiences of nude deepfakes.pdf}
}

@article{jacobs2024,
  title = {{{DIY}} Pornography and the Deepfake Coup},
  author = {Jacobs, Katrien},
  date = {2024-01-02},
  journaltitle = {Porn Studies},
  shortjournal = {Porn Studies},
  volume = {11},
  number = {1},
  pages = {91--98},
  issn = {2326-8743, 2326-8751},
  doi = {10.1080/23268743.2023.2297691},
  url = {https://www.tandfonline.com/doi/full/10.1080/23268743.2023.2297691},
  urldate = {2025-06-05},
  langid = {english}
}

@article{jacobs2024a,
  title = {{{DIY}} Pornography and the Deepfake Coup},
  author = {Jacobs, Katrien},
  date = {2024-01-02},
  journaltitle = {Porn Studies},
  shortjournal = {Porn Studies},
  volume = {11},
  number = {1},
  pages = {91--98},
  issn = {2326-8743, 2326-8751},
  doi = {10.1080/23268743.2023.2297691},
  url = {https://www.tandfonline.com/doi/full/10.1080/23268743.2023.2297691},
  urldate = {2025-07-04},
  langid = {english},
  keywords = {⏳}
}

@article{jacobsen2024,
  title = {Deepfakes and the Promise of Algorithmic Detectability},
  author = {Jacobsen, Benjamin N},
  date = {2024-04-02},
  journaltitle = {European Journal of Cultural Studies},
  shortjournal = {European Journal of Cultural Studies},
  pages = {13675494241240028},
  issn = {1367-5494, 1460-3551},
  doi = {10.1177/13675494241240028},
  url = {https://journals.sagepub.com/doi/10.1177/13675494241240028},
  urldate = {2025-06-04},
  abstract = {Deepfakes, as a sociocultural and technical phenomenon, have engendered two distinct yet intimately interwoven set of responses: on one hand, they have created widespread anxieties concerning the potential and harmful impact of deepfakes. On the other hand, they have also given rise to a new regime of detection: tools, models, and methods that are developed and used to detect whether something is a deepfake or not. However, the ways in which machine learning algorithms are being framed as the solution to the problem of deepfake detection have not received sufficient critical attention. Drawing on the 2019 Deepfake Detection Challenge organised by Meta as well as finding resonances in the work of Eyal Weizman, this article seeks to problematise and unsettle what I call the promise of algorithmic detectability. That is, the claim that machine learning algorithms render the issue of deepfake detection knowable, tractable, and resolvable. Examining the themes of training data, thresholds, and certainty, I emphasise the inherent difficulties, intractabilities and contingencies of deepfake detection models. Ultimately, I argue that the promise of algorithmic detectability falls short and that the ethico-politics of deepfakes cannot be reduced solely to a framework of detection algorithms.},
  langid = {english},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/BQ3DTLCQ/Jacobsen_2024_Deepfakes and the promise of algorithmic detectability.pdf}
}

@article{jones2024,
  entrysubtype = {nonacademic},
  title = {Spain Sentences 15 Schoolchildren over {{AI-generated}} Naked Images},
  author = {Jones, Sam},
  date = {2024-07-09},
  journaltitle = {theguardian.com},
  url = {https://www.theguardian.com/world/article/2024/jul/09/spain-sentences-15-school-children-over-ai-generated-naked-images},
  urldate = {2025-03-22}
}

@report{jugendschutz.net2024,
  title = {Bericht {{Jugendschutz}} Im {{Internet}} 2023 - {{Risiken}} Und {{Handlungsbedarf}}},
  author = {{Jugendschutz.net}},
  date = {2024-07},
  url = {https://www.jugendschutz.net/fileadmin/daten/publikationen/jahresberichte/jahresbericht_2023.pdf},
  urldate = {2024-08-29},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/6ZE6Z4Z5/Jugendschutz.net - 2024 - Bericht Jugendschutz im Internet 2023 - Risiken un.pdf}
}

@book{jünger2023,
  title = {Computational Methods für die Sozial- und Geisteswissenschaften},
  author = {Jünger, Jakob and Gärtner, Chantal},
  date = {2023},
  publisher = {Springer Fachmedien Wiesbaden},
  location = {Wiesbaden},
  doi = {10.1007/978-3-658-37747-2},
  url = {https://link.springer.com/10.1007/978-3-658-37747-2},
  urldate = {2025-04-11},
  isbn = {978-3-658-37746-5 978-3-658-37747-2},
  langid = {ngerman},
  file = {/Users/sgraf/Zotero/storage/6EZCB8ZA/Jünger und Gärtner_2023_Computational Methods für die Sozial- und Geisteswissenschaften.pdf;/Users/sgraf/Zotero/storage/B4MXMFP7/Jünger und Gärtner_2023_Computational Methods für die Sozial- und Geisteswissenschaften.pdf}
}

@online{karaboga2024,
  title = {Deepfakes und manipulierte Realitäten - Technologiefolgenabschätzung und Handlungsempfehlungen für die Schweiz},
  author = {Karaboga, Murat and Frei, Nula and Puppis, Manuel and Vogler, Daniel and Raemy, Patric and Ebbers, Frank and Runge, Greta and Rauchfleisch, Adrian and family=Seta, given=Gabriela, prefix=de, useprefix=true and Gurr, Gwendolin and Friedewald, Michael and Rovelli, Sophia},
  date = {2024-06-18},
  eprinttype = {vdf},
  doi = {10.5281/ZENODO.11643644},
  url = {https://zenodo.org/doi/10.5281/zenodo.11643644},
  urldate = {2025-07-29},
  abstract = {A deepfake is an audio or (moving) image content synthesised or manipulated with the aid of artificial intelligence technologies, which appears to be authentic and in which a person says or does something that he or she has never said or done. Since 2017, when synthetic and manipulated media content was firstreferred to as “deepfake”, the term has become firmly entrenched in political and media debate. Several years after its introduction, we can now draw some mixed conclusions: some political deepfakes and deepfake-based fraud cases, for example nuisance or scam calls, appear to confirm certain concerns. On the other hand, avariety of useful applications have been created that are based on synthetic and manipulated media content. Neither the widely feared large-scale use of deepfakes in disinformation campaigns nor a major information apocalypse have materialised to date. The purpose of this study is to assess the opportunities and risks associated with deepfakes for Switzerland.},
  langid = {ngerman},
  pubstate = {prepublished},
  keywords = {⏳},
  file = {/Users/sgraf/Zotero/storage/BGI7JA29/Karaboga et al._2024_Deepfakes und manipulierte Realitäten - Technologiefolgenabschätzung und Handlungsempfehlungen für d.pdf}
}

@article{karagianni2024,
  title = {A Feminist Legal Analysis of Non-Consensual Sexualized Deepfakes: Contextualizing Its Impact as {{AI-generated}} Image-Based Violence under {{EU}} Law},
  shorttitle = {A Feminist Legal Analysis of Non-Consensual Sexualized Deepfakes},
  author = {Karagianni, Anastasia and Doh, Miriam},
  date = {2024-11-14},
  journaltitle = {Porn Studies},
  shortjournal = {Porn Studies},
  pages = {1--18},
  issn = {2326-8743, 2326-8751},
  doi = {10.1080/23268743.2024.2408277},
  url = {https://www.tandfonline.com/doi/full/10.1080/23268743.2024.2408277},
  urldate = {2025-06-03},
  langid = {english},
  keywords = {⏳},
  file = {/Users/sgraf/Zotero/storage/7CRGA978/Karagianni und Doh_2024_A feminist legal analysis of non-consensual sexualized deepfakes contextualizing its impact as AI-g.pdf}
}

@article{karasavva2022,
  title = {Personality, {{Attitudinal}}, and {{Demographic Predictors}} of {{Non-consensual Dissemination}} of {{Intimate Images}}},
  author = {Karasavva, V. and Forth, A.},
  date = {2022-11},
  journaltitle = {Journal of Interpersonal Violence},
  shortjournal = {J Interpers Violence},
  volume = {37},
  number = {21--22},
  pages = {NP19265-NP19289},
  issn = {0886-2605, 1552-6518},
  doi = {10.1177/08862605211043586},
  url = {https://journals.sagepub.com/doi/10.1177/08862605211043586},
  urldate = {2025-06-04},
  abstract = {Non-consensual intimate image dissemination (NCII), or else better known as “revenge pornography” is a form of technology-facilitated sexual violence that can have devastating effects on the victim. This is one of the first studies examining how demographic characteristics (gender, sexual orientation), personality traits (Dark Tetrad), and attitudes (aggrieved entitlement, sexual entitlement, sexual image abuse myth acceptance) predict NCII perpetration and victimization. In a sample of 810 undergraduate students (72.7\% female and 23.3\% male), 13.7\% of the participants had at some point in their life, distributed nude, or sexual pictures of someone else without consent and 28.5\% had experienced such victimization. NCII perpetration was predictive of NCII victimization and vice versa. Using binomial logistic regression, we found that women, members of the LGBQ+ community, those scoring higher in sadism, and participants with a history of NCII perpetration were more likely to report that someone had distributed their nude or sexual image without consent. Further, we found that those scoring higher in narcissism and sadism, along with those with a history of NCII victimization were more likely to report they had distributed the nude or sexual image of someone else without consent. Finally, the findings suggest that the relationship between victims and perpetrators is quite a bit more varied than the term “revenge pornography” implies.},
  langid = {english},
  file = {/Users/sgraf/Zotero/storage/RBYUSRSN/Karasavva und Forth_2022_Personality, Attitudinal, and Demographic Predictors of Non-consensual Dissemination of Intimate Ima.pdf}
}

@article{karasavva2023,
  title = {From Myth to Reality: Sexual Image Abuse Myth Acceptance, the {{Dark Tetrad}}, and Non-Consensual Intimate Image Dissemination Proclivity},
  shorttitle = {From Myth to Reality},
  author = {Karasavva, Vasileia and Swanek, Jessie and Smodis, Audrey and Forth, Adelle},
  date = {2023-01-02},
  journaltitle = {Journal of Sexual Aggression},
  shortjournal = {Journal of Sexual Aggression},
  volume = {29},
  number = {1},
  pages = {51--67},
  issn = {1355-2600, 1742-6545},
  doi = {10.1080/13552600.2022.2032430},
  url = {https://www.tandfonline.com/doi/full/10.1080/13552600.2022.2032430},
  urldate = {2025-06-03},
  langid = {english},
  keywords = {⏳},
  file = {/Users/sgraf/Zotero/storage/BWCV5XID/Karasavva et al._2023_From myth to reality sexual image abuse myth acceptance, the Dark Tetrad, and non-consensual intima.pdf}
}

@book{katzenbach2018,
  title = {Die Regeln digitaler Kommunikation},
  author = {Katzenbach, Christian},
  date = {2018},
  publisher = {Springer Fachmedien Wiesbaden},
  location = {Wiesbaden},
  doi = {10.1007/978-3-658-19337-9},
  url = {http://link.springer.com/10.1007/978-3-658-19337-9},
  urldate = {2025-03-14},
  isbn = {978-3-658-19336-2 978-3-658-19337-9},
  langid = {ngerman},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/8E6TYHQE/Katzenbach_2018_Die Regeln digitaler Kommunikation.pdf}
}

@book{kelly1988,
  title = {Surviving Sexual Violence},
  author = {Kelly, Liz},
  date = {1988},
  publisher = {Polity Press},
  location = {Cambridge Oxford},
  abstract = {Women's awareness of the threat and reality of sexual violence is now perhaps more than ever publicly acknowledged. Yet this fact continues to be almost wholly ignored. This new study, based on in-depth interviews with 60 women, is the first to cover the experience of a range of forms of sexual violence over women's lifetimes. Drawing on feminist theory, developing a critique of male research and quoting extensively from the women interviewed, it developes feminist thought in several key areas: the similarities and differences between forms of sexual violence; the ways women define their experiences; and the strategies women use in resisting, coping with and surviving sexual violence. The author stresses the importance for all women of recognizing the incidents of sexual violence in their lives and seeing themselves and other women as survivors rather than victims. In highlighting the ways in which the media, the criminal justice system and even the 'helping' profess ions contribute to the trivialization of sexual violence, she demonstrates the necessity of women organizing collectively to end this suffering},
  langid = {english},
  pagetotal = {273}
}

@article{kharvi2024,
  title = {Understanding the {{Impact}} of {{AI-Generated Deepfakes}} on {{Public Opinion}}, {{Political Discourse}}, and {{Personal Security}} in {{Social Media}}},
  author = {Kharvi, Prakash L.},
  date = {2024-07},
  journaltitle = {IEEE Security \& Privacy},
  shortjournal = {IEEE Secur. Privacy},
  volume = {22},
  number = {4},
  pages = {115--122},
  publisher = {{Institute of Electrical and Electronics Engineers (IEEE)}},
  issn = {1540-7993, 1558-4046},
  doi = {10.1109/msec.2024.3405963},
  url = {https://ieeexplore.ieee.org/document/10552098/},
  urldate = {2025-07-23}
}

@incollection{kikerpill2021,
  title = {Dealing with {{Deepfakes}}: {{Reddit}}, {{Online Content Moderation}}, and {{Situational Crime Prevention}}},
  shorttitle = {Dealing with {{Deepfakes}}},
  booktitle = {Studies in {{Media}} and {{Communications}}},
  author = {Kikerpill, Kristjan and Siibak, Andra and Valli, Suido},
  editor = {Wiest, Julie B.},
  date = {2021-03-25},
  pages = {25--45},
  publisher = {Emerald Publishing Limited},
  doi = {10.1108/S2050-206020210000020008},
  url = {https://www.emerald.com/insight/content/doi/10.1108/S2050-206020210000020008/full/html},
  urldate = {2025-06-03},
  isbn = {978-1-83909-112-4 978-1-83909-111-7},
  keywords = {❌}
}

@article{kira2024,
  title = {When Non-Consensual Intimate Deepfakes Go Viral: {{The}} Insufficiency of the {{UK Online Safety Act}}},
  shorttitle = {When Non-Consensual Intimate Deepfakes Go Viral},
  author = {Kira, Beatriz},
  date = {2024-09},
  journaltitle = {Computer Law \& Security Review},
  shortjournal = {Computer Law \& Security Review},
  volume = {54},
  pages = {106024},
  issn = {02673649},
  doi = {10.1016/j.clsr.2024.106024},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0267364924000906},
  urldate = {2024-09-09},
  abstract = {Advancements in artificial intelligence (AI) have drastically simplified the creation of synthetic media. While concerns often focus on potential misinformation harms, ‘non-consensual intimate deepfakes’ (NCID) – a form of image-based sexual abuse – pose a current, severe, and growing threat, disproportionately impacting women and girls. This article examines the measures implemented with the recently adopted Online Safety Act 2023 (OSA) and argues that the new criminal offences and the ‘systems and processes’ approach the law adopts are insufficient to counter NCID in the UK. This is because the OSA relies on platform policies that often lack consistency regarding synthetic media and on platforms’ content removal mechanisms which offer limited redress to victimsurvivors after the harm has already occurred. The article argues that stronger prevention mechanisms are necessary and proposes that the law should mandate all AI-powered deepfake creation tools to ban the generation of intimate synthetic content and require the implementation of comprehensive and enforceable content moderation systems.},
  langid = {english},
  keywords = {⏳,✅},
  file = {/Users/sgraf/Zotero/storage/L7249PTT/Kira - 2024 - When non-consensual intimate deepfakes go viral T.pdf}
}

@article{kozlovski2025,
  entrysubtype = {nonacademic},
  title = {Deepfakes and {{Beyond}}: {{Mapping}} the {{Ethics}} and {{Risks}} of {{Digital Duplicates}}},
  author = {Kozlovski, Atay},
  date = {2025-05-13},
  journaltitle = {Tech Policy Press},
  url = {https://www.techpolicy.press/deepfakes-and-beyond-mapping-the-ethics-and-risks-of-digital-duplicates/},
  keywords = {⏳},
  file = {/Users/sgraf/Zotero/storage/I6IF5IA6/Kozlovski_2025_Deepfakes and Beyond Mapping the Ethics and Risks of Digital Duplicates.pdf}
}

@article{kristof2020,
  entrysubtype = {nonacademic},
  title = {The Children of {{Pornhub}}: {{Why Does Canada Allow This}}. {{Company}} to {{Profit Off Videos}} of {{Exploitation}} and {{Assault}}?},
  author = {Kristof, Nicholas},
  date = {2020},
  journaltitle = {New York Times},
  url = {https://www.nytimes.com/2020/12/04/opinion/sunday/pornhub-rape-trafficking.html}
}

@article{łabuz2023,
  title = {Regulating {{Deep Fakes}} in the {{Artificial Intelligence Act}}},
  author = {Łabuz, Mateusz},
  date = {2023-10-27},
  journaltitle = {Applied Cybersecurity \& Internet Governance},
  shortjournal = {Applied Cybersecurity \& Internet Governance},
  volume = {2},
  number = {1},
  pages = {1--42},
  issn = {2956-3119, 2956-4395},
  doi = {10.60097/ACIG/162856},
  url = {https://www.acigjournal.com/Regulating-Deep-Fakes-in-the-Artificial-Intelligence-Act,184302,0,2.html},
  urldate = {2025-05-20},
  abstract = {The Artificial Intelligence Act (AI Act) may be a milestone of regulating artificial intelligence by the European Union. Regulatory framework proposed by the European Commission has the potential to serve as a benchmark worldwide and strengthen the position of the EU as one of the main players of the technology market. One of the components of the regulation are the provisions on deep fakes, which include the definition, classification as a “specific risk” AI system and transparency obligations. Deep fakes rightly arouse controversy and are assessed as a complex phenomenon, the negative use of which significantly increases the risk of political manipulation, and at the same time contributes to disinformation, undermining trust in information or in the media. The AI Act may strengthen the protection of citizens against some of the negative consequences of misusing deep fakes, although the impact of the regulatory framework in its current form will be limited due to the specificity of creating and disseminating deep fakes. The effectiveness of the provisions will depend not only on the enforcement capabilities, but also on the precision of phrasing provisions to prevent misinterpretation and deliberate abuse of exceptions. At the same time, the AI Act will not cover a significant part of deep fakes, which, due to the malicious intentions of their creators, will not be subject to the protection in the form of transparency obligations. This study allows for the analysis of provisions relating to deep fakes in the AI Act and proposing improvements that will take into account the specificity of this phenomenon to a greater extent.},
  keywords = {⏳},
  file = {/Users/sgraf/Zotero/storage/IRB3SD64/Łabuz_2023_Regulating Deep Fakes in the Artificial Intelligence Act.pdf}
}

@article{łabuz2025,
  title = {A {{Teleological Interpretation}} of the {{Definition}} of {{DeepFakes}} in the {{EU Artificial Intelligence Act}}—{{A Purpose}}‐{{Based Approach}} to {{Potential Problems With}} the {{Word}} “{{Existing}}”},
  author = {Łabuz, Mateusz},
  date = {2025-03},
  journaltitle = {Policy \& Internet},
  shortjournal = {Policy \&amp; Internet},
  volume = {17},
  number = {1},
  pages = {e435},
  issn = {1944-2866, 1944-2866},
  doi = {10.1002/poi3.435},
  url = {https://onlinelibrary.wiley.com/doi/10.1002/poi3.435},
  urldate = {2025-05-20},
  abstract = {ABSTRACT             The EU Artificial Intelligence Act is the world's first attempt to holistically regulate artificial intelligence. It presents an extensive, multi‐faceted definition of deepfakes, and introduces specific safeguards against their misuses. These guardrails have the potential to become a global role model. The AI Act uses concepts that leave room for interpretation, which is important given the constant development of technology and the need for adjustments. However, some solutions raise the problem of vagueness, which in turn may result in a narrower interpretation of a linguistic nature, and reduce the scope of legally permissible countermeasures. The aim of this study is to critically evaluate the definition of deepfakes contained in the AI Act in relation to the word “existing” used. A narrow interpretation could potentially exclude some synthetic media from the scope of transparency obligations due to the non‐classification of these media as deepfakes. Therefore, a teleological interpretation of the provisions is proposed, reinforced with elements of systemicity, so that the safeguards built by the AI Act also include deepfakes that do not depict any identifiable pre‐existing persons, objects, places, entities or events to better reflect goals of the regulation, and complement the value‐based system of the AI Act.           ,              摘要:             欧盟《人工智能法案》是世界上用于全面监管人工智能的首次尝试。该法案对深度伪造技术进行了广泛、多方面的定义, 并引入了防止其滥用的具体保障措施。这些措施有可能成为全球榜样。《人工智能法案》使用的概念留有解释空间, 鉴于技术的不断发展和调整的需要, 这一点很重要。然而, 一些解决方案提出了模糊性的问题, 这反过来可能导致对语言性质的更狭隘的解释, 并缩小法律允许的对策范围。本研究旨在批判性地评价《人工智能法案》中与“现有”一词相关的深度伪造技术的定义。狭义解释可能会将某些合成媒体排除在透明度义务范围之外, 因为这些媒体不被归类为深度伪造。因此, 建议对这些条款进行目的论解释, 并辅以系统性要素, 以便《人工智能法案》建立的保障措施也包括那些“不描绘任何可识别的预先存在的人、物体、地点、实体或事件”的深度伪造, 以期更好地反映监管目标, 并补充《人工智能法案》的价值体系。           ,              Resumen:             La Ley de Inteligencia Artificial de la UE es el primer intento del mundo de regular de manera holística la inteligencia artificial. Presenta una definición extensa y multifacética de deep fakes e introduce salvaguardas específicas contra su uso indebido. Estas barandillas tienen el potencial de convertirse en un modelo global a seguir. La Ley de IA utiliza conceptos que dejan espacio para la interpretación, lo cual es importante dado el constante desarrollo de la tecnología y la necesidad de ajustes. Sin embargo, algunas soluciones plantean el problema de la vaguedad, que a su vez puede dar lugar a una interpretación más estrecha de naturaleza lingüística y reducir el alcance de las contramedidas legalmente permisibles. El objetivo de este estudio es evaluar críticamente la definición de deep fakes contenida en la Ley de IA en relación con la palabra “existente” utilizada. Una interpretación estricta podría excluir algunos medios sintéticos del ámbito de aplicación de las obligaciones de transparencia debido a la no clasificación de estos medios como deep fakes. Por lo tanto, se propone una interpretación teleológica de las disposiciones, reforzada con elementos de sistematicidad, de modo que las salvaguardas construidas por la Ley de IA también incluyan deep fakes que no retraten ninguna persona, objeto, lugar, entidad o evento preexistente identificable para reflejar mejor los objetivos de la regulación y complementar el sistema basado en valores de la Ley de IA.},
  langid = {english},
  keywords = {⏳},
  file = {/Users/sgraf/Zotero/storage/HLMVAEYX/Łabuz_2025_A Teleological Interpretation of the Definition of DeepFakes in the EU Artificial Intelligence Act—A.pdf}
}

@article{lakshané2024,
  title = {Non-Consensual Intimate Imagery: An Overview},
  shorttitle = {Non-Consensual Intimate Imagery},
  author = {Lakshané, Rohini},
  date = {2024-03-25},
  publisher = {Take Back The Tech},
  doi = {10.5281/ZENODO.10980144},
  url = {https://zenodo.org/doi/10.5281/zenodo.10980144},
  urldate = {2025-07-21},
  abstract = {Take Back the Tech! is proud to present this overview paper regarding non-consensual intimate imagery (NCII) by Rohini Lakshané. It unpacks definitions, the impact on survivors/victims, how morality and victim-blaming is often interwoven in responses, the difficulty of action, types of legislation (and limits) to address it, and, importantly, resources for take-down and coping with NCII. As noted in the introduction, NCII refers to intimate photos or videos that are captured, published or distributed without the explicit consent of the person(s) depicted in those images. The meaning and connotations of what constitutes an intimate or sexually explicit image changes vastly with social and cultural norms and contexts in different parts of the world. In this document, we define intimate images as sexually explicit, nude or partially nude photos or videos. They are a violation of privacy and of consent, and are a type of technology-facilitated gender-based violence (TFGBV). When perpetrated by intimate partners, NCII are also a form of intimate partner violence (IPV) or domestic violence. NCII impinge on the victim’s right to privacy, sexual consent, their freedom of (sexual) expression, and right to live free from violence. The majority of the victims of NCII are known to be women or gender-diverse persons. However, NCII victims may belong to any gender or sexual orientation. Symptomatic of the surveillance economy, which threatens the freedom of expression and speech of women, gender-diverse and LGBTQIA+ persons, NCII is often accompanied by personal and identifying details and captured or commodified in order to extort, threaten or inflict harm. First published at: https://www.takebackthetech.net/blog/non-consensual-intimate-imagery-overview ~ Deleted versions of this document This is a list of the previous (deleted) DOIs of this document. They were retracted on account of errors in formatting, layout, errors etc of this document. While no published version of this document has ever contained any factual errors, the ones listed here have been retracted. Hence, please do not refer to them and delete any copies you may have of these documents.~~ https://zenodo.org/doi/10.5281/zenodo.11655780 https://zenodo.org/records/12698227 https://zenodo.org/records/11656105 https://zenodo.org/records/10911462 https://zenodo.org/records/10893868 https://zenodo.org/records/10893867 https://zenodo.org/uploads/12277588},
  langid = {english},
  keywords = {⏳,GBV,Gender studies,gender-based violence,IBSA,image-based abuse,image-based sexual abuse,NCII,non-consensual intimate images,OGBV,Sexual violence,TFGBV,VAW},
  file = {/Users/sgraf/Zotero/storage/PT2ENE9C/Lakshané_2024_Non-consensual intimate imagery an overview.pdf}
}

@report{landesanstaltfürmediennrw2024,
  title = {Erfahrung von {{Kindern}} Und {{Jugendlichen}} Mit {{Sexting}} Und {{Pornos}} –~{{Zentrale Ergebnisse}} Der {{Befragung}}},
  author = {{Landesanstalt für Medien NRW}},
  date = {2024-09},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/F9TGXMPA/Landesanstalt für Medien NRW - 2024 - Erfahrung von Kindern und Jugendlichen mit Sexting.pdf}
}

@article{lapointe2025,
  title = {The {{Present}} and {{Future}} of {{Adult Entertainment}}: {{A Content Analysis}} of {{AI-Generated Pornography Websites}}},
  shorttitle = {The {{Present}} and {{Future}} of {{Adult Entertainment}}},
  author = {Lapointe, Valerie A. and Dubé, Simon and Rukhlyadyev, Sophia and Kessai, Tinhinane and Lafortune, David},
  date = {2025-03-03},
  journaltitle = {Archives of Sexual Behavior},
  shortjournal = {Arch Sex Behav},
  issn = {0004-0002, 1573-2800},
  doi = {10.1007/s10508-025-03099-1},
  url = {https://link.springer.com/10.1007/s10508-025-03099-1},
  urldate = {2025-06-03},
  langid = {english},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/K252F6BQ/Lapointe et al._2025_The Present and Future of Adult Entertainment A Content Analysis of AI-Generated Pornography Websit.pdf}
}

@article{leerssen2024,
  title = {Outside the Black Box: {{From}} Algorithmic Transparency to Platform Observability in the {{Digital Services Act}}},
  shorttitle = {Outside the {{Black Box}}},
  author = {Leerssen, Paddy},
  date = {2024},
  journaltitle = {Weizenbaum Journal of the Digital Society},
  volume = {4},
  number = {2},
  publisher = {Weizenbaum Institute},
  issn = {2748-5625},
  doi = {10.34669/WI.WJDS/4.2.3},
  url = {https://ojs.weizenbaum-institut.de/index.php/wjds/article/view/4_2_3},
  urldate = {2024-10-17},
  abstract = {Algorithmic transparency is high on the agenda for social media regulation. However, recent work in Science and Technology Studies questions whether this endeavor of “opening the black box” is feasible or even meaningful due to the sociotechnical contingency of platform behavior. To address these shortcomings, Bernhard Rieder and Jeannette Hoffman have proposed a move from algorithmic transparency to platform observability: a pragmatic and sociotechnical perspective aimed at securing structural, real-time access to the means of platform knowledge production. This paper applies the concept of observability to recent legislative developments in the EU’s new Digital Services Act. Reviewing that legislation’s transparency rules demonstrates how familiar algorithmic principles rules are starting to be complemented by innovative new observability policies and how these reflect revised understandings of transparency’s possible subjects, functions, and formats. This review also surfaces normative tensions in observability policy. In terms of substance, observability demands access to content but struggles to discern public from private discourses in semi-public social media channels. In terms of function, observability aims to act as a companion to regulation, but tensions arise between a broad concept of knowledge production and a narrow concept of regulatory compliance monitoring. In terms of format, observability’s drive for infrastructural and real-time access entails new API governance tradeoffs between, for example, scope and scalability. Along these lines, observability paves the way for a more constructive debate around platform data access laws and the dead ends of algorithmic transparency.},
  langid = {english},
  keywords = {✅,read},
  file = {/Users/sgraf/Zotero/storage/4P6MHDDB/Leerssen - 2024 - Outside the Black Box From Algorithmic Transparen.pdf}
}

@article{light2018a,
  title = {The Walkthrough Method: {{An}} Approach to the Study of Apps},
  shorttitle = {The Walkthrough Method},
  author = {Light, Ben and Burgess, Jean and Duguay, Stefanie},
  date = {2018-03},
  journaltitle = {New Media \& Society},
  volume = {20},
  number = {3},
  pages = {881--900},
  publisher = {SAGE Publications},
  issn = {1461-4448, 1461-7315},
  doi = {10.1177/1461444816675438},
  url = {https://journals.sagepub.com/doi/10.1177/1461444816675438},
  urldate = {2025-05-23},
  abstract = {Software applications (apps) are now prevalent in the digital media environment. They are the site of significant sociocultural and economic transformations across many domains, from health and relationships to entertainment and everyday finance. As relatively closed technical systems, apps pose new methodological challenges for sociocultural digital media research. This article describes a method, grounded in a combination of science and technology studies with cultural studies, through which researchers can perform a critical analysis of a given app. The method involves establishing an app’s environment of expected use by identifying and describing its vision, operating model and modes of governance. It then deploys a walkthrough technique to systematically and forensically step through the various stages of app registration and entry, everyday use and discontinuation of use. The walkthrough method establishes a foundational corpus of data upon which can be built a more detailed analysis of an app’s intended purpose, embedded cultural meanings and implied ideal users and uses. The walkthrough also serves as a foundation for further user-centred research that can identify how users resist these arrangements and appropriate app technology for their own purposes.},
  langid = {english},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/BC8B6KXW/Light et al._2018_The walkthrough method An approach to the study of apps.pdf}
}

@article{lord2020,
  title = {Pornhub: {{Opening}} the {{Floodgates}}?},
  shorttitle = {Pornhub},
  author = {Lord, Phil},
  date = {2020},
  journaltitle = {SSRN Electronic Journal},
  shortjournal = {SSRN Journal},
  issn = {1556-5068},
  doi = {10.2139/ssrn.3751640},
  url = {https://www.ssrn.com/abstract=3751640},
  urldate = {2025-08-17},
  langid = {english}
}

@inproceedings{macdonald2023,
  title = {The Algorithmic Moderation of Sexual Expression: {{Pornhub}}, Payment Processors and {{CSAM}}},
  shorttitle = {{{THE ALGORITHMIC MODERATION OF SEXUAL EXPRESSION}}},
  booktitle = {{{AoIR Selected Papers}} of {{Internet Research}}},
  author = {MacDonald, Maggie},
  date = {2023-12-31},
  doi = {10.5210/spir.v2023i0.13453},
  url = {https://spir.aoir.org/ojs/index.php/spir/article/view/13453},
  urldate = {2025-06-03},
  abstract = {Pornography platforms are increasingly required by payment processor business partners to mitigate harm in their content management systems through algorithmic moderation. Demands that adult merchants incorporate these tools are not proportional to instances of harmful content, but a response to the widespread conflation of pornography with harm and risk online. This paper explores co-governance by payment processors calling for algorithmic tools through the case of Pornhub, asking: what standards are required by financial firms, how are these enforced on platforms, and what effects does this arrangement have on porn content? I open with key context regarding the deplatforming of sex, antiporn campaigning and constructions of harm through 'reputational risk’. Following this, I detail financial firms infrastructural influence in platform co-governance. Next, a close reading of adult merchant terms identifies specific clauses calling for algorithmic moderation. Concluding this issue mapping, I provide a taxonomy of moderation tools in place on Pornhub. I close with an issue discussion to consider AI's positioning as a regulatory solution, CSAM data ethics, moderator labour, and the many technical problems obscured by promises of safety through automated content management systems. The resulting review of algorithmic measures enforced by financial firms offers a detailed case of the opaque governance conditions imperilling sexual expression across porn platforms.},
  keywords = {⏳},
  file = {/Users/sgraf/Zotero/storage/CNPTQLCI/MacDonald_2023_THE ALGORITHMIC MODERATION OF SEXUAL EXPRESSION PORNHUB, PAYMENT PROCESSORS AND CSAM.pdf}
}

@article{mackenzie2024,
  entrysubtype = {nonacademic},
  title = {Inside the Deepfake Porn Crisis Engulfing {{Korean}} Schools},
  author = {Mackenzie, Jean and Choi, Leehyun},
  date = {2024-09-03},
  journaltitle = {bbc.com},
  url = {https://www.bbc.com/news/articles/cpdlpj9zn9go},
  urldate = {2025-03-22},
  keywords = {❌}
}

@article{mackenzie2024a,
  entrysubtype = {nonacademic},
  title = {South {{Korea}} Faces Deepfake Porn 'Emergency'},
  author = {Mackenzie, Jean and Marsh, Nick},
  date = {2024-08-28},
  journaltitle = {bbc.com},
  url = {https://www.bbc.com/news/articles/cg4yerrg451o},
  urldate = {2025-03-22},
  file = {/Users/sgraf/Zotero/storage/XXM24NLA/Mackenzie und Marsh_South Korea faces deepfake porn 'emergency'.pdf}
}

@article{maddocks2018,
  title = {From {{Non-consensual Pornography}} to {{Image-based Sexual Abuse}}: {{Charting}} the {{Course}} of a {{Problem}} with {{Many Names}}},
  shorttitle = {From {{Non-consensual Pornography}} to {{Image-based Sexual Abuse}}},
  author = {Maddocks, Sophie},
  date = {2018-07-03},
  journaltitle = {Australian Feminist Studies},
  shortjournal = {Australian Feminist Studies},
  volume = {33},
  number = {97},
  pages = {345--361},
  issn = {0816-4649, 1465-3303},
  doi = {10.1080/08164649.2018.1542592},
  url = {https://www.tandfonline.com/doi/full/10.1080/08164649.2018.1542592},
  urldate = {2025-06-10},
  langid = {english},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/SNKAZB8G/Maddocks_2018_From Non-consensual Pornography to Image-based Sexual Abuse Charting the Course of a Problem with M.pdf}
}

@article{maddocks2020,
  title = {‘{{A Deepfake Porn Plot Intended}} to {{Silence Me}}’: Exploring Continuities between Pornographic and ‘Political’ Deep Fakes},
  shorttitle = {‘{{A Deepfake Porn Plot Intended}} to {{Silence Me}}’},
  author = {Maddocks, Sophie},
  date = {2020-10},
  journaltitle = {Porn Studies},
  shortjournal = {Porn Studies},
  volume = {7},
  number = {4},
  pages = {415--423},
  issn = {2326-8743, 2326-8751},
  doi = {10.1080/23268743.2020.1757499},
  url = {https://www.tandfonline.com/doi/full/10.1080/23268743.2020.1757499},
  urldate = {2025-06-03},
  langid = {english},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/3G3KVR7G/Maddocks_2020_‘A Deepfake Porn Plot Intended to Silence Me’ exploring continuities between pornographic and ‘poli.pdf}
}

@online{madio2025,
  title = {Asymmetric {{Content Moderation}} in {{Search Markets}}: {{The Case}} of {{Adult Websites}}},
  shorttitle = {Asymmetric {{Content Moderation}} in {{Search Markets}}},
  author = {Madio, Leonardo and Mitchell, Matthew F. and Quinn, Martin and Reggiani, Carlo},
  date = {2025},
  eprinttype = {SSRN},
  doi = {10.2139/ssrn.5106235},
  url = {https://www.ssrn.com/abstract=5106235},
  urldate = {2025-06-04},
  pubstate = {prepublished}
}

@article{maiberg2025,
  entrysubtype = {nonacademic},
  title = {Mr. {{Deepfakes}}, the {{Biggest Deepfake Porn Site}} on the {{Internet}}, {{Says It}}’s {{Shutting Down}} for {{Good}}},
  author = {Maiberg, Emanuel and Cole, Samantha},
  date = {2025-05-04},
  journaltitle = {404 Media},
  url = {https://www.404media.co/mr-deepfakes-the-biggest-deepfake-porn-site-on-the-internet-says-its-shutting-down-for-good/},
  keywords = {✅,❌}
}

@article{mania2020,
  title = {The {{Legal Implications}} and {{Remedies Concerning Revenge Porn}} and {{Fake Porn}}: {{A Common Law Perspective}}},
  shorttitle = {The {{Legal Implications}} and {{Remedies Concerning Revenge Porn}} and {{Fake Porn}}},
  author = {Mania, Karolina},
  date = {2020-12},
  journaltitle = {Sexuality \& Culture},
  shortjournal = {Sexuality \& Culture},
  volume = {24},
  number = {6},
  pages = {2079--2097},
  issn = {1095-5143, 1936-4822},
  doi = {10.1007/s12119-020-09738-0},
  url = {https://link.springer.com/10.1007/s12119-020-09738-0},
  urldate = {2024-09-09},
  abstract = {Abstract             Based on US and British regulations in force, this article offers an overview of legislation of two Common Law countries in the area of modern forms of law infringements focusing on the notions of revenge porn and fake porn. The first part contains definitions and descriptions of the terms ‘revenge porn’ and ‘fake porn’, pointing out to the context of the relationship between the dynamic technological development and use of artificial intelligence on the one hand and the regulatory framework failing to meet the current needs on the other. Further, examination is conducted of US and British legislation in force divided into civil and criminal law, indicating legislative gaps as well as the inefficiency of the existing legal solutions and presenting a range of proposals of legislative changes. The considerations have been supplemented with the results of the author’s assessment of sociological and statistical research available in source literature carried thus far in the field in question. The following section is dedicated to a comparative assessment of American and British legal solutions based on selected, critical issues. The final parts of the article serve to postulate systemic changes in legislation and is a proposal to introduce out-of-court dispute settlement methods in legal disputes pertaining to the matters discussed herein, and to~frame future research directions.},
  langid = {english},
  keywords = {✅,legal},
  file = {/Users/sgraf/Zotero/storage/KQHCHGX7/Mania - 2020 - The Legal Implications and Remedies Concerning Rev.pdf}
}

@article{mania2024,
  title = {Legal {{Protection}} of {{Revenge}} and {{Deepfake Porn Victims}} in the {{European Union}}: {{Findings From}} a {{Comparative Legal Study}}},
  shorttitle = {Legal {{Protection}} of {{Revenge}} and {{Deepfake Porn Victims}} in the {{European Union}}},
  author = {Mania, Karolina},
  date = {2024-01},
  journaltitle = {Trauma, Violence, \& Abuse},
  shortjournal = {Trauma, Violence, \& Abuse},
  volume = {25},
  number = {1},
  pages = {117--129},
  issn = {1524-8380, 1552-8324},
  doi = {10.1177/15248380221143772},
  url = {https://journals.sagepub.com/doi/10.1177/15248380221143772},
  urldate = {2025-08-03},
  abstract = {The use of images of persons in a pornographic context (without the prior consent of the person concerned) on the internet is an increasingly widespread infringement. Unlawful activities carried out with the use of generated images and artificial intelligence are a variant of this phenomenon. “Revenge porn” and “deepfake porn” illustrate the inadequacy of legal systems vis a vis the fast-changing reality. Using the comparative law method, a comparison was made between the current laws of nine EU Member States to create a map of protection for victims of revenge porn. As the results showed, in three of the studied countries there is a separate incrimination of revenge porn; however, the conceptual scope of its definition is significantly different and it is these differences that determine the legal way for the victims to assert their rights. This article is a comparison of the current legal regulations of selected European Union countries and the means of legal protection used by the victims. The text presents the differences occurring in the legal systems adopted in the countries subject to analysis, as well as an assessment of possible solutions at the legal and technological level to face the existing problem.},
  langid = {english},
  keywords = {⏳}
}

@article{maris2020,
  title = {Tracking Sex: {{The}} Implications of Widespread Sexual Data Leakage and Tracking on Porn Websites},
  shorttitle = {Tracking Sex},
  author = {Maris, Elena and Libert, Timothy and Henrichsen, Jennifer R},
  date = {2020-11},
  journaltitle = {New Media \& Society},
  shortjournal = {New Media \& Society},
  volume = {22},
  number = {11},
  pages = {2018--2038},
  issn = {1461-4448, 1461-7315},
  doi = {10.1177/1461444820924632},
  url = {https://journals.sagepub.com/doi/10.1177/1461444820924632},
  urldate = {2025-06-04},
  abstract = {This article explores tracking and privacy risks on pornography websites. Our analysis of 22,484 pornography websites indicated that 93\% leak user data to a third-party. Tracking on these sites is highly concentrated by a handful of major companies, which we identify. We successfully extracted privacy policies for 3856 sites, 17\% of the total. The policies were written such that one might need a 2-year college education to understand them. Our content analysis of the sample’s domains indicated 44.97\% of them expose or suggest a specific gender/sexual identity or interest likely to be linked to the user. We identify three core implications of the quantitative results: (1) the unique/elevated risks of porn data leakage versus other types of data, (2) the particular risks/impact for “vulnerable” populations, and (3) the complications of providing consent for porn site users and the need for affirmative consent in these online sexual interactions.},
  langid = {english},
  file = {/Users/sgraf/Zotero/storage/Z8ZEQ33S/Maris et al._2020_Tracking sex The implications of widespread sexual data leakage and tracking on porn websites.pdf}
}

@article{mast2024a,
  title = {Forschungsdatenzugang und Technologieregulierung},
  author = {Mast, Tobias},
  date = {2024},
  journaltitle = {Wissenschaftsrecht},
  shortjournal = {WissR},
  volume = {57},
  number = {2},
  pages = {101},
  issn = {0948-0218},
  doi = {10.1628/wissr-2024-0011},
  url = {https://www.mohrsiebeck.com/10.1628/wissr-2024-0011},
  urldate = {2025-01-06},
  langid = {ngerman},
  keywords = {⏳,❌}
}

@article{mccosker2024,
  title = {Making Sense of Deepfakes: {{Socializing AI}} and Building Data Literacy on {{GitHub}} and {{YouTube}}},
  shorttitle = {Making Sense of Deepfakes},
  author = {McCosker, Anthony},
  date = {2024-05},
  journaltitle = {New Media \& Society},
  shortjournal = {New Media \& Society},
  volume = {26},
  number = {5},
  pages = {2786--2803},
  issn = {1461-4448, 1461-7315},
  doi = {10.1177/14614448221093943},
  url = {https://journals.sagepub.com/doi/10.1177/14614448221093943},
  urldate = {2025-06-04},
  abstract = {As a form of synthetic media built on the Internet’s extensive visual datasets with evolving machine learning techniques, deepfakes raise the specter of new types of informational harms and possibilities for image-based abuse. There are calls for three types of defensive response: regulation, technical controls, and improved digital or media literacy. Each is problematic by itself. This article asks what kind of literacy can address deepfake harms, proposing an artificial intelligence (AI) and data literacy framework to explore the potential for social learning with deepfakes and identify sites and methods for intervening in their cultures of production. The article applies contextual qualitative content analysis to explore the most popular GitHub repositories and YouTube accounts teaching “how to deepfake.” The analysis shows that these sites contribute to socializing AI and establishing cultures of social learning, offering potential sites of intervention and pointing to new methods for addressing AI and data harms.},
  langid = {english},
  keywords = {⏳},
  file = {/Users/sgraf/Zotero/storage/G856FZF4/McCosker_2024_Making sense of deepfakes Socializing AI and building data literacy on GitHub and YouTube.pdf}
}

@article{mcglynn2017a,
  title = {Image-Based Sexual Abuse},
  author = {McGlynn, Clare and Rackley, Erika},
  date = {2017},
  journaltitle = {Oxford Journal of Legal Studies},
  volume = {37},
  number = {3},
  pages = {534--561},
  issn = {0143-6503, 1464-3820},
  doi = {10.1093/ojls/gqw033},
  url = {http://academic.oup.com/ojls/article/37/3/534/2965256/ImageBased-Sexual-Abuse},
  urldate = {2024-09-19},
  langid = {english},
  keywords = {⏳,unread},
  file = {/Users/sgraf/Zotero/storage/5YTTTH72/McGlynn und Rackley_2017_Image-Based Sexual Abuse.pdf}
}

@article{mcglynn2017b,
  title = {Beyond ‘{{Revenge Porn}}’: {{The Continuum}} of {{Image-Based Sexual Abuse}}},
  shorttitle = {Beyond ‘{{Revenge Porn}}’},
  author = {McGlynn, Clare and Rackley, Erika and Houghton, Ruth},
  date = {2017-04},
  journaltitle = {Feminist Legal Studies},
  shortjournal = {Fem Leg Stud},
  volume = {25},
  number = {1},
  pages = {25--46},
  issn = {0966-3622, 1572-8455},
  doi = {10.1007/s10691-017-9343-2},
  url = {http://link.springer.com/10.1007/s10691-017-9343-2},
  urldate = {2025-06-12},
  langid = {english},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/8I8WFC6B/McGlynn et al._2017_Beyond ‘Revenge Porn’ The Continuum of Image-Based Sexual Abuse.pdf}
}

@article{mckee2022,
  title = {Pornhub, Child Sexual Abuse Materials and Anti-Pornography Campaigning},
  author = {McKee, Alan and Lumby, Catharine},
  date = {2022-10-02},
  journaltitle = {Porn Studies},
  shortjournal = {Porn Studies},
  volume = {9},
  number = {4},
  pages = {464--476},
  issn = {2326-8743, 2326-8751},
  doi = {10.1080/23268743.2022.2083662},
  url = {https://www.tandfonline.com/doi/full/10.1080/23268743.2022.2083662},
  urldate = {2025-08-17},
  langid = {english},
  keywords = {⏳}
}

@article{miller2023,
  title = {{{AI Hyperrealism}}: {{Why AI Faces Are Perceived}} as {{More Real Than Human Ones}}},
  shorttitle = {{{AI Hyperrealism}}},
  author = {Miller, Elizabeth J. and Steward, Ben A. and Witkower, Zak and Sutherland, Clare A. M. and Krumhuber, Eva G. and Dawel, Amy},
  date = {2023-12},
  journaltitle = {Psychological Science},
  shortjournal = {Psychol Sci},
  volume = {34},
  number = {12},
  pages = {1390--1403},
  issn = {0956-7976, 1467-9280},
  doi = {10.1177/09567976231207095},
  url = {https://journals.sagepub.com/doi/10.1177/09567976231207095},
  urldate = {2025-07-04},
  abstract = {Recent evidence shows that AI-generated faces are now indistinguishable from human faces. However, algorithms are trained disproportionately on White faces, and thus White AI faces may appear especially realistic. In Experiment 1 ( N = 124 adults), alongside our reanalysis of previously published data, we showed that White AI faces are judged as human more often than actual human faces—a phenomenon we term AI hyperrealism. Paradoxically, people who made the most errors in this task were the most confident (a Dunning-Kruger effect). In Experiment 2 ( N = 610 adults), we used face-space theory and participant qualitative reports to identify key facial attributes that distinguish AI from human faces but were misinterpreted by participants, leading to AI hyperrealism. However, the attributes permitted high accuracy using machine learning. These findings illustrate how psychological theory can inform understanding of AI outputs and provide direction for debiasing AI algorithms, thereby promoting the ethical use of AI.},
  langid = {english},
  file = {/Users/sgraf/Zotero/storage/ZQVDMWGU/Miller et al._2023_AI Hyperrealism Why AI Faces Are Perceived as More Real Than Human Ones.pdf}
}

@book{mraz1998,
  title = {Elisabeth: {{Prinzessin}} in {{Bayern}}, {{Kaiserin}} von {{Österreich}}, {{Königin}} von {{Ungarn}}: {{Wunschbilder}} Oder Die {{Kunst}} Der {{Retouche}}},
  shorttitle = {Elisabeth},
  author = {Mraz, Gerda and Fischer-Westhauser, Ulla},
  date = {1998},
  edition = {1. Aufl},
  publisher = {Brandstätter},
  location = {Wien},
  isbn = {978-3-85447-774-7},
  pagetotal = {159},
  keywords = {✅,❌,Austria,Biography Pictorial works,Elisabeth,Empresses,Pictorial works}
}

@article{newton2020,
  title = {My {{NSFW}} Video Has Partial Occlusion: Deepfakes and the Technological Production of Non-Consensual Pornography},
  shorttitle = {My {{NSFW}} Video Has Partial Occlusion},
  author = {Newton, Olivia B. and Stanfill, Mel},
  date = {2020-10},
  journaltitle = {Porn Studies},
  shortjournal = {Porn Studies},
  volume = {7},
  number = {4},
  pages = {398--414},
  issn = {2326-8743, 2326-8751},
  doi = {10.1080/23268743.2019.1675091},
  url = {https://www.tandfonline.com/doi/full/10.1080/23268743.2019.1675091},
  urldate = {2025-06-03},
  langid = {english},
  keywords = {⏳,production},
  file = {/Users/sgraf/Zotero/storage/62NMPQTQ/Newton und Stanfill_2020_My NSFW video has partial occlusion deepfakes and the technological production of non-consensual po.pdf}
}

@incollection{ortolani2025,
  title = {Generative {{AI}} and {{Content Moderation}}},
  booktitle = {The {{Oxford Handbook}} of the {{Foundations}} and {{Regulation}} of {{Generative AI}}},
  author = {Ortolani, Pietro},
  editor = {Hacker, Philipp and Mittelstadt, Brent and Hammer, Sarah and Engel, Andreas},
  date = {2025-04-22},
  edition = {1},
  publisher = {Oxford University Press},
  doi = {10.1093/oxfordhb/9780198940272.013.0020},
  url = {https://academic.oup.com/edited-volume/59908/chapter/512463151},
  urldate = {2025-05-20},
  abstract = {Abstract             The chapter investigates the interplay between Generative AI (GenAI) and content moderation. It addresses both the moderation of content created through GenAI and the use of GenAI in content moderation processes. The chapter argues that the rise of GenAI poses certain challenges to the current content moderation framework, which has been mainly developed with an eye to user-generated content. At the same time, GenAI also has the potential to improve certain aspects of content moderation, such as the drafting of text explaining the rationale of content moderation decisions. The chapter advocates for an increased focus on the human–machine interaction: rather than replacing human decision-making, GenAI should be used to support humans in content moderation decision-making.},
  isbn = {978-0-19-894027-2 978-0-19-894030-2},
  langid = {english},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/ALM5FJSC/Ortolani_2025_Generative AI and Content Moderation.pdf}
}

@report{oversightboard2024,
  type = {Multiple case decision},
  title = {Explicit {{AI}} Images of Female Public Figures},
  author = {{Oversight Board}},
  date = {2024-07-25},
  institution = {Meta Oversight Board},
  url = {https://www.oversightboard.com/decision/bun-7e941o1n/},
  keywords = {⏳},
  file = {/Users/sgraf/Zotero/storage/S5NK576Z/Oversight Board_.pdf}
}

@article{paradiso2024,
  title = {Image-{{Based Sexual Abuse Associated Factors}}: {{A Systematic Review}}},
  shorttitle = {Image-{{Based Sexual Abuse Associated Factors}}},
  author = {Paradiso, Maria Noemi and Rollè, Luca and Trombetta, Tommaso},
  date = {2024-07},
  journaltitle = {Journal of Family Violence},
  shortjournal = {J Fam Viol},
  volume = {39},
  number = {5},
  pages = {931--954},
  issn = {0885-7482, 1573-2851},
  doi = {10.1007/s10896-023-00557-z},
  url = {https://link.springer.com/10.1007/s10896-023-00557-z},
  urldate = {2024-09-19},
  abstract = {Abstract                            Purpose               Image-Based Sexual Abuse (IBSA) is a recently studied form of violence and abuse perpetrated using technology. This systematic review aims to examine and systematize studies exploring factors associated with IBSA (e.g., victimization, perpetration, and propensity to perpetrate).                                         Method               Following the Preferred Reporting Items for Systematic Review and Meta-Analysis (PRISMA) statement, 17 articles were included.                                         Results               The results of this study highlighted conceptual and methodological limitations in the literature on IBSA. Aside from these limitations, this systematic review identified factors associated with IBSA, focusing on four macro-areas: victimization, perpetration, propensity to perpetrate IBSA, and IBSA implications. The results demonstrated the role of psychological, relational, and social variables, although the effect sizes observed in the quantitative studies were small or in few cases moderate.                                         Conclusions               These results suggest further research should be carried out to explore the multidimensionality of IBSA and its associated factors, which may assist in guiding interventions to promote preventive and rehabilitative methods to lower the prevalence of this crime and its consequences.},
  langid = {english},
  keywords = {✅,❌},
  file = {/Users/sgraf/Zotero/storage/YYFRWRBF/Paradiso et al. - 2024 - Image-Based Sexual Abuse Associated Factors A Systematic Review.pdf}
}

@article{petit2025,
  title = {The Limits of ‘Zero Tolerance’ Policies for Animated Pornographic Media},
  author = {Petit, Aurélie},
  date = {2025-05-28},
  journaltitle = {Porn Studies},
  shortjournal = {Porn Studies},
  pages = {1--18},
  issn = {2326-8743, 2326-8751},
  doi = {10.1080/23268743.2025.2491506},
  url = {https://www.tandfonline.com/doi/full/10.1080/23268743.2025.2491506},
  urldate = {2025-06-05},
  langid = {english}
}

@article{podsakoff2016,
  title = {Recommendations for {{Creating Better Concept Definitions}} in the {{Organizational}}, {{Behavioral}}, and {{Social Sciences}}},
  author = {Podsakoff, Philip M. and MacKenzie, Scott B. and Podsakoff, Nathan P.},
  date = {2016-04},
  journaltitle = {Organizational Research Methods},
  shortjournal = {Organizational Research Methods},
  volume = {19},
  number = {2},
  pages = {159--203},
  issn = {1094-4281, 1552-7425},
  doi = {10.1177/1094428115624965},
  url = {https://journals.sagepub.com/doi/10.1177/1094428115624965},
  urldate = {2025-06-11},
  abstract = {Despite the importance of establishing good, clear concept definitions in organizational research, the field lacks a comprehensive source that explains how to effectively develop and articulate a concept’s domain. Thus, the purpose of this article is to explain why clear conceptual definitions are essential for scientific progress and provide a concrete set of steps that researchers can follow to improve their conceptual definitions. First, we define what is meant by a concept, describe the functions served by concepts in scientific endeavors, and identify problems associated with a lack of conceptual clarity. Then we explain why it is so difficult to adequately define concepts. Next, we provide a series of recommendations for scholars in the organizational, behavioral, and social sciences who are either trying to define a new concept or revise the definition of one that already exists in the field. Following this, we provide some examples that generally meet the criteria for a good conceptual definition. We conclude with a set of questions that authors, reviewers, and editors can use as a guide for evaluating concept definitions.},
  langid = {english},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/JV5833FT/Podsakoff et al._2016_Recommendations for Creating Better Concept Definitions in the Organizational, Behavioral, and Socia.pdf}
}

@article{popova2020,
  title = {Reading out of Context: Pornographic Deepfakes, Celebrity and Intimacy},
  shorttitle = {Reading out of Context},
  author = {Popova, Milena},
  date = {2020-10},
  journaltitle = {Porn Studies},
  shortjournal = {Porn Studies},
  volume = {7},
  number = {4},
  pages = {367--381},
  issn = {2326-8743, 2326-8751},
  doi = {10.1080/23268743.2019.1675090},
  url = {https://www.tandfonline.com/doi/full/10.1080/23268743.2019.1675090},
  urldate = {2025-07-02},
  langid = {english},
  keywords = {⏳},
  file = {/Users/sgraf/Zotero/storage/ZXJ8V5MG/Popova_2020_Reading out of context pornographic deepfakes, celebrity and intimacy.pdf}
}

@online{pornhub,
  title = {Our Commitment to {{Trust}} and {{Safety}}},
  author = {{Pornhub}},
  url = {https://help.pornhub.com/hc/en-us/categories/4419836212499},
  urldate = {2025-08-07},
  keywords = {✅}
}

@online{pornhub.com2019,
  title = {The 2019 {{Year}} in {{Review}}},
  author = {{pornhub.com}},
  date = {2019},
  url = {https://www.pornhub.com/insights/2019-year-in-review#celebrity},
  organization = {Pornhub Insights},
  keywords = {✅}
}

@report{pornhubhelp,
  type = {report},
  title = {2024 {{Transparency Report}} (Second Half)},
  author = {{Pornhub Help}},
  number = {July 1, 2024 -- December 31, 2024},
  institution = {Aylo},
  url = {https://help.pornhub.com/hc/en-us/articles/38743689517715-2024-Transparency-Report-Second-Half},
  urldate = {2025-08-14},
  keywords = {✅}
}

@online{pornhubhelp2024,
  title = {Non-{{Consensual Content Policy}}},
  author = {{Pornhub Help}},
  date = {2024-09},
  url = {https://help.pornhub.com/hc/en-us/articles/4419871787027-Non-Consensual-Content-Policy},
  urldate = {2025-08-14},
  organization = {Pornhub Help Center},
  keywords = {✅}
}

@online{pornhubhelp2024a,
  title = {Child {{Sexual Abuse Material Policy}}},
  author = {{Pornhub Help}},
  date = {2024-09},
  url = {https://help.pornhub.com/hc/en-us/articles/4419869793683-Child-Sexual-Abuse-Material-Policy},
  urldate = {2025-08-14},
  organization = {Pornhub Help Center},
  keywords = {✅}
}

@online{pornhubhelp2025,
  title = {Community {{Guidelines}}},
  author = {{Pornhub Help}},
  date = {2025-08},
  url = {https://help.pornhub.com/hc/en-us/articles/4419900587155-Community-Guidelines},
  urldate = {2025-08-14},
  organization = {Pornhub Help Center},
  keywords = {✅}
}

@report{pornhubhelpa,
  type = {report},
  title = {2020 {{Transparency Report}}},
  author = {{Pornhub Help}},
  institution = {Pornhub},
  url = {https://help.pornhub.com/hc/en-us/articles/4419860718483-2020-Transparency-Report},
  urldate = {2025-08-14},
  keywords = {✅}
}

@report{pornhubhelpb,
  type = {report},
  title = {2021 {{Transparency Report}}},
  author = {{Pornhub Help}},
  institution = {Pornhub},
  url = {https://help.pornhub.com/hc/en-us/articles/5357457259155-2021-Transparency-Report},
  urldate = {2025-08-14},
  keywords = {✅}
}

@online{pornhubhelpc,
  title = {Pornhub {{Trusted Flagger Program}}},
  author = {{Pornhub Help}},
  url = {https://help.pornhub.com/hc/en-us/articles/4419879221907-Pornhub-Trusted-Flagger-Program},
  urldate = {2025-08-07},
  organization = {Pornhub Help Center},
  keywords = {✅}
}

@online{qiwei2024,
  title = {Reporting {{Non-Consensual Intimate Media}}: {{An Audit Study}} of {{Deepfakes}}},
  author = {Qiwei, Li and Zhang, Shihui and Kasper, Andrew T. and Ashkinaze, Joshua and Eaton, Asia A. and Schoenebeck, Sarita and Gilbert, Eric},
  date = {2024},
  eprint = {2409.12138},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.2409.12138},
  pubstate = {prepublished},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/IEYEY5HB/Reporting Non-Consensual Intimate Media An Audit .pdf}
}

@article{rama2023,
  title = {The Platformization of Gender and Sexual Identities: An Algorithmic Analysis of {{Pornhub}}},
  shorttitle = {The Platformization of Gender and Sexual Identities},
  author = {Rama, Ilir and Bainotti, Lucia and Gandini, Alessandro and Giorgi, Giulia and Semenzin, Silvia and Agosti, Claudio and Corona, Giulia and Romano, Salvatore},
  date = {2023-04-03},
  journaltitle = {Porn Studies},
  shortjournal = {Porn Studies},
  volume = {10},
  number = {2},
  pages = {154--173},
  issn = {2326-8743, 2326-8751},
  doi = {10.1080/23268743.2022.2066566},
  url = {https://www.tandfonline.com/doi/full/10.1080/23268743.2022.2066566},
  urldate = {2025-03-05},
  langid = {english},
  keywords = {⏳},
  file = {/Users/sgraf/Zotero/storage/3W7TTWRI/Rama et al._2023_The platformization of gender and sexual identities an algorithmic analysis of Pornhub.pdf}
}

@article{rieder2020b,
  title = {Towards Platform Observability},
  author = {Rieder, Bernhard and Hofmann, Jeanette},
  date = {2020-12-18},
  journaltitle = {Internet Policy Review},
  volume = {9},
  number = {4},
  issn = {2197-6775},
  doi = {10.14763/2020.4.1535},
  url = {https://policyreview.info/articles/analysis/towards-platform-observability},
  urldate = {2024-11-24},
  langid = {english},
  keywords = {⏳},
  file = {/Users/sgraf/Zotero/storage/R8JDL94F/Rieder und Hofmann - 2020 - Towards platform observability.pdf}
}

@article{risius2024,
  title = {Shadowbanning: {{An Opaque Form}} of {{Content Moderation}}},
  shorttitle = {Shadowbanning},
  author = {Risius, Marten and Blasiak, Kevin Marc},
  date = {2024-12},
  journaltitle = {Business \& Information Systems Engineering},
  shortjournal = {Bus Inf Syst Eng},
  volume = {66},
  number = {6},
  pages = {817--829},
  publisher = {{Springer Science and Business Media LLC}},
  issn = {2363-7005, 1867-0202},
  doi = {10.1007/s12599-024-00905-3},
  url = {https://link.springer.com/10.1007/s12599-024-00905-3},
  urldate = {2025-07-18},
  langid = {english},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/8SLMIKEU/Risius und Blasiak_2024_Shadowbanning An Opaque Form of Content Moderation.pdf}
}

@incollection{roberts2017,
  title = {Content {{Moderation}}},
  booktitle = {Encyclopedia of {{Big Data}}},
  author = {Roberts, Sarah T.},
  editor = {Schintler, Laurie A. and McNeely, Connie L.},
  date = {2017},
  pages = {1--4},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-319-32001-4_44-1},
  url = {http://link.springer.com/10.1007/978-3-319-32001-4_44-1},
  urldate = {2025-03-05},
  isbn = {978-3-319-32001-4},
  langid = {english},
  keywords = {⏳,❌}
}

@article{roberts2018,
  title = {Digital Detritus: '{{Error}}' and the Logic of Opacity in Social Media Content Moderation},
  shorttitle = {Digital Detritus},
  author = {Roberts, Sarah T.},
  date = {2018-03-01},
  journaltitle = {First Monday},
  shortjournal = {FM},
  issn = {1396-0466},
  doi = {10.5210/fm.v23i3.8283},
  url = {https://www.firstmonday.org/ojs/index.php/fm/article/view/8283},
  urldate = {2025-04-01},
  abstract = {The late 2016 case of the Facebook content moderation controversy over the infamous Vietnam-era photo, “The Terror of War,” is examined in this paper for both its specifics, as well as a mechanism to engage in a larger discussion of the politics and economics of the content moderation of user-generated content. In the context of mainstream commercial social media platforms, obfuscation and secrecy work together to form an operating logic of opacity, a term and concept introduced in this paper. The lack of clarity around platform policies, procedures and the values that inform them lead users to wildly different interpretations of the user experience on the same site, resulting in confusion in no small part by the platforms’ own design. Platforms operationalize their content moderation practices under a complex web of nebulous rules and procedural opacity, while governments and other actors clamor for tighter controls on some material, and other members of civil society demand greater freedoms for online expression. Few parties acknowledge the fact that mainstream social media platforms are already highly regulated, albeit rarely in such a way that can be satisfactory to all. The final turn in the paper connects the functions of the commercial content moderation process on social media platforms like Facebook to their output, being either the content that appears on a site, or content that is rescinded: digital detritus. While meaning and intent of user-generated content may often be imagined to be the most important factors by which content is evaluated for a site, this paper argues that its value to the platform as a potentially revenue-generating commodity is actually the key criterion and the one to which all moderation decisions are ultimately reduced. The result is commercialized online spaces that have far less to offer in terms of political and democratic challenge to the status quo and which, in fact, may serve to reify and consolidate power rather than confront it.},
  keywords = {❌}
}

@incollection{roberts2019,
  title = {Understanding Commercial Content Moderation},
  booktitle = {Behind the Screen : {{Content}} Moderation in the Shadows of Social Media},
  author = {Roberts, Sarah T.},
  date = {2019},
  pages = {33--72},
  publisher = {Yale University Press},
  keywords = {⏳},
  file = {/Users/sgraf/Zotero/storage/IKEKL3BX/Behind_the_Screen_Content_Moderation_in_the_Shadow..._----_(TWO._Understanding_Commercial_Content_Moderation).pdf}
}

@article{romeromoreno2024,
  title = {Generative {{AI}} and Deepfakes: A Human Rights Approach to Tackling Harmful Content},
  shorttitle = {Generative {{AI}} and Deepfakes},
  author = {Romero Moreno, Felipe},
  date = {2024-09},
  journaltitle = {International Review of Law, Computers \& Technology},
  shortjournal = {International Review of Law, Computers \& Technology},
  volume = {38},
  number = {3},
  pages = {297--326},
  issn = {1360-0869, 1364-6885},
  doi = {10.1080/13600869.2024.2324540},
  url = {https://www.tandfonline.com/doi/full/10.1080/13600869.2024.2324540},
  urldate = {2025-06-03},
  langid = {english},
  keywords = {⏳,legal},
  file = {/Users/sgraf/Zotero/storage/RWGBN5SL/Romero Moreno_2024_Generative AI and deepfakes a human rights approach to tackling harmful content.pdf}
}

@article{sanders2025,
  title = {Non-Consensual Sharing of Images: {{Commercial}} Content Creators, Sexual Content Creation Platforms and the Lack of Protection},
  shorttitle = {Non-Consensual Sharing of Images},
  author = {Sanders, Teela and Trueman, Gaynor and Worthington, Kate and Keighley, Rachel},
  date = {2025-01},
  journaltitle = {New Media \& Society},
  shortjournal = {New Media \& Society},
  volume = {27},
  number = {1},
  pages = {84--105},
  issn = {1461-4448, 1461-7315},
  doi = {10.1177/14614448231172711},
  url = {https://journals.sagepub.com/doi/10.1177/14614448231172711},
  urldate = {2025-06-04},
  abstract = {In this article, we explore the experiences of commercial content creators who have their content (videos, photos, and images) misused. This article reports from a mixed-methods study consisting of 16 interviews with content creators; nine interviews with practitioners who support sex workers and interviews with seven adult service website (ASW) operators. These qualitative data are supported by 221 responses to a survey from the content creators’ community. We describe how content creators experience blackmail, threats of exposure and recording without knowledge, stalking, harassment, doxing, ‘deepfakes’ and impersonation. We conclude that the online sex work environment may not be as safe as previous research has demonstrated, and that commercial content creators are often ignored by governance and platforms following sex workers’ complaints regarding their content being misused. We reflect on the forthcoming UK Online Safety Bill as compared to the US Stop Enabling Sex Traffickers Act/Fight Online Sex Trafficking Act (SESTA/FOSTA) law which have seen implications across the globe for digital sex workers. We offer solutions for ASWs to act more responsibly.},
  langid = {english},
  file = {/Users/sgraf/Zotero/storage/YYAMHXGD/Sanders et al._2025_Non-consensual sharing of images Commercial content creators, sexual content creation platforms and.pdf}
}

@article{saner2024,
  entrysubtype = {nonacademic},
  title = {Inside the {{Taylor Swift}} Deepfake Scandal: ‘{{It}}’s Men Telling a Powerful Woman to Get Back in Her Box’},
  author = {Saner, Emine},
  date = {2024-01-31},
  journaltitle = {theguardian.com},
  url = {https://www.theguardian.com/technology/2024/jan/31/inside-the-taylor-swift-deepfake-scandal-its-men-telling-a-powerful-woman-to-get-back-in-her-box},
  urldate = {2025-03-21},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/8VX3DYNE/Saner_2024_Inside the Taylor Swift deepfake scandal ‘It’s men telling a powerful woman to get back in her box’.pdf}
}

@article{schaffner2024,
  title = {"{{Community Guidelines Make}} This the {{Best Party}} on the {{Internet}}": {{An In-Depth Study}} of {{Online Platforms}}' {{Content Moderation Policies}}},
  shorttitle = {"{{Community Guidelines Make}} This the {{Best Party}} on the {{Internet}}"},
  author = {Schaffner, Brennan and Bhagoji, Arjun Nitin and Cheng, Siyuan and Mei, Jacqueline and Shen, Jay L. and Wang, Grace and Chetty, Marshini and Feamster, Nick and Lakier, Genevieve and Tan, Chenhao},
  date = {2024},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.2405.05225},
  url = {https://arxiv.org/abs/2405.05225},
  urldate = {2025-07-23},
  abstract = {Moderating user-generated content on online platforms is crucial for balancing user safety and freedom of speech. Particularly in the United States, platforms are not subject to legal constraints prescribing permissible content. Each platform has thus developed bespoke content moderation policies, but there is little work towards a comparative understanding of these policies across platforms and topics. This paper presents the first systematic study of these policies from the 43 largest online platforms hosting user-generated content, focusing on policies around copyright infringement, harmful speech, and misleading content. We build a custom web-scraper to obtain policy text and develop a unified annotation scheme to analyze the text for the presence of critical components. We find significant structural and compositional variation in policies across topics and platforms, with some variation attributable to disparate legal groundings. We lay the groundwork for future studies of ever-evolving content moderation policies and their impact on users.},
  version = {1},
  keywords = {⏳,FOS: Computer and information sciences,Human-Computer Interaction (cs.HC),Social and Information Networks (cs.SI)},
  file = {/Users/sgraf/Zotero/storage/7HDV82FW/Schaffner et al._2024_Community Guidelines Make this the Best Party on the Internet An In-Depth Study of Online Platfor.pdf}
}

@report{seiling2024,
  title = {Response to the {{Consultation}} on the {{Delegated Regulation}} on {{Data Access}} Provided for in the {{Digital Services Act}}},
  author = {Seiling, Lukas and Ohme, Jakob and Klinger, Ulrike},
  date = {2024},
  institution = {Weizenbaum Institute},
  issn = {2940-8490},
  doi = {10.34669/WI.PP/11},
  url = {https://www.weizenbaum-library.de/handle/id/762},
  urldate = {2025-01-16},
  abstract = {This response provides feedback on the Delegated Regulation on Data Access provided for in the Digital Services Act. It is informed by a variety of exchanges with empirical platform researchers across Germany and Europe. The first section highlights clarifications and proposed procedures for non-public data access which are practical, workable or welcomed by scientists for other reasons. The second section outlines further opportunities for clarification, additions, or modifications to the draft text, particularly regarding the data access procedure, the data access portal, the types of data, as well as the documentation and modalities of data access.},
  langid = {english},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/GICDNC6T/Seiling et al._2024_Response to the Consultation on the Delegated Regulation on Data Access provided for in the Digital.pdf}
}

@article{semenzin2020,
  title = {The {{Use}} of {{Telegram}} for {{Non-Consensual Dissemination}} of {{Intimate Images}}: {{Gendered Affordances}} and the {{Construction}} of {{Masculinities}}},
  shorttitle = {The {{Use}} of {{Telegram}} for {{Non-Consensual Dissemination}} of {{Intimate Images}}},
  author = {Semenzin, Silvia and Bainotti, Lucia},
  date = {2020-10},
  journaltitle = {Social Media + Society},
  shortjournal = {Social Media + Society},
  volume = {6},
  number = {4},
  pages = {2056305120984453},
  issn = {2056-3051, 2056-3051},
  doi = {10.1177/2056305120984453},
  url = {https://journals.sagepub.com/doi/10.1177/2056305120984453},
  urldate = {2025-06-04},
  abstract = {This article analyses the role of Telegram in orienting, amplifying, and normalizing the non-consensual diffusion of intimate images (NCII). We focus on the sense of anonymity, the platform’s weak regulation, and the possibility of creating large male communities, arguing that these affordances are “gendered affordances” as they orient male participants’ harassment behaviors and, in concert with an established misogynist culture, contribute to the reinstatement of hegemonic masculinity. The research draws on data collected through an online covert ethnography of Italian Telegram channels and groups.},
  langid = {english},
  keywords = {⏳,Distribution},
  file = {/Users/sgraf/Zotero/storage/IQJNWNLX/Semenzin und Bainotti_2020_The Use of Telegram for Non-Consensual Dissemination of Intimate Images Gendered Affordances and th.pdf}
}

@online{similarweb2025,
  title = {Top Websites Ranking - Most Visited Websites in the World},
  author = {{Similarweb}},
  date = {2025-08},
  url = {https://www.similarweb.com/top-websites/},
  urldate = {2025-08-12},
  organization = {similarweb.com},
  keywords = {✅}
}

@online{sippy2024,
  title = {Behind the {{Deepfake}}: 8\% {{Create}}; 90\% {{Concerned}}. {{Surveying}} Public Exposure to and Perceptions of Deepfakes in the {{UK}}},
  shorttitle = {Behind the {{Deepfake}}},
  author = {Sippy, Tvesha and Enock, Florence and Bright, Jonathan and Margetts, Helen Z.},
  date = {2024},
  doi = {10.48550/ARXIV.2407.05529},
  url = {https://arxiv.org/abs/2407.05529},
  urldate = {2025-08-03},
  abstract = {This article examines public exposure to and perceptions of deepfakes based on insights from a nationally representative survey of 1403 UK adults. The survey is one of the first of its kind since recent improvements in deepfake technology and widespread adoption of political deepfakes. The findings reveal three key insights. First, on average, 15\% of people report exposure to harmful deepfakes, including deepfake pornography, deepfake frauds/scams and other potentially harmful deepfakes such as those that spread health/religious misinformation/propaganda. In terms of common targets, exposure to deepfakes featuring celebrities was 50.2\%, whereas those featuring politicians was 34.1\%. And 5.7\% of respondents recall exposure to a selection of high profile political deepfakes in the UK. Second, while exposure to harmful deepfakes was relatively low, awareness of and fears about deepfakes were high (and women were significantly more likely to report experiencing such fears than men). As with fears, general concerns about the spread of deepfakes were also high; 90.4\% of the respondents were either very concerned or somewhat concerned about this issue. Most respondents (at least 91.8\%) were concerned that deepfakes could add to online child sexual abuse material, increase distrust in information and manipulate public opinion. Third, while awareness about deepfakes was high, usage of deepfake tools was relatively low (8\%). Most respondents were not confident about their detection abilities and were trustful of audiovisual content online. Our work highlights how the problem of deepfakes has become embedded in public consciousness in just a few years; it also highlights the need for media literacy programmes and other policy interventions to address the spread of harmful deepfakes.},
  pubstate = {prepublished},
  version = {1},
  keywords = {⏳,Computers and Society (cs.CY),FOS: Computer and information sciences},
  file = {/Users/sgraf/Zotero/storage/YA2LXUVE/Sippy et al._2024_Behind the Deepfake 8% Create; 90% Concerned. Surveying public exposure to and perceptions of deepf.pdf}
}

@article{sorbán2023,
  title = {An Elephant in the Room—{{EU}} Policy Gaps in the Regulation of Moderating Illegal Sexual Content on Video-Sharing Platforms},
  author = {Sorbán, Kinga},
  date = {2023-11-28},
  journaltitle = {International Journal of Law and Information Technology},
  volume = {31},
  number = {3},
  pages = {171--185},
  issn = {0967-0769, 1464-3693},
  doi = {10.1093/ijlit/eaad024},
  url = {https://academic.oup.com/ijlit/article/31/3/171/7273696},
  urldate = {2024-09-09},
  abstract = {Abstract             With the availability of broadband internet and a significant increase in storage capacity, people are sharing a dynamically growing amount of multimedia content on video-sharing platforms, including sexually explicit content. While sexual content on the internet is not illegal per se and remains in the domain of economic services, there are certain forms of sexually explicit content that are criminally unlawful, such as child pornography or non-consensual pornography. This article explores why the current business-oriented regulatory environment fails to provide effective tools to combat illegal sexual content: first, from the perspective of content moderation on video-sharing platforms, and then from the perspective of substantive criminal law. After mapping the gaps in policy at all levels of content regulation, the article offers recommendations to address these issues, open up a policy debate and influence policy makers.},
  langid = {english},
  keywords = {✅,legal},
  file = {/Users/sgraf/Zotero/storage/XPA7NIZC/Sorbán - 2023 - An elephant in the room—EU policy gaps in the regu.pdf}
}

@book{sprenger2024,
  title = {Das Plattformverfahren: Ausbalancierte Rechtsdurchsetzung mittels Verfahrensgrundsätzen},
  shorttitle = {Das Plattformverfahren},
  author = {Sprenger, Tim},
  date = {2024},
  series = {Normsetzung und Entscheidungsverfahren – Schriftenreihe des Weizenbaum-Instituts für normative Wissenschaften},
  edition = {1. Auflage},
  number = {2},
  publisher = {Nomos Verlagsgesellschaft mbH \& Co. KG},
  location = {Baden-Baden},
  doi = {10.5771/9783748949527},
  isbn = {978-3-7489-4952-7},
  langid = {german},
  pagetotal = {1},
  file = {/Users/sgraf/Zotero/storage/B69XW9NJ/9783748949527-23.pdf;/Users/sgraf/Zotero/storage/D3HZGI52/9783748949527-357.pdf;/Users/sgraf/Zotero/storage/XR4K4ZG6/Sprenger_2024_Das Plattformverfahren Ausbalancierte Rechtsdurchsetzung mittels Verfahrensgrundsätzen.pdf}
}

@article{stegeman2024,
  title = {Regulating and Representing Camming: {{Strict}} Limits on Acceptable Content on Webcam Sex Platforms},
  shorttitle = {Regulating and Representing Camming},
  author = {Stegeman, Hanne Marleen},
  date = {2024-01},
  journaltitle = {New Media \& Society},
  shortjournal = {New Media \& Society},
  volume = {26},
  number = {1},
  pages = {329--345},
  issn = {1461-4448, 1461-7315},
  doi = {10.1177/14614448211059117},
  url = {https://journals.sagepub.com/doi/10.1177/14614448211059117},
  urldate = {2025-06-04},
  abstract = {This article analyses the discursive construction of the limits of webcamming in terms of service agreements by BongaCams, LiveJasmin and Chaturbate, three of the world’s most popular webcam sex platforms. Through this analysis, the moderation practices in the webcamming industry are examined. Regulation of sexual platforms and its implications for representations of online sex work are still largely unclear. Through a critical discourse analysis of seven webcam platform terms of service documents, this article scrutinises the norms for camming as dictated by industry leading platforms. This analysis shows that these platforms, for legal and financial reasons, reject the idea of camming as sexually explicit or as (sex) work. Such a construction of camming limits sexual expression online, obstructs online sex workers’ labour rights and perpetuates sex work stigma. This article sheds light on how digital platforms can establish and maintain norms which regulate users’ online expressions, working conditions and representations.},
  langid = {english}
}

@article{stilinovic2025,
  title = {Creative {{Underspheres}} and Democratic Challenges: {{Exploring}} the Implications of Generative {{AI}} Misuse},
  shorttitle = {Creative {{Underspheres}} and Democratic Challenges},
  author = {Stilinovic, Milica and Bailo, Francesco and Hutchinson, Jonathon},
  date = {2025-05-15},
  journaltitle = {New Media \& Society},
  shortjournal = {New Media \& Society},
  pages = {14614448251338511},
  issn = {1461-4448, 1461-7315},
  doi = {10.1177/14614448251338511},
  url = {https://journals.sagepub.com/doi/10.1177/14614448251338511},
  urldate = {2025-06-04},
  abstract = {This article introduces the concept of the Undersphere – a networked community brought together via creative exchange – to highlight how the increased proliferation of Generative AI poses risks not yet acknowledged by policymakers within emerging AI regulatory frameworks. Employing a single case study methodology – namely, exploring exchanges made on r/StableDiffusion, a known subgroup on Reddit – it illustrates the conceptual parameters of the Undersphere, outlines the potential for creative harm within the GenAI space, and counters these elements against the AI regulatory frameworks found within the EU AI Act. It concludes that a risk management framework that provides a more fluid approach to addressing risks, such as those found in governance frameworks aimed at eradicating climate change, could be better positioned to address insecurities manifesting from the GenAI space.},
  langid = {english},
  file = {/Users/sgraf/Zotero/storage/SSC4VHC4/Stilinovic et al._2025_Creative Underspheres and democratic challenges Exploring the implications of generative AI misuse.pdf}
}

@article{sybert2022,
  title = {The Demise of \#{{NSFW}}: {{Contested}} Platform Governance and {{Tumblr}}’s 2018 Adult Content Ban},
  shorttitle = {The Demise of \#{{NSFW}}},
  author = {Sybert, Jeanna},
  date = {2022-10},
  journaltitle = {New Media \& Society},
  shortjournal = {New Media \& Society},
  volume = {24},
  number = {10},
  pages = {2311--2331},
  issn = {1461-4448, 1461-7315},
  doi = {10.1177/1461444821996715},
  url = {https://journals.sagepub.com/doi/10.1177/1461444821996715},
  urldate = {2025-06-04},
  abstract = {On December 3, 2018, Tumblr announced that it would ban sexually explicit content from the platform, drawing immediate backlash from users. The ensuing discord on the site is conceptualized here as contested platform governance, or a conflict between users and ownership, in which not only are a platform’s policies and features challenged, but also its core values, identity, and/or purposes are put into question. By examining 238 Tumblr posts, this analysis identifies the unique ways users combatted the ban and (re)inscribed community values, while also contesting the owners’ legitimacy to govern the platform. Holding implications for the site’s long-term survival, such conflicts capture a critical moment in which the boundaries of power between users and ownership are challenged and, possibly, transformed. By examining Tumblr’s Not Safe For Work (NSFW) ban through the lens of platform governance, this study offers insight into how power and its limits are negotiated online.},
  langid = {english},
  keywords = {⏳,✅},
  file = {/Users/sgraf/Zotero/storage/DPF4ZQRD/Sybert_2022_The demise of #NSFW Contested platform governance and Tumblr’s 2018 adult content ban.pdf}
}

@article{thurman2021,
  title = {The Regulation of Internet Pornography: {{What}} a Survey of Under‐18s Tells Us about the Necessity for and Potential Efficacy of Emerging Legislative Approaches},
  shorttitle = {The Regulation of Internet Pornography},
  author = {Thurman, Neil and Obster, Fabian},
  date = {2021-09},
  journaltitle = {Policy \& Internet},
  shortjournal = {Policy \&amp; Internet},
  volume = {13},
  number = {3},
  pages = {415--432},
  issn = {1944-2866, 1944-2866},
  doi = {10.1002/poi3.250},
  url = {https://onlinelibrary.wiley.com/doi/10.1002/poi3.250},
  urldate = {2024-09-09},
  abstract = {Abstract             In 2017, the UK Parliament passed an Act requiring legal pornographic websites to implement ‘robust’ age verification checks. Although the Act inspired lawmakers elsewhere to propose similar legislation, it was never enacted, in part because it did not cover social media platforms. Instead, the UK government has turned to its Online Harms White Paper—which does target social media platforms—to protect children from online pornography. There is, however, scant evidence on the media platforms and technologies children use to access pornography. To fill this knowledge gap, we conducted a survey of 16‐ and 17‐year‐olds in the United Kingdom. The results show that more (63\%) had seen pornography on social media platforms than on pornographic websites (47\%), suggesting the UK government was right to target such platforms in its latest proposals. However, pornography was much more frequently viewed on pornographic websites than on social media, showing how important the regulation of such sites remains. Furthermore, our finding that 46\% of 16‐ and 17‐year‐olds had used a virtual private network or Tor browser adds weight to concerns that restrictions on legal internet pornography—such as age verification checks—imposed by a single country may be circumvented by those the restrictions are designed to protect.           ,              摘要             2017年，英国议会通过一项法案，要求合法的色情网站执行“稳健的”年龄验证措施。尽管该法案启发了其他地方的立法者提出相似法律，但该法案却从未颁布，这部分归因于其没有涵盖社交媒体平台。相反，英国政府转向《网络危害白皮书》—该白皮书以社交媒体平台为目标—来保护儿童远离网络色情。不过，几乎没有关于儿童获取色情网站所使用的媒体平台和技术的研究。为填补该知识空白，我们对英国16‐17岁的未成年人进行了一项调查。调查结果显示，比起浏览色情网站（47\%），更多的调查对象（63\%）通过社交媒体平台浏览色情内容，这暗示英国政府在最近的提议中瞄准这类平台是正确的。不过，比起社交媒体，色情网站的浏览次数高得多，这表明了对这类网站的监管仍然是重要的。此外，我们的研究发现—46\%的调查对象曾使用虚拟专用网络或Tor浏览器—强调了相关顾虑，即由单个国家强制执行的合法网络色情限制（例如年龄验证）可能被保护对象所规避。           ,              Resumen             En 2017, el Parlamento del Reino Unido aprobó una ley que requiere que los sitios web pornográficos legales implementen controles de verificación de edad "robustos". Aunque la ley inspiró a los legisladores de otros lugares a proponer una legislación similar, nunca se promulgó, en parte porque no cubría las plataformas de redes sociales. En cambio, el gobierno del Reino Unido ha recurrido a su Libro blanco sobre daños en línea, que se dirige a las plataformas de redes sociales, para proteger a los niños de la pornografía en línea. Sin embargo, hay poca evidencia sobre las plataformas de medios y las tecnologías que utilizan los niños para acceder a la pornografía. Para llenar este vacío de conocimiento, realizamos una encuesta a jóvenes de 16 y 17 años en el Reino Unido. Los resultados muestran que más (63\%) había visto pornografía en plataformas de redes sociales que en sitios web pornográficos (47\%), lo que sugiere que el gobierno del Reino Unido hizo bien en apuntar a tales plataformas en sus últimas propuestas. Sin embargo, la pornografía se ve con mucha más frecuencia en sitios web pornográficos que en las redes sociales, lo que demuestra lo importante que sigue siendo la regulación de dichos sitios. Además, nuestro hallazgo de que el 46\% de los jóvenes de 16 y 17 años habían usado un navegador VPN o Tor aumenta las preocupaciones de que las restricciones sobre la pornografía legal en Internet, como los controles de verificación de edad, impuestas por un solo país pueden ser eludidas por aquellos las restricciones están diseñadas para proteger.},
  langid = {english},
  keywords = {⏳,unread},
  file = {/Users/sgraf/Zotero/storage/Y7S8I8B9/Thurman und Obster - 2021 - The regulation of internet pornography What a sur.pdf}
}

@article{thurman2022,
  title = {Lessons from {{France}} on the Regulation of {{Internet}} Pornography: {{How}} Displacement Effects, Circumvention, and Legislative Scope May Limit the Efficacy of {{Article}} 23},
  shorttitle = {Lessons from {{France}} on the Regulation of {{Internet}} Pornography},
  author = {Thurman, Neil and Nalmpatian, Asmik and Obster, Fabian},
  date = {2022-09},
  journaltitle = {Policy \& Internet},
  shortjournal = {Policy \& Internet},
  volume = {14},
  number = {3},
  pages = {690--710},
  issn = {1944-2866, 1944-2866},
  doi = {10.1002/poi3.293},
  url = {https://onlinelibrary.wiley.com/doi/10.1002/poi3.293},
  urldate = {2024-09-09},
  abstract = {Abstract             In 2020, the French Parliament passed an amendment that put the country at the forefront of attempts by democratic states to restrict young people's access to legal online pornography. This study examines the necessity for and potential efficacy of the amendment, Article 23,~through a comparative analysis of emerging legislative and regulatory approaches in France, the UK, Canada, Utah, and Germany, and through a survey of French 15‐, 16‐, and 17‐year‐olds. Among~other things, our survey shows that 41\% of 15‐, 16‐, and 17‐year‐olds in France visit dedicated pornographic sites, on average monthly and often much more frequently. However, the range of media platforms via which French adolescents are exposed to pornography, their knowledge about technologies that could circumvent age verification, and the power, scope, and implementation of Article 23 may limit the legislation's efficacy. Our findings suggest the mechanisms that may limit its efficacy include media displacement, socio‐technical circumvention, and the Article's relatively broad and imprecise nature. This study has implications for legislators and regulators in democratic countries beyond France as they too grapple with the challenges of regulating online pornography. Furthermore, it extends the often contradictory and/or limited evidence that exists about adolescents' consumption of pornography.           ,              摘要             2020年，法国议会通过了一项修订案，此举在由民主国家发起的限制年轻人对合法网络色情获取的一系列举措中占据重要位置。通过对法国、英国、加拿大、犹他州、以及德国的法律措施和监管措施进行比较分析，并通过对法国的15‐17岁未成年人进行调研，本研究分析了该修订案的必要性和潜在效能。我们的调查显示，除其他因素外，法国15‐17岁未成年中有41\%的人平均每月访问并且经常更频繁地访问专门的色情网站。不过，法国未成年人接触的色情媒体平台范围、其对能规避年龄验证的技术的了解、以及《法案第23条》（Article 23）的权力、范围和执行，这些因素能限制该法案的效能。我们的研究发现暗示，能限制该法律效能的机制包括媒体替代（media displacement）、社会‐技术规避、以及该法案相对宽泛和模糊的性质。本研究对法国之外的民主国家的立法者和监管者具有意义，因为他们也在努力应对网络色情监管挑战。此外，本研究扩展了有关未成年人色情消费的证据，后者经常是不一致和/或不充足的。           ,              Resumen             En 2020, el parlamento francés aprobó una enmienda que colocó al país a la vanguardia de los intentos de los estados democráticos de restringir el acceso de los jóvenes a la pornografía legal en línea. Este estudio examina la necesidad y la eficacia potencial de la enmienda a través de un análisis comparativo de enfoques legislativos y regulatorios emergentes en Francia, el Reino Unido, Canadá, Utah y Alemania, y a través de una encuesta de franceses de 15, 16 y 17 años. Entre otras cosas, nuestra encuesta muestra que el 41\% de los jóvenes de 15, 16 y 17 años en Francia visitan sitios pornográficos dedicados, en promedio mensualmente y, a menudo, con mucha más frecuencia. Sin embargo, la variedad de plataformas de medios a través de las cuales los adolescentes franceses están expuestos a la pornografía, su conocimiento sobre tecnologías que podrían eludir la verificación de edad y el poder, el alcance y la implementación del Artículo 23 pueden limitar su eficacia. Nuestros hallazgos sugieren que los mecanismos que pueden limitar la eficacia de la legislación incluyen el desplazamiento de los medios, la elusión sociotécnica y la naturaleza relativamente amplia e imprecisa del artículo. Este estudio tiene implicaciones para los legisladores y reguladores en países democráticos más allá de Francia, ya que ellos también lidian con los desafíos de regular la pornografía en línea. Además, amplía la evidencia muchas veces contradictoria y/o limitada que existe sobre el consumo de pornografía por parte de los adolescentes.},
  langid = {english},
  keywords = {⏳,unread},
  file = {/Users/sgraf/Zotero/storage/CN36NS8P/Thurman et al. - 2022 - Lessons from France on the regulation of Internet .pdf}
}

@article{tiidenberg2021,
  title = {Sex, Power and Platform Governance},
  author = {Tiidenberg, Katrin},
  date = {2021-10-02},
  journaltitle = {Porn Studies},
  shortjournal = {Porn Studies},
  volume = {8},
  number = {4},
  pages = {381--393},
  issn = {2326-8743, 2326-8751},
  doi = {10.1080/23268743.2021.1974312},
  url = {https://www.tandfonline.com/doi/full/10.1080/23268743.2021.1974312},
  urldate = {2025-03-05},
  langid = {english},
  keywords = {⏳},
  file = {/Users/sgraf/Zotero/storage/HMTGKB4M/Tiidenberg_2021_Sex, power and platform governance.pdf}
}

@article{timmerman2023,
  title = {Studying the {{Online Deepfake Community}}},
  author = {Timmerman, Brian and Mehta, Pulak and Deb, Progga and Gallagher, Kevin and Dolan-Gavitt, Brendan and Garg, Siddharth and Greenstadt, Rachel},
  date = {2023-09-21},
  journaltitle = {Journal of Online Trust and Safety},
  shortjournal = {jots},
  volume = {2},
  number = {1},
  issn = {2770-3142},
  doi = {10.54501/jots.v2i1.126},
  url = {https://www.tsjournal.org/index.php/jots/article/view/126},
  urldate = {2025-07-05},
  abstract = {Deepfakes have become a dual-use technology with applications in the domains of art, science, and industry. However, the technology can also be leveraged maliciously in areas such as disinformation, identity fraud, and harassment. In response to the technology's dangerous potential many deepfake creation communities have been deplatformed, including the technology's originating community~– r/deepfakes. Opening in February 2018, just eight days after the removal of r/deepfakes, MrDeepFakes (MDF) went online as a privately owned platform to fulfill the role of community hub, and has since grown into the largest dedicated deepfake creation and discussion platform currently online. This position of community hub is balanced against the site's other main purpose, which is the hosting of deepfake pornography depicting public figures- produced without consent. In this paper we explore the two largest deepfake communities that have existed via a mixed methods approach utilizing quantitative and qualitative analysis. We seek to identify how these platforms were and are used by their members, what opinions these deepfakers hold about the technology and how it is seen by society at large, and identify how deepfakes-as-disinformation is viewed by the community. We find that there is a large emphasis on technical discussion on these platforms, intermixed with potentially malicious content. Additionally, we find the deplatforming of deepfake communities early in the technology's life has significantly impacted trust regarding alternative community platforms.},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/UDYA32NA/Timmerman et al._2023_Studying the Online Deepfake Community.pdf}
}

@report{uklawcommission2022,
  title = {Intimate Image Abuse: A Final Report},
  author = {{UK Law Commission}},
  date = {2022-07-06},
  number = {Law Com No 407},
  pages = {505},
  institution = {Law Commission},
  url = {https://webarchive.nationalarchives.gov.uk/ukgwa/20250109101427mp_/https://cloud-platform-e218f50a4812967ba1215eaecede923f.s3.amazonaws.com/uploads/sites/30/2022/07/Intimate-image-abuse-final-report.pdf},
  urldate = {2025-06-16},
  file = {/Users/sgraf/Zotero/storage/7HGLM6S4/UK Law Commission_2022_Intimate image abuse a final report.pdf}
}

@inproceedings{umbach2024,
  title = {Non-{{Consensual Synthetic Intimate Imagery}}: {{Prevalence}}, {{Attitudes}}, and {{Knowledge}} in 10 {{Countries}}},
  shorttitle = {Non-{{Consensual Synthetic Intimate Imagery}}},
  booktitle = {Proceedings of the {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Umbach, Rebecca and Henry, Nicola and Beard, Gemma Faye and Berryessa, Colleen M.},
  date = {2024-05-11},
  pages = {1--20},
  publisher = {ACM},
  location = {Honolulu HI USA},
  doi = {10.1145/3613904.3642382},
  url = {https://dl.acm.org/doi/10.1145/3613904.3642382},
  urldate = {2025-08-03},
  eventtitle = {{{CHI}} '24: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {979-8-4007-0330-0},
  langid = {english},
  keywords = {⏳},
  file = {/Users/sgraf/Zotero/storage/FEVLTFUR/Umbach et al._2024_Non-Consensual Synthetic Intimate Imagery Prevalence, Attitudes, and Knowledge in 10 Countries.pdf}
}

@article{vandernagel2020,
  title = {Verifying Images: Deepfakes, Control, and Consent},
  shorttitle = {Verifying Images},
  author = {Van Der Nagel, Emily},
  date = {2020-10},
  journaltitle = {Porn Studies},
  shortjournal = {Porn Studies},
  volume = {7},
  number = {4},
  pages = {424--429},
  issn = {2326-8743, 2326-8751},
  doi = {10.1080/23268743.2020.1741434},
  url = {https://www.tandfonline.com/doi/full/10.1080/23268743.2020.1741434},
  urldate = {2025-06-03},
  langid = {english},
  keywords = {⏳},
  file = {/Users/sgraf/Zotero/storage/TFDL2SLJ/Van Der Nagel_2020_Verifying images deepfakes, control, and consent.pdf}
}

@article{velez2019,
  title = {“{{Why Take}} the {{Photo}} If {{You Didn}}’t {{Want It Online}}?”: {{Agency}}, {{Transformation}}, and {{Nonconsensual Pornography}}},
  shorttitle = {“{{Why Take}} the {{Photo}} If {{You Didn}}’t {{Want It Online}}?},
  author = {Velez, Meghan},
  date = {2019-10-02},
  journaltitle = {Women's Studies in Communication},
  volume = {42},
  number = {4},
  pages = {452--470},
  publisher = {Informa UK Limited},
  issn = {0749-1409, 2152-999X},
  doi = {10.1080/07491409.2019.1676350},
  url = {https://www.tandfonline.com/doi/full/10.1080/07491409.2019.1676350},
  urldate = {2025-07-15},
  langid = {english}
}

@article{viola2023,
  title = {Designed to Abuse? {{Deepfakes}} and the Non-Consensual Diffusion of Intimate Images},
  shorttitle = {Designed to Abuse?},
  author = {Viola, Marco and Voto, Cristina},
  date = {2023-01-13},
  journaltitle = {Synthese},
  shortjournal = {Synthese},
  volume = {201},
  number = {1},
  pages = {30},
  issn = {1573-0964},
  doi = {10.1007/s11229-022-04012-2},
  url = {https://link.springer.com/10.1007/s11229-022-04012-2},
  urldate = {2025-06-03},
  abstract = {Abstract                            The illicit diffusion of intimate photographs or videos intended for private use is a troubling phenomenon known as the diffusion of Non-Consensual Intimate Images (NCII). Recently, it has been feared that the spread of deepfake technology, which allows users to fabricate fake intimate images or videos that are indistinguishable from genuine ones, may dramatically extend the scope of NCII. In the present essay, we counter this pessimistic view, arguing for               qualified               optimism instead. We hypothesize that the growing diffusion of deepfakes will end up disrupting the status that makes our visual experience of photographic images and videos epistemically and affectively special; and that once divested of this status, NCII will lose much of their allure in the eye of the perpetrators, probably resulting in diminished diffusion. We conclude by offering some caveats and drawing some implications to better understand, and ultimately better counter, this phenomenon.},
  langid = {english},
  keywords = {⏳},
  file = {/Users/sgraf/Zotero/storage/WKD8QLMR/Viola und Voto_2023_Designed to abuse Deepfakes and the non-consensual diffusion of intimate images.pdf}
}

@article{warzel2018,
  entrysubtype = {nonacademic},
  title = {Pornhub Banned Deepfake Celebrity Sex Videos, but the Site Is Still Full of Them},
  author = {Warzel, Charlie},
  date = {2018-04-19},
  url = {https://www.buzzfeednews.com/article/charliewarzel/pornhub-banned-deepfake-celebrity-sex-videos-but-the-site#.hrzVy3bM5V},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/GWVXQ3GL/Warzel_2018_Pornhub banned deepfake celebrity sex videos, but the site is still full of them.pdf}
}

@article{webber2023,
  title = {Pornhub and {{Policy}}: {{Examining}} the {{Erasure}} of {{Pornography Workers}} in {{Canadian Platform Governance}}},
  shorttitle = {Pornhub and {{Policy}}},
  author = {Webber, Valerie and MacDonald, Maggie and Duguay, Stefanie and McKelvey, Fenwick},
  date = {2023-06-01},
  journaltitle = {Canadian Journal of Communication},
  volume = {48},
  number = {2},
  pages = {381--404},
  publisher = {University of Toronto Press Inc. (UTPress)},
  issn = {0705-3657, 1499-6642},
  doi = {10.3138/cjc.2022-0044},
  url = {https://cjc.utppublishing.com/doi/10.3138/cjc.2022-0044},
  urldate = {2025-05-22},
  abstract = {Background: In 2021, the Canadian Parliamentary Standing Committee on Access to Information, Privacy and Ethics (ETHI) conducted an inquiry around Pornhub, following allegations that parent company MindGeek profits from non-consensual content.  Analysis: This article offers a discourse analysis of the ETHI’s process, testimony, and report on Pornhub using Carol Bacchi’s policy analysis method, “What is the problem represented to be?”  Conclusions and implications: This study reveals a policy process blatantly influenced by anti-porn sentiments, resulting in hearings that framed porn as sexual violence rather than sex industry labour. It exposes how ETHI’s approach failed to constructively engage existing regulations, precarious labour conditions, or platform operations. The result is ineffective policy recommendations that procedurally exclude relevant stakeholders and do not adequately protect platform users from harm.},
  langid = {english},
  keywords = {✅},
  file = {/Users/sgraf/Zotero/storage/4ZZ6QLB2/Webber et al._2023_Pornhub and Policy Examining the Erasure of Pornography Workers in Canadian Platform Governance.pdf}
}

@article{west2024,
  title = {Image-Based Sexual Violence and Imperfect Victims: The Case for Platform Cooperativism in the Online Sex Industry},
  shorttitle = {Image-Based Sexual Violence and Imperfect Victims},
  author = {West, Josie Rachel},
  date = {2024-06-26},
  journaltitle = {Porn Studies},
  shortjournal = {Porn Studies},
  pages = {1--15},
  issn = {2326-8743, 2326-8751},
  doi = {10.1080/23268743.2024.2362154},
  url = {https://www.tandfonline.com/doi/full/10.1080/23268743.2024.2362154},
  urldate = {2025-06-03},
  langid = {english},
  file = {/Users/sgraf/Zotero/storage/RQCUN8QJ/West_2024_Image-based sexual violence and imperfect victims the case for platform cooperativism in the online.pdf}
}

@article{williams2025,
  entrysubtype = {nonacademic},
  title = {Free {{Speech Advocates Express Concerns As TAKE IT DOWN Act Passes US Senate}}},
  author = {Williams, Kaylee},
  date = {2025-02-21},
  journaltitle = {Tech Policy Press},
  url = {https://www.techpolicy.press/free-speech-advocates-express-concerns-as-take-it-down-act-passes-us-senate/},
  urldate = {2025-04-02},
  file = {/Users/sgraf/Zotero/storage/TT4JIMAX/Williams_2025_Free Speech Advocates Express Concerns As TAKE IT DOWN Act Passes US Senate.pdf}
}

@article{witt2022,
  title = {Platform {{Regulation}} in {{Europe}}— {{{\mkbibemph{Per Se}}}} {{Rules}} to the {{Rescue}}?},
  author = {Witt, Anne C},
  date = {2022-09-15},
  journaltitle = {Journal of Competition Law \& Economics},
  volume = {18},
  number = {3},
  pages = {670--708},
  issn = {1744-6414, 1744-6422},
  doi = {10.1093/joclec/nhac001},
  url = {https://academic.oup.com/jcle/article/18/3/670/6535681},
  urldate = {2025-03-05},
  abstract = {ABSTRACT             Mainstream competition law has failed to protect competition in core digital platform markets. This is partially due to enforcement agencies’ current commitment to proving the investigated conduct’s actual effects on competition and consumer welfare on the basis of in-depth assessments of each case’s individual circumstances before intervening in the market. While reducing the likelihood of erroneously prohibiting conduct that is not actually harmful, this approach is too time- and resource-consuming to protect competition in digital markets prone to tipping. This contribution argues that well-designed per se rules offer a promising alternative. Against this background, it critically assesses how three emerging European models of platform regulation (the draft EU Digital Markets Act, the draft UK Pro-Competition Regime, and the German Digitalisation Act) balance the objectives of ensuring time- and cost-effective enforcement, avoiding enforcement errors, and maximizing legal certainty for platforms. It concludes that the UK model currently promises to strike the best balance between these competing aims.},
  langid = {english},
  keywords = {⏳,❌}
}

@article{yanow2007,
  title = {Interpretation in Policy Analysis: {{On}} Methods and Practice},
  shorttitle = {Interpretation in Policy Analysis},
  author = {Yanow, Dvora},
  date = {2007-03},
  journaltitle = {Critical Policy Studies},
  shortjournal = {Critical Policy Studies},
  volume = {1},
  number = {1},
  pages = {110--122},
  issn = {1946-0171, 1946-018X},
  doi = {10.1080/19460171.2007.9518511},
  url = {http://www.tandfonline.com/doi/abs/10.1080/19460171.2007.9518511},
  urldate = {2025-04-04},
  langid = {english},
  keywords = {⏳,✅},
  file = {/Users/sgraf/Zotero/storage/JC2ABC2W/Interpretation in policy analysis  On methods and practice.pdf;/Users/sgraf/Zotero/storage/PMI76LIN/Yanow_2007_Interpretation in policy analysis On methods and practice.pdf}
}

@incollection{yanow2007a,
  title = {Qualitative-{{Interpretive Methods}} in {{Policy Research}}},
  booktitle = {Handbook of Public Policy Analysis: Theory, Politics, and Methods},
  author = {Yanow, Dvora},
  editor = {Fischer, Frank and Miller, Gerald},
  date = {2007},
  series = {Public {{Administration}} and {{Public Policy}}},
  edition = {1st edition},
  pages = {405--416},
  publisher = {Routledge},
  location = {New York},
  doi = {10.4324/9781315093192},
  abstract = {"The study of public policy and the methods of policy analysis are among the most rapidly developing areas in the social sciences. Policy analysis has emerged to provide a better understanding of the policymaking process and to supply decision makers with reliable policy-relevant knowledge about pressing economic and social problems. Presenting a broad, comprehensive perspective, the Handbook of Public Policy Analysis: Theory, Politics, and Methods covers the historical development of policy analysis, its role in the policy process, and empirical methods. The handbook considers the theory generated by these methods and the normative and ethical issues surrounding their practice. Written by leading experts in the field, this book-Deals with the basic origins and evolution of public policy Examines the stages of the policy-making processIdentifies political advocacy and expertise in the policy processFocuses on rationality in policy decision-making and the role of policy networks and learningDetails argumentation, rhetoric, and narratives Explores the comparative, cultural, and ethical aspects of public policy Explains primary quantitative-oriented analytical methods employed in policy researchAddresses the qualitative sides of policy analysis Discusses tools used to refine policy choicesTraces the development of policy analysis in selected national contextsThe Handbook of Public Policy Analysis: Theory, Politics, and Methods describes the theoretical debates that have recently defined the field, including the work of postpositivist, interpretivist, and social constructionist scholars. This book also explores the interplay between empirical and normative analysis, a crucial issue running through contemporary debates."--Provided by publisher},
  isbn = {978-1-315-09319-2},
  langid = {english},
  keywords = {⏳},
  file = {/Users/sgraf/Zotero/storage/PURF6CKD/Fischer und Miller_2017_Handbook of public policy analysis theory, politics, and methods.pdf}
}

@article{ziewitz2016,
  title = {Governing {{Algorithms}}: {{Myth}}, {{Mess}}, and {{Methods}}},
  shorttitle = {Governing {{Algorithms}}},
  author = {Ziewitz, Malte},
  date = {2016-01},
  journaltitle = {Science, Technology, \& Human Values},
  shortjournal = {Science, Technology, \& Human Values},
  volume = {41},
  number = {1},
  pages = {3--16},
  issn = {0162-2439, 1552-8251},
  doi = {10.1177/0162243915608948},
  url = {https://journals.sagepub.com/doi/10.1177/0162243915608948},
  urldate = {2025-04-04},
  abstract = {Algorithms have developed into somewhat of a modern myth. On the one hand, they have been depicted as powerful entities that rule, sort, govern, shape, or otherwise control our lives. On the other hand, their alleged obscurity and inscrutability make it difficult to understand what exactly is at stake. What sustains their image as powerful yet inscrutable entities? And how to think about the politics and governance of something that is so difficult to grasp? This editorial essay provides a critical backdrop for the special issue, treating algorithms not only as computational artifacts but also as sensitizing devices that can help us rethink some entrenched assumptions about agency, transparency, and normativity.},
  langid = {english},
  keywords = {⏳},
  file = {/Users/sgraf/Zotero/storage/5SPRL99F/ziewitz-2015-governing-algorithms-myth-mess-and-methods.pdf}
}

@legislation{zotero-item-13064,
  title = {Draft {{Delegated Act}}},
  file = {/Users/sgraf/Zotero/storage/CVJJJLJ3/090166e513e46d31.pdf}
}

@article{zotero-item-14407,
  title = {Directive ({{EU}}) 2024/1385 of the {{European Parliament}} and of the {{Council}} of 14 {{May}} 2024 on Combating Violence against Women and Domestic Violence},
  langid = {english},
  file = {/Users/sgraf/Zotero/storage/T3ILBCDU/Directive (EU) 20241385 of the European Parliament and of the Council of 14 May 2024 on combating v.pdf}
}
